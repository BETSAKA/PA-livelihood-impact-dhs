---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Sensitivity tests

Ce document fournit les différents tests de robustesse utilisés dans l'analyse. Cette étape est un aspect crucial pour garantir la fiabilité et de la validation de notre méthodologie.

## Test de sensibilité aux tailles de buffer

### Test pour une distance de 5 km

#### Assignation des traitements

```{r}
# Library
library(tidyverse) 
library(haven) 
library(sf) 
library(tmap) 
library(gt)  
library(geodata) 
library(writexl)
library(units) 
library(leaflet) 
library(readxl) 
library(glue)


# Systèmes de coordonnées de référence 
standard_crs <- 4326
mdg_crs <- 29702 

# On charge les données gps 
gps_1997_initial <- st_read("data/raw/dhs/DHS_1997/MDGE32FL/MDGE32FL.shp")
gps_2008_initial <- st_read("data/raw/dhs/DHS_2008/MDGE53FL/MDGE53FL.shp") 
gps_2011_initial <- st_read("data/raw/dhs/DHS_2011/MDGE61FL/MDGE61FL.shp") 
gps_2013_initial <- st_read("data/raw/dhs/DHS_2013/MDGE6AFL/MDGE6AFL.shp") 
gps_2016_initial <- st_read("data/raw/dhs/DHS_2016/MDGE71FL/MDGE71FL.shp")
gps_2021_initial <- st_read("data/raw/dhs/DHS_2021/MDGE81FL/MDGE81FL.shp")

# Fonction qui vérifie que les coordonnées ne sont pas nulles
check_coordinates <- function(dhs_gps, country_polygon, negate = FALSE) {
  dhs_gps %>%
    filter(LONGNUM != 0 | LATNUM != 0)
}

gps_1997 <- check_coordinates(gps_1997_initial, contour_mada)
gps_2008 <- check_coordinates(gps_2008_initial, contour_mada)
gps_2011 <- check_coordinates(gps_2011_initial, contour_mada)
gps_2013 <- check_coordinates(gps_2013_initial, contour_mada)
gps_2016 <- check_coordinates(gps_2016_initial, contour_mada)
gps_2021 <- check_coordinates(gps_2021_initial, contour_mada)

# Load boundary 
contour_mada <- gadm(country = "Madagascar", level = 0, path = "data") %>%
  st_as_sf() %>%
  st_set_crs(standard_crs)

# On charge les données des AP
wdpa_terrestre_mod <- st_read("data/derived/wdpa_terrestre_mod.shp") %>%
  rename(
    WDPA_PID = WDPA_PI,
    ORIG_NAME = ORIG_NA,
    DESIG_ENG = DESIG_E,
    DESIG_TYPE = DESIG_T,
    IUCN_CAT = IUCN_CA,   
    INT_CRIT = INT_CRI,
    REP_M_AREA = REP_M_A,
    REP_AREA = REP_ARE,
    NO_TK_AREA = NO_TK_A,
    STATUS_YR = STATUS_,
    GEOMETRY_TYPE = GEOMETR,
    AREA_KM2 = AREA_KM,
    area_km2 = are_km2
  ) %>% 
  st_make_valid() %>%
  st_transform(standard_crs)

# Intersection des AP de WDPA avec la limite de Madagascar
wdpa_terrestre <- wdpa_terrestre_mod %>%
  st_make_valid() %>%
  filter(rowSums(st_intersects(., contour_mada, sparse = FALSE)) > 0) %>%
  st_transform(mdg_crs) %>%
  mutate(
    area_m2  = as.numeric(st_area(.)),
    area_ha  = area_m2 / 1e4,
    area_km2 = area_m2 / 1e6
  ) %>%
  st_transform(standard_crs)

# Buffer de 5 km
buffer_dist <- 5000

# Spécification des AP avant-après 2008--------
wdpa_before_2008 <- wdpa_terrestre_mod %>%
  filter(STATUS_YR < 2008)
wdpa_from_2008 <- wdpa_terrestre_mod %>%
  filter(STATUS_YR >= 2008)

# Créer des buffers de 5 km autour des AP
buffer_5km_before_2008 <- 
  wdpa_before_2008 %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)


buffer_5km_from_2008 <- wdpa_from_2008  %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)

# Visualisation des cartes---------------------
tmap_mode("view")

tm_shape(contour_mada) + 
  tm_borders(col = "black", lwd = 1) +
  
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "blue", 
              col =  "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) +
  
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "darkgreen", 
              col = "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) + 
  
tm_shape(buffer_5km_from_2008) +
tm_borders(col = "darkgreen", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
  
tm_shape(buffer_5km_before_2008) +
tm_borders(col = "blue", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
tm_add_legend(
  type = "polygons", 
  fill = c("blue", "darkgreen"), 
  labels = c("avant 2008", "après 2008")) +
  tm_title("Aires protégées du WDPA par période de création</b><br/>Source: WDPA, 2024") +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE,
    legend.title.size = 1.2,
    legend.text.size = 0.8
  ) +
  tm_compass(type = "8star", position = c("right", "top")) +
  tm_scalebar(position = c("right", "bottom"))

# Classification des clusters---------------------------------------------------------
#| fig-cap: "Grappes d'enquêtes DHS par rapport aux aires protégées existantes"


classify_clusters_with_pa <- function(cluster_gps,
                                      buffer_before,   # union of <2008
                                      wdpa_after,      # polygons >=2008 (no union)
                                      buffer_dist = 5000,
                                      label_treat = "Treatment",
                                      label_excl  = "Excluded",
                                      label_ctrl  = "Control") {

  # per-PA buffers (keep attrs)
  wdpa_after_buf <- wdpa_after %>%
    st_transform(mdg_crs) %>%
    mutate(geometry = st_buffer(geometry, buffer_dist)) %>%
    st_transform(standard_crs)

  # flags
  in_after  <- st_within(cluster_gps, st_union(wdpa_after_buf),  sparse = FALSE)[,1]
  in_before <- st_within(cluster_gps, buffer_before,            sparse = FALSE)[,1]

  base <- cluster_gps %>%
    mutate(groupe = case_when(
      in_after & !in_before & URBAN_RURA == "R" ~ label_treat,
      in_before | URBAN_RURA == "U"            ~ label_excl,
      TRUE                                     ~ label_ctrl
    ))

  # enrich treated with oldest+nearest PA
  treated_pts <- base %>% filter(groupe == label_treat)

  if (nrow(treated_pts) == 0) return(base)

  cand <- st_join(treated_pts, wdpa_after_buf, join = st_within, left = FALSE) %>%
  mutate(
    .idx = match(WDPAID, wdpa_after$WDPAID),
    dist_km = as.numeric(
      st_distance(
        geometry,
        wdpa_after$geometry[.idx],
        by_element = TRUE
      )
    ) / 1000
  ) %>%
  dplyr::select(-.idx)

  best <- cand %>%
    group_by(DHSCLUST) %>%
    slice_min(STATUS_YR, with_ties = TRUE) %>%
    slice_min(dist_km,   with_ties = FALSE) %>%
    ungroup() %>%
    st_drop_geometry() %>%
    select(DHSYEAR, DHSCLUST, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

  base %>% left_join(best, by = c("DHSYEAR","DHSCLUST"))
}

gps_1997_class <- classify_clusters_with_pa(gps_1997, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2008_class <- classify_clusters_with_pa(gps_2008, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2011_class <- classify_clusters_with_pa(gps_2011, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2013_class <- classify_clusters_with_pa(gps_2013, buffer_5km_before_2008,
                                            wdpa_from_2008)
gps_2016_class <- classify_clusters_with_pa(gps_2016, buffer_5km_before_2008,
                                            wdpa_from_2008)
gps_2021_class <- classify_clusters_with_pa(gps_2021, buffer_5km_before_2008,
                                            wdpa_from_2008)


gps_all_class_5km <- bind_rows(
  gps_1997_class,
  gps_2008_class,
  gps_2011_class,
  gps_2013_class,
  gps_2016_class,
  gps_2021_class
)

# Créer un plot pour visualiser la carte des AP avec les clusters----------------------
tm_shape(buffer_5km_from_2008) +
  tm_borders("green", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +  
  tm_shape(buffer_5km_before_2008) +
  tm_borders("darkgreen", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "green", 
              fill_alpha = 0.5,
              col = "black", 
              fill.legend = tm_legend(title = "à partir de 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "darkgreen", 
              fill_alpha = 0.5, 
              col =  "black", 
              fill.legend = tm_legend(title = "avant 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(gps_all_class_5km) +
  tm_symbols(
    fill = "groupe", 
    fill.legend = tm_legend(title = "Groupes"),
    fill.scale = tm_scale(values = c("Treatment" = "red", "Control" = "blue", "Excluded" = "gray")),
     size = 0.5,
    shape = 21
  ) +
  tm_facets("DHSYEAR") +
  tm_add_legend(type = "polygons", 
                fill = c("green", "darkgreen"), 
                labels = c("à partir de 2008", "avant 2008")) +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE
  ) +
  tm_scalebar(position = c("left", "bottom"))

# Tableau récapitulatif du nombre de grappes d'enquête classées dans chaque groupe-----
treated_sub_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  mutate(subcat = case_when(
    !is.na(STATUS_YR) & DHSYEAR <  STATUS_YR ~ "Avant traitement",
    !is.na(STATUS_YR) & DHSYEAR >= STATUS_YR ~ "Déjà traités",
    TRUE ~ NA_character_
  )) %>%
  count(DHSYEAR, subcat, name = "n_clusters") %>%
  pivot_wider(names_from = subcat, values_from = n_clusters, values_fill = 0)

# Ligne "Ensemble" (tous les traités, quel que soit le statut)
treated_all_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  count(DHSYEAR, name = "Ensemble")

# Colonnes Contrôles / Exclus
ctrl_excl_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe %in% c("Control", "Excluded")) %>%
  mutate(Groupe = recode(groupe, Control = "Contrôles", Excluded = "Exclus")) %>%
  count(DHSYEAR, Groupe, name = "n") %>%
  pivot_wider(names_from = Groupe, values_from = n, values_fill = 0)

# Assemblage large (années en lignes)
tab_wide_clusters <- list(treated_sub_clusters, treated_all_clusters, 
                          ctrl_excl_clusters) %>%
  Reduce(function(x, y) full_join(x, y, by = "DHSYEAR"), .) %>%
  arrange(DHSYEAR) %>%
  mutate(across(-DHSYEAR, ~replace_na(.x, 0L)))

# Tableau gt : spanner "Traitement" + colonnes Contrôles / Exclus
gt_table_clusters <- tab_wide_clusters %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de grappes par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des grappes *Traitement*."),
    locations = cells_title(groups = "title")
  )

gt_table_clusters

# Tableau récapitulatif du nombre de ménages d'enquête classées dans chaque groupe-----
load_dhs_data <- function(dhs_folder, year, identifier) {
  folder_pattern <- paste0(".*", year, ".*", identifier)
  
  matching_folder <- list.dirs(dhs_folder, full.names = TRUE, recursive = TRUE) %>%
    keep(~ str_detect(.x, folder_pattern))
  
  if (length(matching_folder) == 0) {
    stop("No folder found for the specified year and identifier.")
  }
  
  if (identifier == "GE") {
    file_pattern <- "\\.shp$"
    data_loader <- function(file) st_read(file, quiet = TRUE)
  } else {
    file_pattern <- "\\.[Dd][Tt][Aa]$"
    data_loader <- read_dta
  }
  
  target_file <- list.files(matching_folder, pattern = file_pattern, full.names = TRUE)
  
  if (length(target_file) == 0) {
    stop("No valid file found in the folder.")
  }
  
  data <- data_loader(target_file)
  
  return(data)
}

dhs_folder <- "data/raw/dhs"


# Années disponibles
years_all <- sort(unique(gps_all_class_5km$DHSYEAR))

# Compte ménages (toutes observations) 
households_counts_all <- map_dfr(years_all, function(y) {
  # HR de l'année
  hr <- load_dhs_data(dhs_folder, y, "HR") %>%
    mutate(DHSYEAR = y)  # pour la jointure avec la classification

  # Classification des grappes de l'année
  cl_y <- gps_all_class_5km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == y) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)

  # Jointure ménages <- classification (par cluster hv001)
  hr_cl <- hr %>%
    select(DHSYEAR, hv001) %>%
    left_join(cl_y, by = c("DHSYEAR" = "DHSYEAR", "hv001" = "DHSCLUST"))

  # Comptes par sous-catégories du traitement (DHSYEAR vs STATUS_YR)
  avant  <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR <  STATUS_YR) %>% nrow()
  deja   <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR >= STATUS_YR) %>% nrow()
  ens    <- hr_cl %>% filter(groupe == "Treatment") %>% nrow()
  ctrl   <- hr_cl %>% filter(groupe == "Control")   %>% nrow()
  excl   <- hr_cl %>% filter(groupe == "Excluded")  %>% nrow()

  tibble(
    DHSYEAR = y,
    `Avant traitement` = avant,
    `Déjà traités`     = deja,
    Ensemble           = ens,
    `Contrôles`        = ctrl,
    `Exclus`           = excl
  )
})

# Tableau gt (ménages, toutes observations)
gt_table_menages_all <- households_counts_all %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de ménages par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0, use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des ménages du groupe *Traitement*."), locations = cells_title(groups = "title"))

gt_table_menages_all   

# Sauvegarde des classifications des clusters 
all_class_5km <- gps_all_class_5km %>%
  select(DHSYEAR, DHSCLUST, GROUP = groupe, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

write_csv(all_class_5km, "data/derived/cluster_treatment_classification_staggered_5km.csv")

write_csv(wdpa_before_2008, "data/derived/wdpa_before_2008_5km.csv")
write_csv(wdpa_from_2008, "data/derived/wdpa_from_2008_5km.csv")

# Classification des clusters avec les données HR des ménages--------------------------- 
for(year in years_all) {
  hr_data <- load_dhs_data(dhs_folder, year, "HR") %>%
    mutate(DHSYEAR = year)
  
  cluster_class <- gps_all_class_5km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == year) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)
  
  hr_final_5km <- hr_data %>%
    rename(DHSCLUST = hv001) %>%
    left_join(cluster_class, by = c("DHSYEAR", "DHSCLUST")) %>%
    
    mutate(treatment = if_else(groupe == "Treatment", 1L, 0L),
           control = if_else(groupe == "Control", 1L, 0L))
  
  saveRDS(hr_final_5km, glue("data/derived/hr_{year}_final_5km.rds"))
    
}
```

#### Covariates Calculation

Nous chargeons les covariables à partir du package mapme.biodiversity.

```{r}
library(labelled) # Manipulation des labels
library(mapme.biodiversity)
library(progressr) # Pour avoir des barres de progression
library(tictoc) # Pour minuter le temps d'exécution
library(future) # Pour permettre du calcul parallèle

# Load data
buffer_all_5km <- gps_all_class_5km %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = 5000) %>%
  st_transform(standard_crs)

# Chargement des données géophysiques des ménages--------------------------------
# Définir le chemin relatif pour ton répertoire local

outdir <- "data/raw/mapme"
dir.create(outdir, recursive = TRUE, showWarnings = FALSE)
mapme_options(outdir = outdir, verbose = TRUE)


# Couvert forestier
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km  %>% 
    get_resources(get_gfw_treecover())
})
toc() # 1.25 sec elapsed 

# Perte de couvert
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_gfw_lossyear()) 
})
toc() # 1.15 sec elapsed 

# NASA SRTM
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_nasa_srtm()) 
})
toc() # 5.22 sec elapsed 

# Worldpop 2000
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>%
    get_resources(get_worldpop(years = 2000))
})
toc() # 0.22 sec elapsed 
  
# Accesibility
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_accessibility_2000()) 
})
toc() # 0.28 sec elapsed 

# Maximum temperatures
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_max_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 28.74 sec elapsed 

# Minimum temperatures
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_min_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 28.23 sec elapsed 

# Precipitations
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_precipitation(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 275.08 sec elapsed
  
```

Après chargement et extraction des données sur les données géophysiques des ménages, nous allons calculer les indicateurs des variables environnementales dans un rayon de 5 km autour de chaque grappe d'enquête.

```{r}
# Calcul des indicateurs------------------------------------------------------- 
if(file.exists("data/derived/spatial_covars_staggered_5km.rds")) {cat("Le fichier spatial_covars_staggered_5km.rds existe déjà")
} else {
    cat("Fichier introuvable, début du traitement... \n")
  
  # Créer un plan pour paralléliser les calculs
  plan(sequential)
  plan(multisession, workers = 4)
  
  # Maximum temperatures
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_temperature_max_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 34502.12 sec elapsed
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_max_temp.rds", compress = "gz")
  
  
  # Minimum temperatures
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
         calc_temperature_min_wc( engine = "extract", stats = "mean")
      )
  })
  toc() # 24445.67 sec elapsed 
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_min_temp.rds", compress = "gz")
  
  
  # Precipitations
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_precipitation_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # # 21007.7 sec elapsed 
 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_precip.rds", compress = "gz") 
  
  
  # Forest cover rate in 2000
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_treecover_area(years = 2000, min_size = 1, min_cover = 10)
      )
  })
  toc()   # 2392.16 sec elapsed
 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_treecover.rds", compress = "gz")
  
  
  # slope 
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_slope(engine = "extract", stats = "mean")
      )
  })
  toc() # 5995.94 sec elapsed  
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_slope.rds", compress = "gz")
  
  
  # Elevation
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_elevation(engine = "extract", stats = "mean")
      )
  })
  toc() # 2163.28 sec elapsed 
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_elevation.rds", compress = "gz")
  
  
  # Population density
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_population_count(engine = "extract", stats = "mean")
      )
  })
  toc() # 2134.34 sec elapsed
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_pop_density.rds", compress = "gz")
  
  
  # Accessibility
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_traveltime_2000(engine = "extract", stats = "mean")
      )
  })
  toc() # 2162.22 sec elapsed  
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_accessibility.rds", compress = "gz")
  
  # Enregistrement final des données 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_staggered_5km.rds")
 }
```

#### Spei calculation

Nous calculons ici l'évolution annuelle du SPEI, à l'échelle de 12 mois, pour un cluster pour la période de 1980 - 2021.

```{r}
library(SPEI) # Calcul de l'indice SPEI
library(labelled) # Manipulation des labels
library(tibbletime) # Manipulation des données temporelles 
library(zoo) # Manipulation des données temporelles 
library(readr) # Lecture des données de texte rectangulaires
library(ggplot2) # visualisation

# Load data 
spatial_covars_5km <- read_rds("data/derived/spatial_covars_staggered_5km.rds")

# Function to compute SPEI
compute_spei_annual <- function(tmin_tbl, tmax_tbl, prec_tbl, lat_deg) {
  # tmin_tbl/tmax_tbl/prec_tbl: tibbles avec colonnes `datetime` (Date) et `value` (num)
  d_tmin <- tibble(date = tmin_tbl$datetime, tmin = tmin_tbl$value)
  d_tmax <- tibble(date = tmax_tbl$datetime, tmax = tmax_tbl$value)
  d_prec <- tibble(date = prec_tbl$datetime, prec = prec_tbl$value)

  d_merged <- reduce(list(d_tmin, d_tmax, d_prec), left_join, by = "date") %>%
    arrange(date)

  d_clean <- drop_na(d_merged)  # supprime lignes avec NA

  # Si séries trop courtes, renvoyer squelette 1981:2021 en NA
  if (nrow(d_clean) < 12) {
    return(tibble(year = 1981:2021, spei_mean = NA_real_))
  }

  # PET (Hargreaves), bilan hydrique et SPEI mensuel
  pet <- hargreaves(Tmin = d_clean$tmin,
                    Tmax = d_clean$tmax,
                    Pre  = d_clean$prec,
                    lat  = lat_deg)

  wb <- d_clean$prec - pet

  wb_ts <- ts(wb,
              start = c(year(min(d_clean$date)), month(min(d_clean$date))),
              frequency = 12)

  spei_obj <- spei(wb_ts,
                   scale = 12,
                   ref.start = c(1981, 1),
                   ref.end   = c(2021, 12))

  tibble(datetime = d_clean$date,
         spei      = as.numeric(spei_obj$fitted)) %>%
    filter(datetime >= as.Date("1981-01-01"),
           datetime <= as.Date("2021-12-31")) %>%
    mutate(year = year(datetime)) %>%
    group_by(year) %>%
    summarise(spei_mean = mean(spei, na.rm = TRUE), .groups = "drop") %>%
    complete(year = 1981:2021, fill = list(spei_mean = NA_real_))
}

# Latitude géodésique depuis la géométrie (centroïde)
spatial_covars_spei_5km <- spatial_covars_5km %>%
  mutate(lat = st_coordinates(st_centroid(geometry))[, 2])

row1 <- spatial_covars_spei_5km[1, ]

spei_tbl_one <- compute_spei_annual(
  tmin_tbl = row1$temperature_min_wc[[1]],
  tmax_tbl = row1$temperature_max_wc[[1]],
  prec_tbl = row1$precipitation_wc[[1]],
  lat_deg  = row1$lat
)

# Graphique 
spei_2017 <- spei_tbl_one %>% 
  filter(year == 2017)

ggplot(spei_tbl_one, aes(x = year, y = spei_mean)) +
  geom_col(aes(y = pmax(0, -spei_mean)), alpha = 0.25) +  # barres pour sécheresse (optionnel)
  geom_line(linewidth = 0.8) +
  geom_vline(xintercept = 2017, color = "red", linetype = "dotted", linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label(
    data = spei_2017, 
    aes(x = 2017, y = spei_mean, 
        label = paste0("Année: 2017\nSPEI: ", round(spei_mean, 2))),
    nudge_x = 1, 
    nudge_y = 0.3,
    fill = "white",
    color = "black",
    linewidth = 0.4, 
    label.padding = unit(0.2, "lines")
  ) +
  
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI (scale=12) – cluster de démonstration",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# SPEI for all clusters 
spatial_covars_spei_5km <- spatial_covars_spei_5km %>%
  mutate(
    spei_wc = pmap(
      list(temperature_min_wc, temperature_max_wc, precipitation_wc, lat),
      ~ compute_spei_annual(..1, ..2, ..3, ..4)
    )
  )

spei_df <- spatial_covars_spei_5km %>%
  select(DHSCLUST, spei_wc) %>%
  unnest(spei_wc)

ggplot(spei_df, aes(x = year, y = spei_mean, group = DHSCLUST)) +
  geom_line(alpha = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI by cluster with 5 km buffer (1981–2021)",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# Chaque élément spei_wc devient une table {datetime, variable, unit, value}
spatial_covars_spei_5km <- spatial_covars_spei_5km %>%
  mutate(
    spei_wc = map(spei_wc, ~ .x %>%
      mutate(
        datetime = as.Date(paste0(.data$year, "-01-01")),
        variable = "spei_scale12_mean",
        unit     = "annual",
        value    = .data$spei_mean
      ) %>%
      select(datetime, variable, unit, value))
  )

# Sauvegarde (cohérente avec le reste de tes scripts)
spatial_covars_spei_df_5km <- as.data.frame(spatial_covars_spei_5km)
write_rds(spatial_covars_spei_df_5km, "data/derived/spatial_covars_spei_staggered_5km.rds")
cat("SPEI (annuel, 1981–2021) enregistré dans data/derived/spatial_covars_spei_staggered_5km.rds\n")
```

Dans l'ensemble, la série oscille autour de zéro, alternant des périodes humides et sèches. On observe toutefois plusieurs épisodes de sécheresse importante à la fin des années 1980. En 2017, le SPEI a une valeur particulièrement basse (SPEI = -2.25), qui d'après la classification de Vicente-Serrano et al. @2010 caractérise une sécheresse très sévère.

#### Variable consolidation

Nous combinons les clusters de 1997, 2008, 2011, 2013, 2016 et 2021 avec leurs caractéristiques géophysiques et leur variable de résultat respectif dans un seul dataframe.

```{r}

library(lubridate)

# Covariates spatio-temporelles + classification de traitement
spatial_covars_spei_5km <- readRDS("data/derived/spatial_covars_spei_staggered_5km.rds")
all_covars <- spatial_covars_spei_5km %>%
  select(DHSYEAR, DHSCLUST, URBAN_RURA, treecover_area, slope, elevation,
         population_count, traveltime_2000, spei_wc)

all_class_5km <- read.csv("data/derived/cluster_treatment_classification_staggered_5km.csv")

# Helper: fabrique la table finale pour une année donnée
vars_to_nest <- c("treecover_area", "slope", "elevation",
                  "population_count", "traveltime_2000", "spei_wc")

build_year <- function(hr_object,
                       year,
                       hh_rural_path,
                       spei_years = (year-2):year) {

  # Charger HR (identifiants + variables chef) et HH_rural (centiles/zscore déjà calculés)
  hr <- hr_object %>%
    dplyr::select(hv001, hv002, hv219, hv220)
  
  hh_rural <- read_rds(hh_rural_path) # contient hv001/hv002 + wealth_* déjà prêts
  
  # Joindre covariates spatiaux + classification de groupes
  base <- hh_rural %>%
    left_join(hr, by = c("hv001", "hv002")) %>%
    left_join(
      all_covars %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    left_join(
      all_class_5km %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    mutate(DHSYEAR = year) %>%
    relocate(DHSYEAR, .before = everything())
  
  # Désimbriquer les covars imbriquées et appliquer la fenêtre temporelle SPEI
  #    moyenne par (hv001, hv002) pour chaque indicateur_année
  df_long <- base %>%
    select(hv001, hv002, any_of(vars_to_nest)) %>%
    pivot_longer(cols = any_of(vars_to_nest),
                 names_to = "indicator", values_to = "data") %>%
    unnest(data) %>%
    filter(indicator != "spei_wc" | year(datetime) %in% spei_years) %>%
    mutate(year_indicator = paste0(indicator, "_", year(datetime))) %>%
    select(hv001, hv002, year_indicator, value)
  
  df_wide <- df_long %>%
    pivot_wider(names_from = year_indicator, values_from = value,
                names_glue = "{year_indicator}") %>%
    group_by(hv001, hv002) %>%
    summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
  
  # Table finale (une ligne par ménage hv001/hv002)
  out <- base %>%
    select(-any_of(vars_to_nest)) %>%
    distinct(hv001, hv002, .keep_all = TRUE) %>%
    left_join(df_wide, by = c("hv001", "hv002"))
  
  out
}

# Application

hr_1997_final_5km <- read_dta("data/raw/dhs/DHS_1997/MDHR31DT/MDHR31FL.DTA") %>%
  build_year(year = 1997,
             hh_rural_path = "data/derived/hh_1997_rural_simpler.rds",
             spei_years = 1995:1997)

hr_2008_final_5km <- read_dta("data/raw/dhs/DHS_2008/MDHR51DT/MDHR51FL.DTA") %>%
  build_year(year = 2008,
             hh_rural_path = "data/derived/hh_2008_rural_simpler.rds",
             spei_years = 2006:2008)

hr_2011_final_5km <- read_dta("data/raw/dhs/DHS_2011/MDHR61DT/MDHR61FL.DTA") %>%
  build_year(year = 2011,
             hh_rural_path = "data/derived/hh_2011_rural_simpler.rds",
             spei_years = 2009:2011)

hr_2013_final_5km <- read_dta("data/raw/dhs/DHS_2013/MDHR6ADT/MDHR6AFL.DTA") %>%
  build_year(year = 2013,
  hh_rural_path = "data/derived/hh_2013_rural_simpler.rds",
  spei_years = 2011:2013)

hr_2016_final_5km <- read_dta("data/raw/dhs/DHS_2016/MDHR71DT/MDHR71FL.DTA") %>%
  build_year(year = 2016,
  hh_rural_path = "data/derived/hh_2016_rural_simpler.rds",
  spei_years = 2014:2016)

hr_2021_final_5km <- read_dta("data/raw/dhs/DHS_2021/MDHR81DT/MDHR81FL.DTA") %>%
  build_year(year = 2021,
  hh_rural_path = "data/derived/hh_2021_rural_simpler.rds",
  spei_years = 2019:2021)

# Consolidation

hr_consolidated_5km <- bind_rows(
  hr_1997_final_5km,
  hr_2008_final_5km,
  hr_2011_final_5km,
  hr_2013_final_5km,
  hr_2016_final_5km,
  hr_2021_final_5km
)

hr_consolidated_5km %>% count(DHSYEAR)

# Sauvegardes millésime
write_rds(hr_1997_final_5km, "data/derived/hr_1997_final_5km.rds")
write_rds(hr_2008_final_5km, "data/derived/hr_2008_final_5km.rds")
write_rds(hr_2011_final_5km, "data/derived/hr_2011_final_5km.rds")
write_rds(hr_2013_final_5km, "data/derived/hr_2013_final_5km.rds")
write_rds(hr_2016_final_5km, "data/derived/hr_2016_final_5km.rds")
write_rds(hr_2021_final_5km, "data/derived/hr_2021_final_5km.rds")

# Sauvegarde consolidée
write_rds(hr_consolidated_5km, "data/derived/hr_consolidated_5km_1997_2008_2011_2013_2016_2021.rds")
cat("Données enregistrées\n")
```

#### Matching

Nous appliquons la méthode de matching pour rendre comparable les groupes traités et contrôles, en les appariant selon cinq caractéristiques environnementales dans un rayon de 5 km.

```{r}
# Library 
library(rbounds) # Analyse de sensibilité
library(MatchIt)
library(rgenoud) # Implementation de l'algorithme génétique
library(Matching) # Estimation des effets de traitement causaux
library(progressr) # Suivi de progression
library(rlang)
library(car)
library(tibble)
library(qqplotr) # pour créer la bande de confiance
library(halfmoon)
library(cobalt)
library(ggpubr)

matching_variables <- c(
  "treecover_area_2000","slope_2000","elevation_2000",
  "population_count_2000","traveltime_2000_2000"
)

prep_matching <- function(df_final) {
  out <- df_final %>%
    filter(GROUP %in% c("Treatment","Control")) %>%
    mutate(treatment = if_else(GROUP == "Treatment", 1L, 0L))
  
  missing_cols <- setdiff(matching_variables, names(out))
  if (length(missing_cols) > 0) {
    message(">> Colonnes manquantes: ", paste(missing_cols, collapse=", "))
  }
  
  out %>% drop_na(all_of(intersect(matching_variables, names(out))))
}

# supprimer toute ancienne version pour éviter le masquage
if (exists("run_matching_year")) rm(run_matching_year)

run_matching_year <- function(year, overwrite = list(gen=FALSE, match=FALSE)) {
  cat("\n=== Matching", year, "===\n")
  fin_path <- glue("data/derived/hr_{year}_final_5km.rds")
  if (!file.exists(fin_path)) stop("Fichier introuvable: ", fin_path)
  
  dat   <- readRDS(fin_path)
  dat_m <- prep_matching(dat)
  
  
  n_total <- nrow(dat)
  n_filt <- nrow(dat_m)
  n_treat <- sum(dat_m$treatment == 1, na.rm = TRUE)
  n_ctrl <- sum(dat_m$treatment == 0, na.rm = TRUE)
  
  
  cat(glue(">> N total={n_total}, après filtre/NA={n_filt}; ",
           "Traités={n_treat}, ",
           "Contrôles={n_ctrl}\n"))
  
  have_all_vars <- all(matching_variables %in% names(dat_m))
  cat(">> Toutes les covars présentes ? ", have_all_vars, "\n")
  if (n_filt < 5 || !have_all_vars) {
    warning(glue("Année {year}: données insuffisantes ou variables manquantes — on saute."))
    return(NULL)
  }
  
  X_match <- dat_m %>%
    sf::st_drop_geometry() %>%
    dplyr::select(all_of(matching_variables)) %>%
    as.data.frame()
  
  gen_path         <- glue("data/derived/gen_match_model_{year}_5km.rds")
  match_path       <- glue("data/derived/matching_result_{year}_5km.rds")
  matched_out_path <- glue("data/derived/data_matched_{year}_5km.rds")
  
  # --- GenMatch ---
  used_cache_gen <- FALSE
  t0 <- Sys.time()
  if (file.exists(gen_path) && !isTRUE(overwrite$gen)) {
    cat(">> GenMatch: cache trouvé -> lecture\n")
    gen_model <- readRDS(gen_path)
    used_cache_gen <- TRUE
  } else {
    cat(">> GenMatch: calcul en cours...\n")
    gen_model <- GenMatch(
      Tr = dat_m$treatment,
      X  = X_match,
      BalanceMatrix = X_match,
      estimand = "ATT",
      M = 1,
      weights = NULL,
      pop.size = 1000,
      max.generations = 100,
      wait.generations = 4,
      caliper = .25,
      print.level = 1,
      cluster = rep("localhost", 4)
    )
    saveRDS(gen_model, gen_path)
  }
  t_gen <- as.numeric(difftime(Sys.time(), t0, units="mins"))
  cat(glue(">> GenMatch temps = {round(t_gen,1)} min (cache={used_cache_gen})\n"))
  
  # --- matchit() ---
  used_cache_match <- FALSE
  t1 <- Sys.time()
  if (file.exists(match_path) && !isTRUE(overwrite$match)) {
    cat(">> matchit: cache trouvé → lecture\n")
    m_out <- readRDS(match_path)
    used_cache_match <- TRUE
  } else {
    cat(">> matchit: calcul en cours...\n")
    fml <- as.formula(paste("treatment ~", paste(matching_variables, collapse=" + ")))
   
    
     m_out <- matchit(
      formula   = fml,
      data      = dat_m,
      method    = "genetic",
      distance  = "mahalanobis",
      gen.match = gen_model
    )
     
    saveRDS(m_out, match_path)
  }
  
  matched <- match.data(m_out, data = sf::st_drop_geometry(dat_m)) %>%
    dplyr::filter(weights > 0)
  
  saveRDS(matched, matched_out_path)
  cat(glue(">> N appariés = {nrow(matched)} (écrit: {matched_out_path})\n"))
  
  
  tibble(
    Année = year,
    'Total des observations' = n_total,
    'Après filtre/NA' = n_filt,
    Traités = n_treat,
    Contrôles = n_ctrl,
    'N appariés' = nrow(matched)
  )
}

need_overwrite <- function(year) {
  gen_path   <- glue("data/derived/gen_match_model_{year}_5km.rds")
  match_path <- glue("data/derived/matching_result_{year}_5km.rds")
  list(gen = !file.exists(gen_path), match = !file.exists(match_path))
}

# --- Exécution avec progression ---
yrs <- c(1997, 2008, 2011, 2013, 2016, 2021)


res_list <- vector("list", length(yrs))
names(res_list) <- yrs

with_progress({
  p <- progressor(along = yrs)

for (i in seq_along(yrs)) {
  yr <- yrs[i]
  ow <- need_overwrite(yr) 
  cat(glue("\n>> overwrite {yr}: gen={ow$gen}, match={ow$match}\n"))
  cat(sprintf("Start %s", yr))
  t_all <- Sys.time()
  res_list[[i]] <- tryCatch(
    run_matching_year(yr, overwrite = ow),
    error = function(e) { warning(glue("Year {yr} ERROR: {e$message}")); NULL }
  )
  cat(sprintf("Done %s (%.1f min)",
            yr, as.numeric(difftime(Sys.time(), t_all, units="mins"))))
}
})

result_list <- purrr::compact(res_list) |> bind_rows()
saveRDS(result_list, "data/derived/matching_summary_all_years_5km.rds")

bal_tabs <- purrr::imap(res_list, ~ {if (!is.null(.x)) {
  tryCatch(cobalt::bal.tab(.x$m), error = function(e) NULL) } else {
    NULL
  }
})

saveRDS(bal_tabs, "data/derived/matching_balance_tabs_all_years_5km.rds")

print(result_list)
```

Après le matching, nous obtenons:

-   1997: 5124 groupes appariées dont 624 traités et 4141 contrôles

-   2008: 13364 groupes appariées dont 1266 traités et 11221 contrôles

-    2011: 6025 groupes appariées dont 528 traités et 5076 contrôles

-   2013: 6375 groupes appariées dont 874 traités et 5092 contrôles

-   2016: 9295 groupes appariées dont 863 traités et 7933 contrôles

-    2021: 15364 groupes appariées dont 1806 traités et 12487 contrôles

##### Checking covariate balance: test before matching

Nous allons vérifier l'équilibre relatif des variables mesurées dans des unités différentes avant le matching pour mesurer l'écart entre les moyennes des covariables dans les groupes de traitement et de contrôle pour un buffer de 5 km.

```{r}
# Load 
hr_list <- setNames(
  lapply(yrs, function(y) read_rds(paste0("data/derived/hr_", y, "_final_5km.rds"))),
  yrs
)

# Equilibre des covariables
check_balance_before <- function(df, year, matching_variables) {
  
  data <- df %>%
    filter(GROUP %in% c("Treatment", "Control")) %>%
    mutate(treatment = if_else(GROUP == "Treatment", 1, 0))

  formula <- reformulate(matching_variables, response = "treatment")
  
  # Balance avant appariement
  bal_before <- bal.tab(
    formula,
    data = data,
    estimand = "ATT",
    un = TRUE,
    abs = TRUE
  )
  
  # Extraction du Standardized Mean Difference (SMD)
 balance_df <- bal_before$Balance %>%
    as.data.frame() %>%
    tibble::rownames_to_column("Variable")

  smd_col <- grep("Diff|Std", names(balance_df), value = TRUE)[1]

  smd_table <- balance_df %>%
    dplyr::select(Variable, SMD = all_of(smd_col)) %>%
    mutate(
      Year = year,
      Equilibre = if_else(abs(SMD) <= 0.1, "Équilibré", "Déséquilibré")
    ) %>%
    relocate(Year)

  return(smd_table)
}

balance_results <- lapply(names(hr_list), function(y) {
  check_balance_before(hr_list[[y]], as.numeric(y), matching_variables)
})

balance_results <- bind_rows(balance_results)

balance_results

# Distribution des covariables
data_list <- list(
  "1997" = hr_1997_final_5km,
  "2008" = hr_2008_final_5km,
  "2011" = hr_2011_final_5km,
  "2013" = hr_2013_final_5km,
  "2016" = hr_2016_final_5km,
  "2021" = hr_2021_final_5km 
)


  density_plot <- function(data, year, matching_variables){
    data %>%
      filter(GROUP %in% c("Treatment", "Control")) %>%
      mutate(GROUP =factor(GROUP, levels = c("Control", "Treatment"))) %>%
    pivot_longer(cols = all_of(matching_variables), names_to = "variable", values_to = "value") %>%
    ggplot(aes(x = value, fill = GROUP)) +
    geom_density(alpha = 0.5, color = "black", linewidth = 0.7, adjust = 0.7) +
    facet_wrap(~variable, scales = "free") + 
    scale_fill_manual(values = c("Control" = "green", "Treatment" = "blue")) +
    labs(
      title = paste("Covariate distribution before matching(", year, ")", sep = ""),
      x = "Valeur de la covariable",
      y = "Densité",
      fill = "Group"
    ) + 
    theme_minimal()
  }
    
print(density_plot(hr_1997_final_5km, 1997, matching_variables))
print(density_plot(hr_2008_final_5km, 2008, matching_variables))
print(density_plot(hr_2011_final_5km, 2011, matching_variables))
print(density_plot(hr_2013_final_5km, 2013, matching_variables))
print(density_plot(hr_2016_final_5km, 2016, matching_variables))
print(density_plot(hr_2021_final_5km, 2021, matching_variables))
```

L'analyse de l'équilibre avant appariement montre que, pour la plupart des années, les différences moyennes standardisées entre les groupes traités et contrôles restent inférieures au seuil de 0.1, indiquant un bon équilibre. En 1997, toutes les covariables présentent un bon équilibre, seule la variable population_count_2000 demeure déséquilibrer (Diff.Un = 0.2107). L'année 2008 affiche l'équilibre les plus satisfaisant, avec des différences quasi nulles pour toutes les covariables. En 2011 et 2013, l'équilibre demeure globalement correct, toutefois la variable population_count_2000 reste légèrement déséquilibrée avec une différence standardisée de 0.1352 pour 2011 et 0.0903 pour 2013. L'année 2016 constitue le cas le plus problématiques pour plusieurs covariables, la variable treecover_ara_2000 (Diff.Un = 0.1113) et population_count_2000 (Diff.Un = 0.1457) dépassant le seuil de 0.1. En revanche, pour 2021, la différence standardisée pour toutes les covariables est inférieure à 0.1.

Nous testons ensuite l'équilibre après l'appariement pour chaque covariable d'appariement.

##### Checking covariate balance: test after matching

```{r}
# Balance test after matching: Quantile- quantile QQ Plot analysis
check_balance_after <- function(data_matched, year, matching_variables, plot_dir = "plots") {
  
  # Balance après appariement
  bal_after <- cobalt::bal.tab(
    x = data_matched[, matching_variables],
    treat = data_matched$GROUP,
    un = TRUE,
    abs = TRUE,
    estimand = "ATT"
  )
  
  print(bal_after)
  
  # QQ Plot
  year_dir <- file.path(plot_dir, paste0("QQplots_", year))
  if (!dir.exists(year_dir)) dir.create(year_dir, recursive = TRUE)
  

  for (var in matching_variables) {
    if (!is.numeric(data_matched[[var]])) {
    }
    
    
    control_values <- data_matched %>% filter(GROUP == "Control") %>% pull(var) %>% na.omit()
    treated_values <- data_matched %>% filter(GROUP == "Treatment") %>% pull(var) %>% na.omit()
    
    p <- ggqqplot(data_matched, x = var, color = "GROUP", palette = c("#1f77b4", "#ff7f0e"),
                  title = paste("QQ Plot -", var, "(", year, ")")) +
      geom_abline(slope = 1, intercept = 0, linetype = "dashed", size = 0.7, color = "black") +
      theme_minimal() +
      labs(x = "Quantiles théoriques", y = "Quantiles observés", color = "Groupe") +
      theme(plot.title = element_text(hjust = 0.5))
    
    # Sauvegarde du graphique
    ggsave(
      filename = file.path(year_dir, paste0("QQplot_", var, "_", year, ".png")),
      plot = p, width = 7, height = 5
    )
  }
  
  return(list(balance = bal_after))
}


res_after_1997_5km <- check_balance_after(data_matched_1997_5km, 1997, matching_variables)
res_after_2008_5km <- check_balance_after(data_matched_2008_5km, 2008, matching_variables)
res_after_2011_5km <- check_balance_after(data_matched_2011_5km, 2011, matching_variables)
res_after_2013_5km <- check_balance_after(data_matched_2013_5km, 2013, matching_variables)
res_after_2016_5km <- check_balance_after(data_matched_2016_5km, 2016, matching_variables)
res_after_2021_5km <- check_balance_after(data_matched_2021_5km, 2021, matching_variables)

# Balance test after matching: Histogram
plot_mirror_hist_5km <- function(year, variable){
  
 df <- readRDS(glue("data/derived/data_matched_{year}.rds")) %>%
   filter(GROUP %in% c("Treatment", "Control")) %>%
   mutate(
     treatment = ifelse(GROUP == "Treatment", "Traité", "Contrôle"), 
     value = .data[[variable]]
   )
 
 treated <- df %>% filter(treatment == "Traité")
 control <- df %>% filter(treatment == "Contrôle")
 
 
 ggplot() +
   geom_histogram(
     data = treated, 
     aes(x = value), 
     bins = 30, 
     fill = "blue", 
     alpha = 0.6
     ) + 
 geom_histogram(
   data = control, 
   aes(x = value, y = -after_stat(count)),
   bins = 30, 
   fill = "green", 
   alpha = 0.6
   ) + 
   labs(
     title = glue("Covariate after matching - {variable} ({year})"),
     x = variable, 
     y = "Effectifs (+ Traités / - Contrôles)"
     ) + 
   geom_hline(yintercept = 0, color = "black") +
   annotate("text", x = Inf, y = -Inf, label = "Traités", hjust = 1.1, vjust = 2, color = "blue") +
   annotate("text", x = Inf, y = -Inf, label = "Contrôles", hjust = 1.1, vjust = -1.5, color = "green") +
   theme_minimal()
 
}

plot_mirror_hist_5km(1997,"treecover_area_2000")
plot_mirror_hist_5km(2008,"treecover_area_2000")
plot_mirror_hist_5km(2011,"treecover_area_2000")
plot_mirror_hist_5km(2013,"treecover_area_2000")
plot_mirror_hist_5km(2016,"treecover_area_2000")
plot_mirror_hist_5km(2021,"treecover_area_2000")
plot_mirror_hist_5km(1997,"slope_2000")
plot_mirror_hist_5km(2008,"slope_2000")
plot_mirror_hist_5km(2011,"slope_2000")
plot_mirror_hist_5km(2013,"slope_2000")
plot_mirror_hist_5km(2016,"slope_2000")
plot_mirror_hist_5km(2021,"slope_2000")
plot_mirror_hist_5km(1997,"elevation_2000")
plot_mirror_hist_5km(2008,"elevation_2000")
plot_mirror_hist_5km(2011,"elevation_2000")
plot_mirror_hist_5km(2013,"elevation_2000")
plot_mirror_hist_5km(2016,"elevation_2000")
plot_mirror_hist_5km(2021,"elevation_2000")
plot_mirror_hist_5km(1997,"population_count_2000")
plot_mirror_hist_5km(2008,"population_count_2000")
plot_mirror_hist_5km(2011,"population_count_2000")
plot_mirror_hist_5km(2013,"population_count_2000")
plot_mirror_hist_5km(2016,"population_count_2000")
plot_mirror_hist_5km(2021,"population_count_2000")
plot_mirror_hist_5km(1997,"traveltime_2000_2000")
plot_mirror_hist_5km(2008,"traveltime_2000_2000")
plot_mirror_hist_5km(2011,"traveltime_2000_2000")
plot_mirror_hist_5km(2013,"traveltime_2000_2000")
plot_mirror_hist_5km(2016,"traveltime_2000_2000")
plot_mirror_hist_5km(2021,"traveltime_2000_2000")
```

#### Estimation

##### Overall effect on livelihoods

```{r}
# 2X2 DiD----------------------------------------------
library(fixest)
library(didimputation)
library(broom)

# Chargement des données
d97_5km <- read_rds("data/derived/data_matched_1997_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_1995,
         spei_wc_n_1 = spei_wc_1996,
         spei_wc_n   = spei_wc_1997) %>%
  mutate(hv219 = zap_labels(hv219), # hhh sex (1/2)
         hv220 = zap_labels(hv220)) # hhh age (num)

d08_5km <- read_rds("data/derived/data_matched_2008_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2006,
         spei_wc_n_1 = spei_wc_2007,
         spei_wc_n   = spei_wc_2008) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d11_5km <- read_rds("data/derived/data_matched_2011_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2009,
         spei_wc_n_1 = spei_wc_2010,
         spei_wc_n   = spei_wc_2011) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d13_5km <- read_rds("data/derived/data_matched_2013_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2011,
         spei_wc_n_1 = spei_wc_2012,
         spei_wc_n   = spei_wc_2013) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d16_5km <- read_rds("data/derived/data_matched_2016_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2014,
         spei_wc_n_1 = spei_wc_2015,
         spei_wc_n   = spei_wc_2016) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d21_5km <- read_rds("data/derived/data_matched_2021_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2019,
         spei_wc_n_1 = spei_wc_2020,
         spei_wc_n   = spei_wc_2021) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

# Préparation des données
dat_5km <- bind_rows(d97_5km, d08_5km, d11_5km, d13_5km, d16_5km, d21_5km) %>%
  filter(GROUP %in% c("Treatment","Control")) %>%
  mutate(
    hv219   = factor(hv219, levels = c(1,2), labels = c("Homme","Femme")), # sexe (cat.)
    hv220   = as.numeric(hv220),                                           # âge
    treat   = as.integer(GROUP == "Treatment"),
    w_svy   = hv005 / 1e6,
    w_all   = w_svy * weights, # poids d'enquête × poids de matching (si 'weights' existe)
    id      = row_number(),
    # Map des années de statut -> première année d'observation post (treatment_phase)
    treatment_phase = case_when(
      STATUS_YR == 2010 ~ 2011,
      STATUS_YR == 2012 ~ 2013,
      STATUS_YR == 2015 ~ 2016,
      STATUS_YR == 2017 ~ 2021,
      is.na(STATUS_YR)  ~ 0,
      TRUE               ~ STATUS_YR
    )
  )

# Outcome h
yvar <- "wealth_centile_rural_weighted"

# fixest DID 2×2: placebo 1997–2008, traitement 2008–2021 ------------------

# Placebo 1997–2008
pre_5km <- dat_5km %>%
  filter(DHSYEAR %in% c(1997, 2008)) %>%
  mutate(post = as.integer(DHSYEAR == 2008),
         treat_post = treat * post)

f_pre <- as.formula(paste(
  yvar, "~ treat + post + treat_post +",
  "spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220"
))

m_pre <- feols(f_pre, data = pre_5km, weights = ~ w_all, cluster = ~ hv001)

# Traitement 2008–2021
main <- dat_5km %>%
  filter(DHSYEAR %in% c(2008, 2021)) %>%
  mutate(post = as.integer(DHSYEAR == 2021),
         treat_post = treat * post)

f_main <- f_pre  # même formule

m_main <- feols(f_main, data = main, weights = ~ w_all, cluster = ~ hv001)

etable(m_pre, m_main, headers = c("Placebo 97–08", "Traitement 08–21"))

# Extraction compacte des deux effets DID
did_row <- function(model, year_post, vc = ~ hv001, term = "treat_post"){
  summary(model, vcov = vc) %>% broom::tidy() %>%
    filter(term == !!term) %>%
    transmute(year = year_post, estimate, se = std.error)
}
did_df <- bind_rows(
  did_row(m_pre, 2008),
  did_row(m_main, 2021)
) %>%
  mutate(period = factor(ifelse(year == 2008, "1997–2008", "2008–2021"),
                         levels = c("1997–2008", "2008–2021")),
         lo = estimate - 1.96*se,
         hi = estimate + 1.96*se)

ggplot(did_df, aes(x = period, y = estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_errorbar(aes(ymin = lo, ymax = hi), width = .2) +
  geom_point(size = 3) +
  labs(x = NULL, y = "Effet DID sur le centile de richesse (pondéré)",
       title = "DID 2×2 avec IC clusterisés (hv001)")


# Staggered diff-in-diff----------------------------------------
# did2s (Gardner) : statique + event-study--------------------------------
library(did2s)

dat3 <- dat_5km %>%
  mutate(
    treat_on = as.integer(treatment_phase > 0 & DHSYEAR >= treatment_phase),
    rel_year = if_else(treatment_phase > 0, DHSYEAR - treatment_phase, Inf),
    # Binning prudent pour stabilité (-5..5)
    rel_year_binned = pmax(pmin(rel_year, 5), -5)
  )

# -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(treat_on, ref = FALSE),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static, headers = "did2s statique")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(rel_year_binned, ref = c(-1, Inf)),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es, headers = "did2s event-study (-5..5)")

# Plot ES did2s
plot_did2s <- broom::tidy(did2s_es, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(k = as.numeric(sub("^rel_year_binned::", "", term))) %>%
  arrange(k)

ggplot(plot_did2s, aes(k, estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s)")

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present <- plot_did2s$k[plot_did2s$k < 0]
if(length(leads_present) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present, collapse="|"), ")$")
  print(fixest::wald(did2s_es, keep = keep_regex))
}
```

##### Effect on inequalities

```{r}
# Staggered DiD-----------------------------------------
yvar <- "zscore_wealth"

# did2s (Gardner) : statique + event-study--------------------------------
# -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(treat_on, ref = FALSE),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static, headers = "did2s statique")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(rel_year_binned, ref = c(-1, Inf)),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es, headers = "did2s event-study (-5..5)")

# Plot ES did2s
plot_did2s <- broom::tidy(did2s_es, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(k = as.numeric(sub("^rel_year_binned::", "", term))) %>%
  arrange(k)

ggplot(plot_did2s, aes(k, estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s)")

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present <- plot_did2s$k[plot_did2s$k < 0]
if(length(leads_present) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present, collapse="|"), ")$")
  print(fixest::wald(did2s_es, keep = keep_regex))
}

# Quantile treatment effects
# Testing Quantile treatment effect------------------------------
library(qte)

# Avec CiC -------------------

## Traitement 2008 -> 2021
set.seed(123)
dat_2per <- dat_5km %>%
  filter(DHSYEAR %in% c(2008, 2021)) %>%
  mutate(treat = as.integer(GROUP == "Treatment"))

cic_res <- suppressWarnings(CiC(
  formla = wealth_centile_rural_weighted ~ treat,
  t = 2021, tmin1 = 2008, tname = "DHSYEAR",
  data = dat_2per,
  panel = FALSE, # repeated cross-sections
  se = TRUE, iters = 200, # bootstrap
  probs = seq(0.05, 0.95, 0.05),
  xformla = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220
))

summary(cic_res)
ggqte(cic_res) + labs(x="Quantiles", y="QTET", title="CiC QTET: 2008-2021")

## placebo------------------------------------------------------

## Placebo: 1997 -> 2008
dat_placebo <- dat_5km %>%
  filter(DHSYEAR %in% c(1997, 2008)) %>%
  mutate(treat = as.integer(GROUP == "Treatment"))

# (Optional) sanity check:
# with(dat_placebo, table(DHSYEAR, treat))

cic_pre <-  suppressWarnings(CiC(
  formla = wealth_centile_rural_simple ~ treat,
  t = 2008, tmin1 = 1997, tname = "DHSYEAR",
  data = dat_placebo,
  panel = FALSE, # repeated cross-sections
  se = TRUE, iters = 100, # bootstrap
  probs = seq(0.05, 0.95, 0.05),
  xformla = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220
))

summary(cic_pre)

ggqte(cic_pre) +
  labs(x = "Quantiles", y = "QTET",
       title = "Placebo CiC QTET: 1997-2008")
```

##### Heterogeneity

```{r}
# Création du groupe IUCN 
dat3 <- dat3 %>%
  filter(!is.na(IUCN_CAT), !is.na(treat_on)) %>%
  mutate(
    IUCN_group = case_when(
    IUCN_CAT %in% c("Ia", "Ib", "II", "III", "IV") ~ "strict",
    IUCN_CAT %in% c("V", "VI") ~ "usage_multiple", 
    TRUE ~ NA_character_
  ),
  IUCN_group = factor(IUCN_group, levels = c("strict", "usage_multiple")),
  rel_year_binned = factor(rel_year_binned, levels = -5:5)
  ) %>%
  filter(!is.na(IUCN_group))

run_did2s_es <- function(data, yvar) {
  
  # -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = data,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ treat_on * IUCN_group,
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
print(etable(did2s_static, headers = paste("did2s statique -", yvar)))
  
}

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data = data,
  yname = yvar, 
  first_stage = ~ spei_wc_n_2 +  spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage = ~ 
    i(rel_year_binned, ref = -1) +
    i(rel_year_binned, IUCN_group),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
print(etable(did2s_es, headers = paste("did2s event-study (-5..5) par statut IUCN", yvar)))

tidy_es <- broom::tidy(did2s_es, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(
    year = as.numeric(sub("rel_year_binned::(-?\\d+).*", "\\1", term)),
    type = case_when(
      grepl("IUCN_group::usage_multiple", term) ~ "diff_usage_multiple",
      TRUE ~ "strict"
    )
  )

# Effet pour les AP stricts
strict_effect <- tidy_es %>%
  filter(type == "strict") %>%
  transmute(
    year, estimate, conf.low, conf.high, group = "strict")

# Effet total pour AP à usage multiple
usage_effect <- tidy_es %>%
  filter(type == "diff_usage_multiple") %>%
  rename(
    estimate_diff = estimate,
    conf.low_diff = conf.low,
    conf.high_diff = conf.high) %>%
  left_join(strict_effect, by = "year") %>%
  mutate(
    estimate = estimate + estimate_diff,
    conf.low = conf.low + conf.low_diff,
    conf.high = conf.high + conf.high_diff,
    group = "usage_multiple"
  ) %>%
  select(year, estimate, conf.low, conf.high, group)

# Plot ES did2s
plot_did2s <- bind_rows(strict_effect, usage_effect)

ggplot(plot_did2s, aes(x = year, y = estimate, color = group)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s) - hétérogénéité par statut IUCN",
       color = "Catégorie IUCN") + 
  theme_minimal()

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present <- strict_effect$year[strict_effect$year < 0]

if(length(leads_present) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present, collapse="|"), ")$")
  print(fixest::wald(did2s_es, keep = keep_regex))
}

 return(list(
   static = did2s_static,
   es = did2s_es,
   plot_did2s = plot_did2s
 ))
}

res_wealth_centile <- run_did2s_es(dat3, "wealth_centile_rural_weighted")

```

### Test pour une distance de 15km

#### Assignation du traitement

```{r}
# Buffer de 15 km
buffer_dist <- 15000

# Créer des buffers de 15 km autour des AP
buffer_15km_before_2008 <- wdpa_before_2008 %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)


buffer_15km_from_2008 <- wdpa_from_2008  %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)

# Visualisation des cartes---------------------
tmap_mode("view")

tm_shape(contour_mada) + 
  tm_borders(col = "black", lwd = 1) +
  
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "blue", 
              col =  "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) +
  
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "darkgreen", 
              col = "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) + 
  
tm_shape(buffer_15km_from_2008) +
tm_borders(col = "darkgreen", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
  
tm_shape(buffer_15km_before_2008) +
tm_borders(col = "blue", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
tm_add_legend(
  type = "polygons", 
  fill = c("blue", "darkgreen"), 
  labels = c("avant 2008", "après 2008")) +
  tm_title("Aires protégées du WDPA par période de création</b><br/>Source: WDPA, 2024") +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE,
    legend.title.size = 1.2,
    legend.text.size = 0.8
  ) +
  tm_compass(type = "8star", position = c("right", "top")) +
  tm_scalebar(position = c("right", "bottom"))

# Classification des clusters---------------------------------------------------------
#| fig-cap: "Grappes d'enquêtes DHS par rapport aux aires protégées existantes"


classify_clusters_with_pa <- function(cluster_gps,
                                      buffer_before,   # union of <2008
                                      wdpa_after,      # polygons >=2008 (no union)
                                      buffer_dist = 15000,
                                      label_treat = "Treatment",
                                      label_excl  = "Excluded",
                                      label_ctrl  = "Control") {

  # per-PA buffers (keep attrs)
  wdpa_after_buf <- wdpa_after %>%
    st_transform(mdg_crs) %>%
    mutate(geometry = st_buffer(geometry, buffer_dist)) %>%
    st_transform(standard_crs)

  # flags
  in_after  <- st_within(cluster_gps, st_union(wdpa_after_buf),  sparse = FALSE)[,1]
  in_before <- st_within(cluster_gps, buffer_before,            sparse = FALSE)[,1]

  base <- cluster_gps %>%
    mutate(groupe = case_when(
      in_after & !in_before & URBAN_RURA == "R" ~ label_treat,
      in_before | URBAN_RURA == "U"            ~ label_excl,
      TRUE                                     ~ label_ctrl
    ))

  # enrich treated with oldest+nearest PA
  treated_pts <- base %>% filter(groupe == label_treat)

  if (nrow(treated_pts) == 0) return(base)

  cand <- st_join(treated_pts, wdpa_after_buf, join = st_within, left = FALSE) %>%
  mutate(
    .idx = match(WDPAID, wdpa_after$WDPAID),
    dist_km = as.numeric(
      st_distance(
        geometry,
        wdpa_after$geometry[.idx],
        by_element = TRUE
      )
    ) / 1000
  ) %>%
  dplyr::select(-.idx)

  best <- cand %>%
    group_by(DHSCLUST) %>%
    slice_min(STATUS_YR, with_ties = TRUE) %>%
    slice_min(dist_km,   with_ties = FALSE) %>%
    ungroup() %>%
    st_drop_geometry() %>%
    select(DHSYEAR, DHSCLUST, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

  base %>% left_join(best, by = c("DHSYEAR","DHSCLUST"))
}

gps_1997_class <- classify_clusters_with_pa(gps_1997, buffer_15km_before_2008, 
                                            wdpa_from_2008)
gps_2008_class <- classify_clusters_with_pa(gps_2008, buffer_15km_before_2008, 
                                            wdpa_from_2008)
gps_2011_class <- classify_clusters_with_pa(gps_2011, buffer_15km_before_2008, 
                                            wdpa_from_2008)
gps_2013_class <- classify_clusters_with_pa(gps_2013, buffer_15km_before_2008,
                                            wdpa_from_2008)
gps_2016_class <- classify_clusters_with_pa(gps_2016, buffer_15km_before_2008,
                                            wdpa_from_2008)
gps_2021_class <- classify_clusters_with_pa(gps_2021, buffer_15km_before_2008,
                                            wdpa_from_2008)


gps_all_class_15km <- bind_rows(
  gps_1997_class,
  gps_2008_class,
  gps_2011_class,
  gps_2013_class,
  gps_2016_class,
  gps_2021_class
)

# Créer un plot pour visualiser la carte des AP avec les clusters----------------------
tm_shape(buffer_15km_from_2008) +
  tm_borders("green", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +  
  tm_shape(buffer_15km_before_2008) +
  tm_borders("darkgreen", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "green", 
              fill_alpha = 0.5,
              col = "black", 
              fill.legend = tm_legend(title = "à partir de 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "darkgreen", 
              fill_alpha = 0.5, 
              col =  "black", 
              fill.legend = tm_legend(title = "avant 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(gps_all_class_15km) +
  tm_symbols(
    fill = "groupe", 
    fill.legend = tm_legend(title = "Groupes"),
    fill.scale = tm_scale(values = c("Treatment" = "red", "Control" = "blue", "Excluded" = "gray")),
     size = 0.5,
    shape = 21
  ) +
  tm_facets("DHSYEAR") +
  tm_add_legend(type = "polygons", 
                fill = c("green", "darkgreen"), 
                labels = c("à partir de 2008", "avant 2008")) +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE
  ) +
  tm_scalebar(position = c("left", "bottom"))

# Tableau récapitulatif du nombre de grappes d'enquête classées dans chaque groupe-----
treated_sub_clusters <- gps_all_class_15km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  mutate(subcat = case_when(
    !is.na(STATUS_YR) & DHSYEAR <  STATUS_YR ~ "Avant traitement",
    !is.na(STATUS_YR) & DHSYEAR >= STATUS_YR ~ "Déjà traités",
    TRUE ~ NA_character_
  )) %>%
  count(DHSYEAR, subcat, name = "n_clusters") %>%
  pivot_wider(names_from = subcat, values_from = n_clusters, values_fill = 0)

# Ligne "Ensemble" (tous les traités, quel que soit le statut)
treated_all_clusters <- gps_all_class_15km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  count(DHSYEAR, name = "Ensemble")

# Colonnes Contrôles / Exclus
ctrl_excl_clusters <- gps_all_class_15km %>%
  st_drop_geometry() %>%
  filter(groupe %in% c("Control", "Excluded")) %>%
  mutate(Groupe = recode(groupe, Control = "Contrôles", Excluded = "Exclus")) %>%
  count(DHSYEAR, Groupe, name = "n") %>%
  pivot_wider(names_from = Groupe, values_from = n, values_fill = 0)

# Assemblage large (années en lignes)
tab_wide_clusters <- list(treated_sub_clusters, treated_all_clusters, 
                          ctrl_excl_clusters) %>%
  Reduce(function(x, y) full_join(x, y, by = "DHSYEAR"), .) %>%
  arrange(DHSYEAR) %>%
  mutate(across(-DHSYEAR, ~replace_na(.x, 0L)))

# Tableau gt : spanner "Traitement" + colonnes Contrôles / Exclus
gt_table_clusters <- tab_wide_clusters %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de grappes par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des grappes *Traitement*."),
    locations = cells_title(groups = "title")
  )

gt_table_clusters

# Tableau récapitulatif du nombre de ménages d'enquête classées dans chaque groupe-----
load_dhs_data <- function(dhs_folder, year, identifier) {
  folder_pattern <- paste0(".*", year, ".*", identifier)
  
  matching_folder <- list.dirs(dhs_folder, full.names = TRUE, recursive = TRUE) %>%
    keep(~ str_detect(.x, folder_pattern))
  
  if (length(matching_folder) == 0) {
    stop("No folder found for the specified year and identifier.")
  }
  
  if (identifier == "GE") {
    file_pattern <- "\\.shp$"
    data_loader <- function(file) st_read(file, quiet = TRUE)
  } else {
    file_pattern <- "\\.[Dd][Tt][Aa]$"
    data_loader <- read_dta
  }
  
  target_file <- list.files(matching_folder, pattern = file_pattern, full.names = TRUE)
  
  if (length(target_file) == 0) {
    stop("No valid file found in the folder.")
  }
  
  data <- data_loader(target_file)
  
  return(data)
}

dhs_folder <- "data/raw/dhs"


# Années disponibles
years_all <- sort(unique(gps_all_class_15km$DHSYEAR))

# Compte ménages (toutes observations) 
households_counts_all <- map_dfr(years_all, function(y) {
  # HR de l'année
  hr <- load_dhs_data(dhs_folder, y, "HR") %>%
    mutate(DHSYEAR = y)  # pour la jointure avec la classification

  # Classification des grappes de l'année
  cl_y <- gps_all_class_15km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == y) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)

  # Jointure ménages <- classification (par cluster hv001)
  hr_cl <- hr %>%
    select(DHSYEAR, hv001) %>%
    left_join(cl_y, by = c("DHSYEAR" = "DHSYEAR", "hv001" = "DHSCLUST"))

  # Comptes par sous-catégories du traitement (DHSYEAR vs STATUS_YR)
  avant  <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR <  STATUS_YR) %>% nrow()
  deja   <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR >= STATUS_YR) %>% nrow()
  ens    <- hr_cl %>% filter(groupe == "Treatment") %>% nrow()
  ctrl   <- hr_cl %>% filter(groupe == "Control")   %>% nrow()
  excl   <- hr_cl %>% filter(groupe == "Excluded")  %>% nrow()

  tibble(
    DHSYEAR = y,
    `Avant traitement` = avant,
    `Déjà traités`     = deja,
    Ensemble           = ens,
    `Contrôles`        = ctrl,
    `Exclus`           = excl
  )
})

# Tableau gt (ménages, toutes observations)
gt_table_menages_all <- households_counts_all %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de ménages par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0, use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des ménages du groupe *Traitement*."), locations = cells_title(groups = "title"))

gt_table_menages_all   

# Sauvegarde des classifications des clusters 
all_class_15km <- gps_all_class_15km %>%
  select(DHSYEAR, DHSCLUST, GROUP = groupe, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

write_csv(all_class_15km, "data/derived/cluster_treatment_classification_staggered_15km.csv")

write_csv(wdpa_before_2008, "data/derived/wdpa_before_2008_15km.csv")
write_csv(wdpa_from_2008, "data/derived/wdpa_from_2008_15km.csv")

# Classification des clusters avec les données HR des ménages--------------------------- 
for(year in years_all) {
  hr_data <- load_dhs_data(dhs_folder, year, "HR") %>%
    mutate(DHSYEAR = year)
  
  cluster_class <- gps_all_class_15km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == year) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)
  
  hr_final_15km <- hr_data %>%
    rename(DHSCLUST = hv001) %>%
    left_join(cluster_class, by = c("DHSYEAR", "DHSCLUST")) %>%
    
    mutate(treatment = if_else(groupe == "Treatment", 1L, 0L),
           control = if_else(groupe == "Control", 1L, 0L))
  
  saveRDS(hr_final_15km, glue("data/derived/hr_{year}_final_15km.rds"))
    
}
```

#### Covariates Calculation

```{r}
# Load data
buffer_all_15km <- gps_all_class_15km %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = 15000) %>%
  st_transform(standard_crs)

# Chargement des données géophysiques des ménages--------------------------------
# Définir le chemin relatif pour ton répertoire local

outdir <- "data/raw/mapme"
dir.create(outdir, recursive = TRUE, showWarnings = FALSE)
mapme_options(outdir = outdir, verbose = TRUE)


# Couvert forestier
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km  %>% 
    get_resources(get_gfw_treecover())
})
toc() # 1.18 sec elapsed 

# Perte de couvert
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% 
  get_resources(get_gfw_lossyear()) 
})
toc() # 1.39 sec elapsed 

# NASA SRTM
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% 
  get_resources(get_nasa_srtm()) 
})
toc() # 5.41 sec elapsed 

# Worldpop 2000
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>%
    get_resources(get_worldpop(years = 2000))
})
toc() # 0.27 sec elapsed 
  
# Accesibility
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% 
  get_resources(get_accessibility_2000()) 
})
toc() # 0.25 sec elapsed 

# Maximum temperatures
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% get_resources(
    get_worldclim_max_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 86.71 sec elapsed 

# Minimum temperatures
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% get_resources(
    get_worldclim_min_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 93.67 sec elapsed 

# Precipitations
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% get_resources(
    get_worldclim_precipitation(years = 1980:2021, resolution = "2.5m")
  )
})
toc() #  25.87 sec elapsed
  
```

Après chargement et extraction des données sur les données géophysiques des ménages, nous allons calculer les indicateurs des variables environnementales dans un rayon de 15 km autour de chaque grappe d'enquête.

```{r}
# Calcul des indicateurs------------------------------------------------------- 
if(file.exists("data/derived/spatial_covars_staggered_15km.rds")) {cat("Le fichier spatial_covars_staggered_15km.rds existe déjà")
} else {
    cat("Fichier introuvable, début du traitement... \n")
  
  # Créer un plan pour paralléliser les calculs
  plan(sequential)
  plan(multisession, workers = 4)
  
  # Maximum temperatures
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_temperature_max_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 28053.12 sec elapsed
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_max_temp_15km.rds", compress = "gz")
   
  
  # Minimum temperatures
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
         calc_temperature_min_wc( engine = "extract", stats = "mean")
      )
  })
  toc() # 26406.66 sec elapsed 
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_min_temp_15km.rds", compress = "gz")
  
  
  # Precipitations
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_precipitation_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 18938.39 sec elapsed 
 
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_precip_15km.rds", compress = "gz") 
  
  
  # Forest cover rate in 2000
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_treecover_area(years = 2000, min_size = 1, min_cover = 10)
      )
  })
  toc()   # 8712.08 sec elapsed
 
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_treecover_15km.rds", compress = "gz")
  
  
  # slope 
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_slope(engine = "extract", stats = "mean")
      )
  })
  toc() # 7270.96 sec elapsed  
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_slope_15km.rds", compress = "gz")
  
  
  # Elevation
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_elevation(engine = "extract", stats = "mean")
      )
  })
  toc() # 8016.01 sec elapsed 
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_elevation_15km.rds", compress = "gz")
  
  
  # Population density
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_population_count(engine = "extract", stats = "mean")
      )
  })
  toc() # 544.9 sec elapsed
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_pop_density_15km.rds", compress = "gz")
  
  
  # Accessibility
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_traveltime_2000(engine = "extract", stats = "mean")
      )
  })
  toc() # 289.5 sec elapsed  
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_accessibility_15km.rds", compress = "gz")
  
  # Enregistrement final des données 
  write_rds(buffer_all_15km, "data/derived/spatial_covars_staggered_15km.rds")
 }
```

#### Spei calculation

```{r}

# Load data 
spatial_covars_15km <- read_rds("data/derived/spatial_covars_staggered_15km.rds")

# Function to compute SPEI
compute_spei_annual <- function(tmin_tbl, tmax_tbl, prec_tbl, lat_deg) {
  # tmin_tbl/tmax_tbl/prec_tbl: tibbles avec colonnes `datetime` (Date) et `value` (num)
  d_tmin <- tibble(date = tmin_tbl$datetime, tmin = tmin_tbl$value)
  d_tmax <- tibble(date = tmax_tbl$datetime, tmax = tmax_tbl$value)
  d_prec <- tibble(date = prec_tbl$datetime, prec = prec_tbl$value)

  d_merged <- reduce(list(d_tmin, d_tmax, d_prec), left_join, by = "date") %>%
    arrange(date)

  d_clean <- drop_na(d_merged)  # supprime lignes avec NA

  # Si séries trop courtes, renvoyer squelette 1981:2021 en NA
  if (nrow(d_clean) < 12) {
    return(tibble(year = 1981:2021, spei_mean = NA_real_))
  }

  # PET (Hargreaves), bilan hydrique et SPEI mensuel
  pet <- hargreaves(Tmin = d_clean$tmin,
                    Tmax = d_clean$tmax,
                    Pre  = d_clean$prec,
                    lat  = lat_deg)

  wb <- d_clean$prec - pet

  wb_ts <- ts(wb,
              start = c(year(min(d_clean$date)), month(min(d_clean$date))),
              frequency = 12)

  spei_obj <- spei(wb_ts,
                   scale = 12,
                   ref.start = c(1981, 1),
                   ref.end   = c(2021, 12))

  tibble(datetime = d_clean$date,
         spei      = as.numeric(spei_obj$fitted)) %>%
    filter(datetime >= as.Date("1981-01-01"),
           datetime <= as.Date("2021-12-31")) %>%
    mutate(year = year(datetime)) %>%
    group_by(year) %>%
    summarise(spei_mean = mean(spei, na.rm = TRUE), .groups = "drop") %>%
    complete(year = 1981:2021, fill = list(spei_mean = NA_real_))
}

# Latitude géodésique depuis la géométrie (centroïde)
spatial_covars_spei_15km <- spatial_covars_15km %>%
  mutate(lat = st_coordinates(st_centroid(geometry))[, 2])

row1 <- spatial_covars_spei_15km[1, ]

spei_tbl_one <- compute_spei_annual(
  tmin_tbl = row1$temperature_min_wc[[1]],
  tmax_tbl = row1$temperature_max_wc[[1]],
  prec_tbl = row1$precipitation_wc[[1]],
  lat_deg  = row1$lat
)

# Graphique 
spei_2017 <- spei_tbl_one %>% 
  filter(year == 2017)

ggplot(spei_tbl_one, aes(x = year, y = spei_mean)) +
  geom_col(aes(y = pmax(0, -spei_mean)), alpha = 0.25) +  # barres pour sécheresse (optionnel)
  geom_line(linewidth = 0.8) +
  geom_vline(xintercept = 2017, color = "red", linetype = "dotted", linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label(
    data = spei_2017, 
    aes(x = 2017, y = spei_mean, 
        label = paste0("Année: 2017\nSPEI: ", round(spei_mean, 2))),
    nudge_x = 1, 
    nudge_y = 0.3,
    fill = "white",
    color = "black",
    linewidth = 0.4, 
    label.padding = unit(0.2, "lines")
  ) +
  
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI (scale=12) – cluster de démonstration",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# SPEI for all clusters 
spatial_covars_spei_15km <- spatial_covars_spei_15km %>%
  mutate(
    spei_wc = pmap(
      list(temperature_min_wc, temperature_max_wc, precipitation_wc, lat),
      ~ compute_spei_annual(..1, ..2, ..3, ..4)
    )
  )

spei_df <- spatial_covars_spei_15km %>%
  select(DHSCLUST, spei_wc) %>%
  unnest(spei_wc)

ggplot(spei_df, aes(x = year, y = spei_mean, group = DHSCLUST)) +
  geom_line(alpha = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI by cluster with 15 km buffer (1981–2021)",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# Chaque élément spei_wc devient une table {datetime, variable, unit, value}
spatial_covars_spei_15km <- spatial_covars_spei_15km %>%
  mutate(
    spei_wc = map(spei_wc, ~ .x %>%
      mutate(
        datetime = as.Date(paste0(.data$year, "-01-01")),
        variable = "spei_scale12_mean",
        unit     = "annual",
        value    = .data$spei_mean
      ) %>%
      select(datetime, variable, unit, value))
  )

# Sauvegarde (cohérente avec le reste de tes scripts)
spatial_covars_spei_df_15km <- as.data.frame(spatial_covars_spei_15km)
write_rds(spatial_covars_spei_df_15km, "data/derived/spatial_covars_spei_staggered_15km.rds")
cat("SPEI (annuel, 1981–2021) enregistré dans data/derived/spatial_covars_spei_staggered_15km.rds\n")
```

#### Variable consolidation

```{r}
# Covariates spatio-temporelles + classification de traitement
spatial_covars_spei_15km <- readRDS("data/derived/spatial_covars_spei_staggered_15km.rds")
all_covars <- spatial_covars_spei_15km %>%
  select(DHSYEAR, DHSCLUST, URBAN_RURA, treecover_area, slope, elevation,
         population_count, traveltime_2000, spei_wc)

all_class_15km <- read.csv("data/derived/cluster_treatment_classification_staggered_15km.csv")

# Helper: fabrique la table finale pour une année donnée
vars_to_nest <- c("treecover_area", "slope", "elevation",
                  "population_count", "traveltime_2000", "spei_wc")

build_year <- function(hr_object,
                       year,
                       hh_rural_path,
                       spei_years = (year-2):year) {

  # Charger HR (identifiants + variables chef) et HH_rural (centiles/zscore déjà calculés)
  hr <- hr_object %>%
    dplyr::select(hv001, hv002, hv219, hv220)
  
  hh_rural <- read_rds(hh_rural_path) # contient hv001/hv002 + wealth_* déjà prêts
  
  # Joindre covariates spatiaux + classification de groupes
  base <- hh_rural %>%
    left_join(hr, by = c("hv001", "hv002")) %>%
    left_join(
      all_covars %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    left_join(
      all_class_15km %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    mutate(DHSYEAR = year) %>%
    relocate(DHSYEAR, .before = everything())
  
  # Désimbriquer les covars imbriquées et appliquer la fenêtre temporelle SPEI
  #    moyenne par (hv001, hv002) pour chaque indicateur_année
  df_long <- base %>%
    select(hv001, hv002, any_of(vars_to_nest)) %>%
    pivot_longer(cols = any_of(vars_to_nest),
                 names_to = "indicator", values_to = "data") %>%
    unnest(data) %>%
    filter(indicator != "spei_wc" | year(datetime) %in% spei_years) %>%
    mutate(year_indicator = paste0(indicator, "_", year(datetime))) %>%
    select(hv001, hv002, year_indicator, value)
  
  df_wide <- df_long %>%
    pivot_wider(names_from = year_indicator, values_from = value,
                names_glue = "{year_indicator}") %>%
    group_by(hv001, hv002) %>%
    summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
  
  # Table finale (une ligne par ménage hv001/hv002)
  out <- base %>%
    select(-any_of(vars_to_nest)) %>%
    distinct(hv001, hv002, .keep_all = TRUE) %>%
    left_join(df_wide, by = c("hv001", "hv002"))
  
  out
}

# Application

hr_1997_final_15km <- read_dta("data/raw/dhs/DHS_1997/MDHR31DT/MDHR31FL.DTA") %>%
  build_year(year = 1997,
             hh_rural_path = "data/derived/hh_1997_rural_simpler.rds",
             spei_years = 1995:1997)

hr_2008_final_15km <- read_dta("data/raw/dhs/DHS_2008/MDHR51DT/MDHR51FL.DTA") %>%
  build_year(year = 2008,
             hh_rural_path = "data/derived/hh_2008_rural_simpler.rds",
             spei_years = 2006:2008)

hr_2011_final_15km <- read_dta("data/raw/dhs/DHS_2011/MDHR61DT/MDHR61FL.DTA") %>%
  build_year(year = 2011,
             hh_rural_path = "data/derived/hh_2011_rural_simpler.rds",
             spei_years = 2009:2011)

hr_2013_final_15km <- read_dta("data/raw/dhs/DHS_2013/MDHR6ADT/MDHR6AFL.DTA") %>%
  build_year(year = 2013,
  hh_rural_path = "data/derived/hh_2013_rural_simpler.rds",
  spei_years = 2011:2013)

hr_2016_final_15km <- read_dta("data/raw/dhs/DHS_2016/MDHR71DT/MDHR71FL.DTA") %>%
  build_year(year = 2016,
  hh_rural_path = "data/derived/hh_2016_rural_simpler.rds",
  spei_years = 2014:2016)

hr_2021_final_15km <- read_dta("data/raw/dhs/DHS_2021/MDHR81DT/MDHR81FL.DTA") %>%
  build_year(year = 2021,
  hh_rural_path = "data/derived/hh_2021_rural_simpler.rds",
  spei_years = 2019:2021)

# Consolidation

hr_consolidated_15km <- bind_rows(
  hr_1997_final_15km,
  hr_2008_final_15km,
  hr_2011_final_15km,
  hr_2013_final_15km,
  hr_2016_final_15km,
  hr_2021_final_15km
)

hr_consolidated_15km %>% count(DHSYEAR)

# Sauvegardes millésime
write_rds(hr_1997_final_15km, "data/derived/hr_1997_final_15km.rds")
write_rds(hr_2008_final_15km, "data/derived/hr_2008_final_15km.rds")
write_rds(hr_2011_final_15km, "data/derived/hr_2011_final_15km.rds")
write_rds(hr_2013_final_15km, "data/derived/hr_2013_final_15km.rds")
write_rds(hr_2016_final_15km, "data/derived/hr_2016_final_15km.rds")
write_rds(hr_2021_final_15km, "data/derived/hr_2021_final_15km.rds")

# Sauvegarde consolidée
write_rds(hr_consolidated_15km, "data/derived/hr_consolidated_15km_1997_2008_2011_2013_2016_2021.rds")
cat("Données enregistrées\n")
```

#### Matching

```{r}

prep_matching <- function(df_final) {
  out <- df_final %>%
    filter(GROUP %in% c("Treatment","Control")) %>%
    mutate(treatment = if_else(GROUP == "Treatment", 1L, 0L))
  
  missing_cols <- setdiff(matching_variables, names(out))
  if (length(missing_cols) > 0) {
    message(">> Colonnes manquantes: ", paste(missing_cols, collapse=", "))
  }
  
  out %>% drop_na(all_of(intersect(matching_variables, names(out))))
}

# supprimer toute ancienne version pour éviter le masquage
if (exists("run_matching_year")) rm(run_matching_year)

run_matching_year <- function(year, overwrite = list(gen=FALSE, match=FALSE)) {
  cat("\n=== Matching", year, "===\n")
  fin_path <- glue("data/derived/hr_{year}_final_15km.rds")
  if (!file.exists(fin_path)) stop("Fichier introuvable: ", fin_path)
  
  dat   <- readRDS(fin_path)
  dat_m <- prep_matching(dat)
  
  
  n_total <- nrow(dat)
  n_filt <- nrow(dat_m)
  n_treat <- sum(dat_m$treatment == 1, na.rm = TRUE)
  n_ctrl <- sum(dat_m$treatment == 0, na.rm = TRUE)
  
  
  cat(glue(">> N total={n_total}, après filtre/NA={n_filt}; ",
           "Traités={n_treat}, ",
           "Contrôles={n_ctrl}\n"))
  
  have_all_vars <- all(matching_variables %in% names(dat_m))
  cat(">> Toutes les covars présentes ? ", have_all_vars, "\n")
  if (n_filt < 5 || !have_all_vars) {
    warning(glue("Année {year}: données insuffisantes ou variables manquantes — on saute."))
    return(NULL)
  }
  
  X_match <- dat_m %>%
    sf::st_drop_geometry() %>%
    dplyr::select(all_of(matching_variables)) %>%
    as.data.frame()
  
  gen_path         <- glue("data/derived/gen_match_model_{year}_15km.rds")
  match_path       <- glue("data/derived/matching_result_{year}_15km.rds")
  matched_out_path <- glue("data/derived/data_matched_{year}_15km.rds")
  
  # --- GenMatch ---
  used_cache_gen <- FALSE
  t0 <- Sys.time()
  if (file.exists(gen_path) && !isTRUE(overwrite$gen)) {
    cat(">> GenMatch: cache trouvé -> lecture\n")
    gen_model <- readRDS(gen_path)
    used_cache_gen <- TRUE
  } else {
    cat(">> GenMatch: calcul en cours...\n")
    gen_model <- GenMatch(
      Tr = dat_m$treatment,
      X  = X_match,
      BalanceMatrix = X_match,
      estimand = "ATT",
      M = 1,
      weights = NULL,
      pop.size = 1000,
      max.generations = 100,
      wait.generations = 4,
      caliper = .25,
      print.level = 1,
      cluster = rep("localhost", 4)
    )
    saveRDS(gen_model, gen_path)
  }
  t_gen <- as.numeric(difftime(Sys.time(), t0, units="mins"))
  cat(glue(">> GenMatch temps = {round(t_gen,1)} min (cache={used_cache_gen})\n"))
  
  # --- matchit() ---
  used_cache_match <- FALSE
  t1 <- Sys.time()
  if (file.exists(match_path) && !isTRUE(overwrite$match)) {
    cat(">> matchit: cache trouvé → lecture\n")
    m_out <- readRDS(match_path)
    used_cache_match <- TRUE
  } else {
    cat(">> matchit: calcul en cours...\n")
    fml <- as.formula(paste("treatment ~", paste(matching_variables, collapse=" + ")))
   
    
     m_out <- matchit(
      formula   = fml,
      data      = dat_m,
      method    = "genetic",
      distance  = "mahalanobis",
      gen.match = gen_model
    )
     
    saveRDS(m_out, match_path)
  }
  
  matched <- match.data(m_out, data = sf::st_drop_geometry(dat_m)) %>%
    dplyr::filter(weights > 0)
  
  saveRDS(matched, matched_out_path)
  cat(glue(">> N appariés = {nrow(matched)} (écrit: {matched_out_path})\n"))
  
  
  tibble(
    Année = year,
    'Total des observations' = n_total,
    'Après filtre/NA' = n_filt,
    Traités = n_treat,
    Contrôles = n_ctrl,
    'N appariés' = nrow(matched)
  )
}

need_overwrite <- function(year) {
  gen_path   <- glue("data/derived/gen_match_model_{year}_15km.rds")
  match_path <- glue("data/derived/matching_result_{year}_15km.rds")
  list(gen = !file.exists(gen_path), match = !file.exists(match_path))
}

# --- Exécution avec progression ---
yrs <- c(1997, 2008, 2011, 2013, 2016, 2021)


res_list <- vector("list", length(yrs))
names(res_list) <- yrs

with_progress({
  p <- progressor(along = yrs)

for (i in seq_along(yrs)) {
  yr <- yrs[i]
  ow <- need_overwrite(yr) 
  cat(glue("\n>> overwrite {yr}: gen={ow$gen}, match={ow$match}\n"))
  cat(sprintf("Start %s", yr))
  t_all <- Sys.time()
  res_list[[i]] <- tryCatch(
    run_matching_year(yr, overwrite = ow),
    error = function(e) { warning(glue("Year {yr} ERROR: {e$message}")); NULL }
  )
  cat(sprintf("Done %s (%.1f min)",
            yr, as.numeric(difftime(Sys.time(), t_all, units="mins"))))
}
})

result_list <- purrr::compact(res_list) |> bind_rows()
saveRDS(result_list, "data/derived/matching_summary_all_years_15km.rds")

bal_tabs <- purrr::imap(res_list, ~ {if (!is.null(.x)) {
  tryCatch(cobalt::bal.tab(.x$m), error = function(e) NULL) } else {
    NULL
  }
})

saveRDS(bal_tabs, "data/derived/matching_balance_tabs_all_years_15km.rds")

print(result_list)
```

##### Checking covariate balance

Nous allons vérifier l'équilibre relatif des variables mesurées dans des unités différentes avant le matching pour mesurer l'écart entre les moyennes des covariables dans les groupes de traitement et de contrôle pour un buffer de 15 km.

```{r}
# Balance test before matching
data_matched_1997_15km <- read_rds("data/derived/data_matched_1997_15km.rds")
data_matched_2008_15km <- read_rds("data/derived/data_matched_2008_15km.rds")
data_matched_2011_15km <- read_rds("data/derived/data_matched_2011_15km.rds")
data_matched_2013_15km <- read_rds("data/derived/data_matched_2013_15km.rds")
data_matched_2016_15km <- read_rds("data/derived/data_matched_2016_15km.rds")
data_matched_2021_15km <- read_rds("data/derived/data_matched_2021_15km.rds")

# Equilibre des covariables
check_balance_before <- function(df, year, matching_variables){
  
  data <- df %>%
    filter(GROUP %in% c("Treatment", "Control")) %>%
    mutate(treatment = if_else(GROUP == "Treatment", 1, 0))
  
  formula <- as.formula(
    paste("treatment ~", paste(matching_variables, collapse = "+"))
  )
  
  # Balance avant appariement
  bal_before <- bal.tab(
    formula,
    data = data,
    estimand = "ATT",
    un = TRUE,
    abs = TRUE
  )
  
  print(bal_before)
  
  # Extraction du Standardized Mean Difference (SMD)
  balance_df <- as.data.frame(bal_before$Balance) %>%
    tibble::rownames_to_column("Variable")
  
  smd_col <- grep("Diff|Std", names(balance_df), value = TRUE)[1]
  
  smd_table <- balance_df %>%
    dplyr::select(Variable, SMD = all_of(smd_col)) %>%
    mutate(
      Equilibre = if_else(abs(SMD) <= 0.1, "Equilibré", "Déséquilibré"),
      Year = year) %>%
    relocate(Year, .before = Variable)
  
  return(list(
    bal_before = bal_before,
    smd_table = smd_table
  ))
}

res_1997_15km  <- check_balance_before(data_matched_1997_15km, 1997, matching_variables)
res_2008_15km  <- check_balance_before(data_matched_2008_15km, 2008, matching_variables)
res_2011_15km  <- check_balance_before(data_matched_2011_15km, 2011, matching_variables)
res_2013_15km  <- check_balance_before(data_matched_2013_15km, 2013, matching_variables)
res_2016_15km  <- check_balance_before(data_matched_2016_15km, 2016, matching_variables)
res_2021_15km  <- check_balance_before(data_matched_2021_15km, 2021, matching_variables)

# Distribution des covariables
data_list <- list(
  "1997" = data_matched_1997_15km,
  "2008" = data_matched_2008_15km,
  "2011" = data_matched_2011_15km,
  "2013" = data_matched_2013_15km,
  "2016" = data_matched_2016_15km,
  "2021" = data_matched_2021_15km 
)


  density_plot <- function(data, year, matching_variables){
    data %>%
      filter(GROUP %in% c("Treatment", "Control")) %>%
      mutate(GROUP =factor(GROUP, levels = c("Control", "Treatment"))) %>%
    pivot_longer(cols = all_of(matching_variables), names_to = "variable", values_to = "value") %>%
    ggplot(aes(x = value, fill = GROUP)) +
    geom_density(alpha = 0.5, color = "black", linewidth = 0.7, adjust = 0.7) +
    facet_wrap(~variable, scales = "free") + 
    scale_fill_manual(values = c("Control" = "green", "Treatment" = "blue")) +
    labs(
      title = paste("Covariate distribution before matching(", year, ")", sep = ""),
      x = "Valeur de la covariable",
      y = "Densité",
      fill = "Group"
    ) + 
    theme_minimal()
  }
    
print(density_plot(data_matched_1997_15km, 1997, matching_variables))
print(density_plot(data_matched_2008_15km, 2008, matching_variables))
print(density_plot(data_matched_2011_15km, 2011, matching_variables))
print(density_plot(data_matched_2013_15km, 2013, matching_variables))
print(density_plot(data_matched_2016_15km, 2016, matching_variables))
print(density_plot(data_matched_2021_15km, 2021, matching_variables))
```

#### Estimation

##### Overall effect on livelihoods

```{r}
# 2X2 DiD----------------------------------------------
library(fixest)
library(didimputation)
library(broom)

# Chargement des données
d97_15km <- read_rds("data/derived/data_matched_1997_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_1995,
         spei_wc_n_1 = spei_wc_1996,
         spei_wc_n   = spei_wc_1997) %>%
  mutate(hv219 = zap_labels(hv219), # hhh sex (1/2)
         hv220 = zap_labels(hv220)) # hhh age (num)

d08_15km <- read_rds("data/derived/data_matched_2008_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2006,
         spei_wc_n_1 = spei_wc_2007,
         spei_wc_n   = spei_wc_2008) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d11_15km <- read_rds("data/derived/data_matched_2011_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2009,
         spei_wc_n_1 = spei_wc_2010,
         spei_wc_n   = spei_wc_2011) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d13_15km <- read_rds("data/derived/data_matched_2013_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2011,
         spei_wc_n_1 = spei_wc_2012,
         spei_wc_n   = spei_wc_2013) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d16_15km <- read_rds("data/derived/data_matched_2016_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2014,
         spei_wc_n_1 = spei_wc_2015,
         spei_wc_n   = spei_wc_2016) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d21_15km <- read_rds("data/derived/data_matched_2021_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2019,
         spei_wc_n_1 = spei_wc_2020,
         spei_wc_n   = spei_wc_2021) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

# Préparation des données
dat_15km <- bind_rows(d97_15km, d08_15km, d11_15km, d13_15km, d16_15km, d21_15km) %>%
  filter(GROUP %in% c("Treatment","Control")) %>%
  mutate(
    hv219   = factor(hv219, levels = c(1,2), labels = c("Homme","Femme")), # sexe (cat.)
    hv220   = as.numeric(hv220),                                           # âge
    treat   = as.integer(GROUP == "Treatment"),
    w_svy   = hv005 / 1e6,
    w_all   = w_svy * weights, # poids d'enquête × poids de matching (si 'weights' existe)
    id      = row_number(),
    # Map des années de statut -> première année d'observation post (treatment_phase)
    treatment_phase = case_when(
      STATUS_YR == 2010 ~ 2011,
      STATUS_YR == 2012 ~ 2013,
      STATUS_YR == 2015 ~ 2016,
      STATUS_YR == 2017 ~ 2021,
      is.na(STATUS_YR)  ~ 0,
      TRUE               ~ STATUS_YR
    )
  )

# Outcome h
yvar <- "wealth_centile_rural_weighted"

# fixest DID 2×2: placebo 1997–2008, traitement 2008–2021 ------------------

# Placebo 1997–2008
pre_15km <- dat_15km %>%
  filter(DHSYEAR %in% c(1997, 2008)) %>%
  mutate(post = as.integer(DHSYEAR == 2008),
         treat_post = treat * post)

f_pre <- as.formula(paste(
  yvar, "~ treat + post + treat_post +",
  "spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220"
))

m_pre <- feols(f_pre, data = pre_15km, weights = ~ w_all, cluster = ~ hv001)

# Traitement 2008–2021
main <- dat_15km %>%
  filter(DHSYEAR %in% c(2008, 2021)) %>%
  mutate(post = as.integer(DHSYEAR == 2021),
         treat_post = treat * post)

f_main <- f_pre  # même formule

m_main <- feols(f_main, data = main, weights = ~ w_all, cluster = ~ hv001)

etable(m_pre, m_main, headers = c("Placebo 97–08", "Traitement 08–21"))

# Extraction compacte des deux effets DID
did_row <- function(model, year_post, vc = ~ hv001, term = "treat_post"){
  summary(model, vcov = vc) %>% broom::tidy() %>%
    filter(term == !!term) %>%
    transmute(year = year_post, estimate, se = std.error)
}
did_df <- bind_rows(
  did_row(m_pre, 2008),
  did_row(m_main, 2021)
) %>%
  mutate(period = factor(ifelse(year == 2008, "1997–2008", "2008–2021"),
                         levels = c("1997–2008", "2008–2021")),
         lo = estimate - 1.96*se,
         hi = estimate + 1.96*se)

ggplot(did_df, aes(x = period, y = estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_errorbar(aes(ymin = lo, ymax = hi), width = .2) +
  geom_point(size = 3) +
  labs(x = NULL, y = "Effet DID sur le centile de richesse (pondéré)",
       title = "DID 2×2 avec IC clusterisés (hv001)")


# Staggered diff-in-diff----------------------------------------
# did2s (Gardner) : statique + event-study--------------------------------
library(did2s)

dat3 <- dat_15km %>%
  mutate(
    treat_on = as.integer(treatment_phase > 0 & DHSYEAR >= treatment_phase),
    rel_year = if_else(treatment_phase > 0, DHSYEAR - treatment_phase, Inf),
    # Binning prudent pour stabilité (-5..5)
    rel_year_binned = pmax(pmin(rel_year, 5), -5)
  )

# -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(treat_on, ref = FALSE),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static, headers = "did2s statique")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(rel_year_binned, ref = c(-1, Inf)),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es, headers = "did2s event-study (-5..5)")

# Plot ES did2s
plot_did2s <- broom::tidy(did2s_es, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(k = as.numeric(sub("^rel_year_binned::", "", term))) %>%
  arrange(k)

ggplot(plot_did2s, aes(k, estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s)")

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present <- plot_did2s$k[plot_did2s$k < 0]
if(length(leads_present) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present, collapse="|"), ")$")
  print(fixest::wald(did2s_es, keep = keep_regex))
}
```

Dans l'ensemble, les analyses DID 2x2 et staggered DID montrent que la création d'aires protégées n'a pas entraîné de changements significatifs sur le centile de richesse des ménages à 15 km des aires protégées.

Les tests placebo (1997-2008) ainsi que les tests de pré-tendances montrent l'absence de d'effet avant la création des aires protégées, renforçant la crédibilité causale. Toutefois, on observe un léger effet positif moyen des aires protégées sur le centile de richesse dans les années 1 à 3 années suivant sa mise en place. Ces effets sont sont ni robustes ni durable.

##### Effect on inequalities

```{r}
# Staggered DiD-----------------------------------------
yvar <- "zscore_wealth"

# did2s (Gardner) : statique + event-study--------------------------------
# -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(treat_on, ref = FALSE),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static, headers = "did2s statique")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(rel_year_binned, ref = c(-1, Inf)),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es, headers = "did2s event-study (-5..5)")

# Plot ES did2s
plot_did2s <- broom::tidy(did2s_es, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(k = as.numeric(sub("^rel_year_binned::", "", term))) %>%
  arrange(k)

ggplot(plot_did2s, aes(k, estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s)")

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present <- plot_did2s$k[plot_did2s$k < 0]
if(length(leads_present) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present, collapse="|"), ")$")
  print(fixest::wald(did2s_es, keep = keep_regex))
}

# Quantile treatment effects
# Testing Quantile treatment effect------------------------------
library(qte)

# Avec CiC -------------------

## Traitement 2008 -> 2021
set.seed(123)
dat_2per <- dat_15km %>%
  filter(DHSYEAR %in% c(2008, 2021)) %>%
  mutate(treat = as.integer(GROUP == "Treatment"))

cic_res <- suppressWarnings(CiC(
  formla = wealth_centile_rural_weighted ~ treat,
  t = 2021, tmin1 = 2008, tname = "DHSYEAR",
  data = dat_2per,
  panel = FALSE, # repeated cross-sections
  se = TRUE, iters = 200, # bootstrap
  probs = seq(0.05, 0.95, 0.05),
  xformla = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220
))

summary(cic_res)
ggqte(cic_res) + labs(x="Quantiles", y="QTET", title="CiC QTET: 2008-2021")

## placebo------------------------------------------------------

## Placebo: 1997 -> 2008
dat_placebo <- dat_15km %>%
  filter(DHSYEAR %in% c(1997, 2008)) %>%
  mutate(treat = as.integer(GROUP == "Treatment"))

# (Optional) sanity check:
# with(dat_placebo, table(DHSYEAR, treat))

cic_pre <-  suppressWarnings(CiC(
  formla = wealth_centile_rural_simple ~ treat,
  t = 2008, tmin1 = 1997, tname = "DHSYEAR",
  data = dat_placebo,
  panel = FALSE, # repeated cross-sections
  se = TRUE, iters = 100, # bootstrap
  probs = seq(0.05, 0.95, 0.05),
  xformla = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220
))

summary(cic_pre)

ggqte(cic_pre) +
  labs(x = "Quantiles", y = "QTET",
       title = "Placebo CiC QTET: 1997-2008")
```

##### Heterogeneity

```{r}
library(dplyr)

# Création du groupe IUCN 
dat3 <- dat3 %>%
  dplyr::filter(!is.na(IUCN_CAT), !is.na(treat_on)) %>%
  dplyr::mutate(
    IUCN_group = case_when(
    IUCN_CAT %in% c("Ia", "Ib", "II", "III", "IV") ~ "strict",
    IUCN_CAT %in% c("V", "VI") ~ "usage_multiple", 
    TRUE ~ NA_character_
  ),
  
  IUCN_group = factor(IUCN_group, levels = c("strict", "usage_multiple")),
  rel_year_binned = factor(rel_year_binned)
  ) %>%
  dplyr::filter(!is.na(IUCN_group))

# Outcome: wealth_centile_rural_weighted ----------------------------------------
yvar <- "wealth_centile_rural_weighted"

run_did2s_iucn <- function(data, yvar) {
  # did2s (Gardner) : statique + event-study--------------------------------
# -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = data,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ treat_on * IUCN_group,
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static, headers = paste0("did2s statique (strict vs usage multiple)(", yvar,")"))

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data = data,
  yname = yvar, 
  first_stage = ~ spei_wc_n_2 +  spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ 
    i(rel_year_binned, ref = -1) +
    i(rel_year_binned, IUCN_group),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es, headers = "did2s event-study (-5..5) par statut IUCN")
  
# Extraction des coefficients

tidy_es <- broom::tidy(did2s_es, conf.int = TRUE) %>%
  dplyr::filter(grepl("^rel_year_binned::", term)) %>%
  dplyr::mutate(
    year = as.numeric(sub("rel_year_binned::(-?\\d+).*", "\\1", term)),
    type = dplyr::if_else(grepl("IUCN_group::usage_multiple", term) ~ "diff_usage_multiple",
      TRUE ~ "strict"
    )
  )

# Effet pour les AP stricts
strict_effect <- tidy_es %>%
  dplyr::filter(type == "strict") %>%
  dplyr::mutate(group = "strict") %>%
  dplyr::select(year, estimate, conf.low, conf.high, group)


# Effet total pour AP à usage multiple
usage_effect <- tidy_es %>%
  dplyr::filter(type == "diff_usage_multiple") %>%
  dplyr::rename(estimate_diff = estimate,
         conf.low_diff = conf.low,
         conf.high_diff = conf.high) %>%
  dplyr::left_join(strict_effect, by = "year") %>%
  dplyr::mutate(
    estimate = estimate + estimate_diff,
    conf.low = conf.low + conf.low_diff,
    conf.high = conf.high + conf.high_diff,
    group = "usage_multiple"
  ) %>%
  dplyr::select(year, estimate, conf.low, conf.high, group)


# Plot ES did2s
plot_did2s <- bind_rows(strict_effect, usage_effect)

p <- ggplot(plot_data, aes(x = year, y = estimate, color = group)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = paste0("Effet estimé sur", yvar),
       title = paste0("Event-study (did2s) - hétérogénéité par statut IUCN (", yvar,")"),
       color = "Catégorie IUCN") + 
  theme_minimal()

print(p)

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present <- plot_data$year[plot_data$year < 0]
if(length(leads_present) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present, collapse="|"), ")$")
  print(fixest::wald(did2s_es, keep = keep_regex))
}

return(list(
  static = did2s_static,
  es = did2s_es,
  plot_data = plot_data,
  plot = p
  
))
}

res_wealth <- run_did2s_iucn(dat3, "wealth_centile_rural_weighted")
res_zscore <- run_did2s_iucn(dat3, "zscore_wealth")










# Outcome: zscore_wealth----------------------------------------------------------
yvar <- "zscore_wealth"

# did2s (Gardner) : statique + event-study--------------------------------
# -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ treat_on * IUCN_group,
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static, headers = "did2s statique (strict vs usage multiple)")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data = dat3,
  yname = yvar, 
  first_stage = ~ spei_wc_n_2 +  spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ 
    i(rel_year_binned, ref = -1) +
    i(rel_year_binned, IUCN_group),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es, headers = "did2s event-study (-5..5) par statut IUCN")

tidy_es <- broom::tidy(did2s_es, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(
    year = as.numeric(sub("rel_year_binned::(-?\\d+).*", "\\1", term)),
    type = case_when(
      grepl("IUCN_group::usage_multiple", term) ~ "diff_usage_multiple",
      TRUE ~ "strict"
    )
  )
# Effet pour les AP stricts
strict_effect <- tidy_es %>%
  dplyr::filter(type == "strict") %>%
  dplyr::mutate(group = "strict") %>%
  dplyr::select(year, estimate, conf.low, conf.high, group)

# Effet total pour AP à usage multiple
usage_effect <- tidy_es %>%
  filter(type == "diff_usage_multiple") %>%
  rename(estimate_diff = estimate,
         conf.low_diff = conf.low,
         conf.high_diff = conf.high) %>%
  left_join(strict_effect, by = "year") %>%
  mutate(
    estimate = estimate + estimate_diff,
    conf.low = conf.low + conf.low_diff,
    conf.high = conf.high + conf.high_diff,
    group = "usage_multiple"
  ) %>%
  select(year, estimate, conf.low, conf.high, group)

# Plot ES did2s
plot_did2s <- bind_rows(strict_effect, usage_effect)

ggplot(plot_did2s, aes(x = year, y = estimate, color = group)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s) - hétérogénéité par statut IUCN",
       color = "Catégorie IUCN") + 
  theme_minimal()

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present <- plot_did2s$k[plot_did2s$k < 0]
if(length(leads_present) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present, collapse="|"), ")$")
  print(fixest::wald(did2s_es, keep = keep_regex))
}
```

## Test pour l'hypothèse multiple

Dans notre analyse, nous testons 3 hypothèses. Or, que lorsqu'on teste beaucoup d'hypothèses, on augmente automatiquement le risque d'inférer à tort des effets significatifs, des problèmes de multiplicité des tests. Afin de mitiger ce risque, nous appliquerons pour ces hypothèses secondaires H2 et H3 la méthode de False Discovery Rate FDR) de @benjamini1995. Cette méthode propose de contrôler la proportion moyenne des faux positifs parmi les résultats déclarés significatifs.

Nous récupérons les p-values des tests de H2 et H3, puis nous les trions dans l'ordre croissant avant d'appliquer la règle BH. Nous considérons comme significatif tout test avec pBH​\<0.05.

```{r}

```

## Analyse de sensibilité de Rosenbaum

Vérification de la robustesse des résultats issus du matching face à un éventuel biais non observé en testant différentes valeurs de Γ, afin d'évaluer dans quelle mesure la présence d'un biais caché pourraient influencer les conclusions de l'analyse

## Effets hétérogènes

Estimation des effets hétérogènes en introduisant des interactions entre le traitement et les différentes variables différenciatrices dans un modèle de double DID pour explorer les effets différenciés des aires protégées sur les ménages en fonction des caractéristiques socio-démographiques et environnementales

Caractéristiques socio-démographiques et environnementales:

-   Sexe et âge du chef de ménage

-   Conditions environnementales (Pluviométrie, sécheresse)

-   Type de gouvernance des aires protégées (strictes (statuts IUCN I-IV) vs multi-usages ( statuts IUCN V-VI))

-   Distance aux aires protégées (5km, 10 km, 15 km) -\> même analyse que test de robustess? si oui, enlver de cette partie

## Impact sur l'inégalité intra-communautaire

-   Inégalité intra-communautaire (Z-score standardisée du wealth index)

## Pseudo Panel

-   Construction de cohorte de ménage

-   Estimation d'un modèle à effet fixe pour corriger les biais liées aux variables non observés

-   Pondérer les observations en fonction de la taille des cohortes

# Appendix

## Statistical power

-   Estimation de la puissance statistique pour détecter un effet d'au moins 7.5 centiles dans l'indice de richesse entre les groupes

-   EStimation de la probabilité à un seuil de puissance fixée à 0.8 avec un seuil de signification fixée à 0.05

-   **Mobilisation des données MIS 2011, MIS 2013 et MIS 2016 si la puissance statistique est insuffisante**

Test pour l'hypothèse multiple

La méthode "False Directory Rate" de Benjamini-Hochberg sera appliqué aux hypothèses H2 et H3 pour corriger le problème des tests multiples.

Analyse de sensibilité de Rosenbaum

Vérification de la robustesse des résultats issus du matching face à un éventuel biais non observé en testant différentes valeurs de Γ, afin d'évaluer dans quelle mesure la présence d'un biais caché pourraient influencer les conclusions de l'analyse

Effets hétérogènes

Estimation des effets hétérogènes en introduisant des interactions entre le traitement et les différentes variables différenciatrices dans un modèle de double DID pour explorer les effets différenciés des aires protégées sur les ménages en fonction des caractéristiques socio-démographiques et environnementales

Caractéristiques socio-démographiques et environnementales:

Sexe et âge du chef de ménage

Conditions environnementales (Pluviométrie, sécheresse)

Type de gouvernance des aires protégées (strictes (statuts IUCN I-IV) vs multi-usages ( statuts IUCN V-VI))

Distance aux aires protégées (5km, 10 km, 15 km) -\> même analyse que test de robustess? si oui, enlver de cette partie

Impact sur l'inégalité intra-communautaire

Inégalité intra-communautaire (Z-score standardisée du wealth index)

Pseudo Panel

Construction de cohorte de ménage

Estimation d'un modèle à effet fixe pour corriger les biais liées aux variables non observés

Pondérer les observations en fonction de la taille des cohortes

Appendix

Statistical power

Estimation de la puissance statistique pour détecter un effet d'au moins 7.5 centiles dans l'indice de richesse entre les groupes

EStimation de la probabilité à un seuil de puissance fixée à 0.8 avec un seuil de signification fixée à 0.05

Mobilisation des données MIS 2011, MIS 2013 et MIS 2016 si la puissance statistique est insuffisante

Analyse de sensibilité ==\> à voir
