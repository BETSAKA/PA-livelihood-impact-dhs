---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Sensitivity tests

Ce document fournit les différents tests de robustesse utilisés dans l'analyse. Cette étape est un aspect crucial pour garantir la fiabilité et de la validation de notre méthodologie.

## Test de sensibilité aux tailles de buffer

### Test pour une distance de 5 km

#### Assignation des traitements

```{r}
# Library
library(tidyverse) 
library(haven) 
library(sf) 
library(tmap) 
library(gt)  
library(geodata) 
library(writexl)
library(units) 
library(leaflet) 
library(readxl) 
library(glue)


# Systèmes de coordonnées de référence 
standard_crs <- 4326
mdg_crs <- 29702 

# On charge les données gps 
gps_1997_initial <- st_read("data/raw/dhs/DHS_1997/MDGE32FL/MDGE32FL.shp")
gps_2008_initial <- st_read("data/raw/dhs/DHS_2008/MDGE53FL/MDGE53FL.shp") 
gps_2011_initial <- st_read("data/raw/dhs/DHS_2011/MDGE61FL/MDGE61FL.shp") 
gps_2013_initial <- st_read("data/raw/dhs/DHS_2013/MDGE6AFL/MDGE6AFL.shp") 
gps_2016_initial <- st_read("data/raw/dhs/DHS_2016/MDGE71FL/MDGE71FL.shp")
gps_2021_initial <- st_read("data/raw/dhs/DHS_2021/MDGE81FL/MDGE81FL.shp")

# Fonction qui vérifie que les coordonnées ne sont pas nulles
check_coordinates <- function(dhs_gps, country_polygon, negate = FALSE) {
  dhs_gps %>%
    filter(LONGNUM != 0 | LATNUM != 0)
}

gps_1997 <- check_coordinates(gps_1997_initial, contour_mada)
gps_2008 <- check_coordinates(gps_2008_initial, contour_mada)
gps_2011 <- check_coordinates(gps_2011_initial, contour_mada)
gps_2013 <- check_coordinates(gps_2013_initial, contour_mada)
gps_2016 <- check_coordinates(gps_2016_initial, contour_mada)
gps_2021 <- check_coordinates(gps_2021_initial, contour_mada)

# Load boundary 
contour_mada <- gadm(country = "Madagascar", level = 0, path = "data") %>%
  st_as_sf() %>%
  st_set_crs(standard_crs)

# On charge les données des AP
wdpa_terrestre_mod <- st_read("data/derived/wdpa_terrestre_mod.shp") %>%
  rename(
    WDPA_PID = WDPA_PI,
    ORIG_NAME = ORIG_NA,
    DESIG_ENG = DESIG_E,
    DESIG_TYPE = DESIG_T,
    IUCN_CAT = IUCN_CA,   
    INT_CRIT = INT_CRI,
    REP_M_AREA = REP_M_A,
    REP_AREA = REP_ARE,
    NO_TK_AREA = NO_TK_A,
    STATUS_YR = STATUS_,
    GEOMETRY_TYPE = GEOMETR,
    AREA_KM2 = AREA_KM,
    area_km2 = are_km2
  ) %>% 
  st_make_valid() %>%
  st_transform(standard_crs)

# Intersection des AP de WDPA avec la limite de Madagascar
wdpa_terrestre <- wdpa_terrestre_mod %>%
  st_make_valid() %>%
  filter(rowSums(st_intersects(., contour_mada, sparse = FALSE)) > 0) %>%
  st_transform(mdg_crs) %>%
  mutate(
    area_m2  = as.numeric(st_area(.)),
    area_ha  = area_m2 / 1e4,
    area_km2 = area_m2 / 1e6
  ) %>%
  st_transform(standard_crs)

# Buffer de 5 km
buffer_dist <- 5000

# Spécification des AP avant-après 2008--------
wdpa_before_2008 <- wdpa_terrestre_mod %>%
  filter(STATUS_YR < 2008)
wdpa_from_2008 <- wdpa_terrestre_mod %>%
  filter(STATUS_YR >= 2008)

# Créer des buffers de 5 km autour des AP
buffer_5km_before_2008 <- 
  wdpa_before_2008 %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)


buffer_5km_from_2008 <- wdpa_from_2008  %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)

# Visualisation des cartes---------------------
tmap_mode("view")

tm_shape(contour_mada) + 
  tm_borders(col = "black", lwd = 1) +
  
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "blue", 
              col =  "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) +
  
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "darkgreen", 
              col = "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) + 
  
tm_shape(buffer_5km_from_2008) +
tm_borders(col = "darkgreen", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
  
tm_shape(buffer_5km_before_2008) +
tm_borders(col = "blue", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
tm_add_legend(
  type = "polygons", 
  fill = c("blue", "darkgreen"), 
  labels = c("avant 2008", "après 2008")) +
  tm_title("Aires protégées du WDPA par période de création</b><br/>Source: WDPA, 2024") +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE,
    legend.title.size = 1.2,
    legend.text.size = 0.8
  ) +
  tm_compass(type = "8star", position = c("right", "top")) +
  tm_scalebar(position = c("right", "bottom"))

# Classification des clusters---------------------------------------------------------
#| fig-cap: "Grappes d'enquêtes DHS par rapport aux aires protégées existantes"


classify_clusters_with_pa <- function(cluster_gps,
                                      buffer_before,   # union of <2008
                                      wdpa_after,      # polygons >=2008 (no union)
                                      buffer_dist = 5000,
                                      label_treat = "Treatment",
                                      label_excl  = "Excluded",
                                      label_ctrl  = "Control") {

  # per-PA buffers (keep attrs)
  wdpa_after_buf <- wdpa_after %>%
    st_transform(mdg_crs) %>%
    mutate(geometry = st_buffer(geometry, buffer_dist)) %>%
    st_transform(standard_crs)

  # flags
  in_after  <- st_within(cluster_gps, st_union(wdpa_after_buf),  sparse = FALSE)[,1]
  in_before <- st_within(cluster_gps, buffer_before,            sparse = FALSE)[,1]

  base <- cluster_gps %>%
    mutate(groupe = case_when(
      in_after & !in_before & URBAN_RURA == "R" ~ label_treat,
      in_before | URBAN_RURA == "U"            ~ label_excl,
      TRUE                                     ~ label_ctrl
    ))

  # enrich treated with oldest+nearest PA
  treated_pts <- base %>% filter(groupe == label_treat)

  if (nrow(treated_pts) == 0) return(base)

  cand <- st_join(treated_pts, wdpa_after_buf, join = st_within, left = FALSE) %>%
  mutate(
    .idx = match(WDPAID, wdpa_after$WDPAID),
    dist_km = as.numeric(
      st_distance(
        geometry,
        wdpa_after$geometry[.idx],
        by_element = TRUE
      )
    ) / 1000
  ) %>%
  dplyr::select(-.idx)

  best <- cand %>%
    group_by(DHSCLUST) %>%
    slice_min(STATUS_YR, with_ties = TRUE) %>%
    slice_min(dist_km,   with_ties = FALSE) %>%
    ungroup() %>%
    st_drop_geometry() %>%
    select(DHSYEAR, DHSCLUST, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

  base %>% left_join(best, by = c("DHSYEAR","DHSCLUST"))
}

gps_1997_class <- classify_clusters_with_pa(gps_1997, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2008_class <- classify_clusters_with_pa(gps_2008, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2011_class <- classify_clusters_with_pa(gps_2011, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2013_class <- classify_clusters_with_pa(gps_2013, buffer_5km_before_2008,
                                            wdpa_from_2008)
gps_2016_class <- classify_clusters_with_pa(gps_2016, buffer_5km_before_2008,
                                            wdpa_from_2008)
gps_2021_class <- classify_clusters_with_pa(gps_2021, buffer_5km_before_2008,
                                            wdpa_from_2008)


gps_all_class_5km <- bind_rows(
  gps_1997_class,
  gps_2008_class,
  gps_2011_class,
  gps_2013_class,
  gps_2016_class,
  gps_2021_class
)

# Créer un plot pour visualiser la carte des AP avec les clusters----------------------
tm_shape(buffer_5km_from_2008) +
  tm_borders("green", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +  
  tm_shape(buffer_5km_before_2008) +
  tm_borders("darkgreen", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "green", 
              fill_alpha = 0.5,
              col = "black", 
              fill.legend = tm_legend(title = "à partir de 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "darkgreen", 
              fill_alpha = 0.5, 
              col =  "black", 
              fill.legend = tm_legend(title = "avant 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(gps_all_class_5km) +
  tm_symbols(
    fill = "groupe", 
    fill.legend = tm_legend(title = "Groupes"),
    fill.scale = tm_scale(values = c("Treatment" = "red", "Control" = "blue", "Excluded" = "gray")),
     size = 0.5,
    shape = 21
  ) +
  tm_facets("DHSYEAR") +
  tm_add_legend(type = "polygons", 
                fill = c("green", "darkgreen"), 
                labels = c("à partir de 2008", "avant 2008")) +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE
  ) +
  tm_scalebar(position = c("left", "bottom"))

# Tableau récapitulatif du nombre de grappes d'enquête classées dans chaque groupe-----
treated_sub_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  mutate(subcat = case_when(
    !is.na(STATUS_YR) & DHSYEAR <  STATUS_YR ~ "Avant traitement",
    !is.na(STATUS_YR) & DHSYEAR >= STATUS_YR ~ "Déjà traités",
    TRUE ~ NA_character_
  )) %>%
  count(DHSYEAR, subcat, name = "n_clusters") %>%
  pivot_wider(names_from = subcat, values_from = n_clusters, values_fill = 0)

# Ligne "Ensemble" (tous les traités, quel que soit le statut)
treated_all_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  count(DHSYEAR, name = "Ensemble")

# Colonnes Contrôles / Exclus
ctrl_excl_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe %in% c("Control", "Excluded")) %>%
  mutate(Groupe = recode(groupe, Control = "Contrôles", Excluded = "Exclus")) %>%
  count(DHSYEAR, Groupe, name = "n") %>%
  pivot_wider(names_from = Groupe, values_from = n, values_fill = 0)

# Assemblage large (années en lignes)
tab_wide_clusters <- list(treated_sub_clusters, treated_all_clusters, 
                          ctrl_excl_clusters) %>%
  Reduce(function(x, y) full_join(x, y, by = "DHSYEAR"), .) %>%
  arrange(DHSYEAR) %>%
  mutate(across(-DHSYEAR, ~replace_na(.x, 0L)))

# Tableau gt : spanner "Traitement" + colonnes Contrôles / Exclus
gt_table_clusters <- tab_wide_clusters %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de grappes par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des grappes *Traitement*."),
    locations = cells_title(groups = "title")
  )

gt_table_clusters

# Tableau récapitulatif du nombre de ménages d'enquête classées dans chaque groupe-----
load_dhs_data <- function(dhs_folder, year, identifier) {
  folder_pattern <- paste0(".*", year, ".*", identifier)
  
  matching_folder <- list.dirs(dhs_folder, full.names = TRUE, recursive = TRUE) %>%
    keep(~ str_detect(.x, folder_pattern))
  
  if (length(matching_folder) == 0) {
    stop("No folder found for the specified year and identifier.")
  }
  
  if (identifier == "GE") {
    file_pattern <- "\\.shp$"
    data_loader <- function(file) st_read(file, quiet = TRUE)
  } else {
    file_pattern <- "\\.[Dd][Tt][Aa]$"
    data_loader <- read_dta
  }
  
  target_file <- list.files(matching_folder, pattern = file_pattern, full.names = TRUE)
  
  if (length(target_file) == 0) {
    stop("No valid file found in the folder.")
  }
  
  data <- data_loader(target_file)
  
  return(data)
}

dhs_folder <- "data/raw/dhs"


# Années disponibles
years_all <- sort(unique(gps_all_class_5km$DHSYEAR))

# Compte ménages (toutes observations) 
households_counts_all <- map_dfr(years_all, function(y) {
  # HR de l'année
  hr <- load_dhs_data(dhs_folder, y, "HR") %>%
    mutate(DHSYEAR = y)  # pour la jointure avec la classification

  # Classification des grappes de l'année
  cl_y <- gps_all_class_5km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == y) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)

  # Jointure ménages <- classification (par cluster hv001)
  hr_cl <- hr %>%
    select(DHSYEAR, hv001) %>%
    left_join(cl_y, by = c("DHSYEAR" = "DHSYEAR", "hv001" = "DHSCLUST"))

  # Comptes par sous-catégories du traitement (DHSYEAR vs STATUS_YR)
  avant  <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR <  STATUS_YR) %>% nrow()
  deja   <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR >= STATUS_YR) %>% nrow()
  ens    <- hr_cl %>% filter(groupe == "Treatment") %>% nrow()
  ctrl   <- hr_cl %>% filter(groupe == "Control")   %>% nrow()
  excl   <- hr_cl %>% filter(groupe == "Excluded")  %>% nrow()

  tibble(
    DHSYEAR = y,
    `Avant traitement` = avant,
    `Déjà traités`     = deja,
    Ensemble           = ens,
    `Contrôles`        = ctrl,
    `Exclus`           = excl
  )
})

# Tableau gt (ménages, toutes observations)
gt_table_menages_all <- households_counts_all %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de ménages par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0, use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des ménages du groupe *Traitement*."), locations = cells_title(groups = "title"))

gt_table_menages_all   

# Sauvegarde des classifications des clusters 
all_class_5km <- gps_all_class_5km %>%
  select(DHSYEAR, DHSCLUST, GROUP = groupe, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

write_csv(all_class_5km, "data/derived/cluster_treatment_classification_staggered_5km.csv")

write_csv(wdpa_before_2008, "data/derived/wdpa_before_2008_5km.csv")
write_csv(wdpa_from_2008, "data/derived/wdpa_from_2008_5km.csv")

# Classification des clusters avec les données HR des ménages--------------------------- 
for(year in years_all) {
  hr_data <- load_dhs_data(dhs_folder, year, "HR") %>%
    mutate(DHSYEAR = year)
  
  cluster_class <- gps_all_class_5km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == year) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)
  
  hr_final_5km <- hr_data %>%
    rename(DHSCLUST = hv001) %>%
    left_join(cluster_class, by = c("DHSYEAR", "DHSCLUST")) %>%
    
    mutate(treatment = if_else(groupe == "Treatment", 1L, 0L),
           control = if_else(groupe == "Control", 1L, 0L))
  
  saveRDS(hr_final_5km, glue("data/derived/hr_{year}_final_5km.rds"))
    
}
```

#### Covariates Calculation

```{r}
library(labelled) # Manipulation des labels
library(mapme.biodiversity)
library(progressr) # Pour avoir des barres de progression
library(tictoc) # Pour minuter le temps d'exécution
library(future) # Pour permettre du calcul parallèle

# Load data
buffer_all_5km <- gps_all_class_5km %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = 5000) %>%
  st_transform(standard_crs)

# Chargement des données géophysiques des ménages--------------------------------
# Définir le chemin relatif pour ton répertoire local

outdir <- "data/raw/mapme"
dir.create(outdir, recursive = TRUE, showWarnings = FALSE)
mapme_options(outdir = outdir, verbose = TRUE)


# Couvert forestier
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km  %>% 
    get_resources(get_gfw_treecover())
})
toc() # 1.25 sec elapsed 

# Perte de couvert
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_gfw_lossyear()) 
})
toc() # 1.15 sec elapsed 

# NASA SRTM
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_nasa_srtm()) 
})
toc() # 5.22 sec elapsed 

# Worldpop 2000
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>%
    get_resources(get_worldpop(years = 2000))
})
toc() # 0.22 sec elapsed 
  
# Accesibility
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_accessibility_2000()) 
})
toc() # 0.28 sec elapsed 

# Maximum temperatures
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_max_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 28.74 sec elapsed 

# Minimum temperatures
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_min_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 28.23 sec elapsed 

# Precipitations
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_precipitation(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 275.08 sec elapsed
  
```

Après chargement et extraction des données sur les données géophysiques des ménages, nous allons calculer les indicateurs des variables environnementales dans un rayon de 5 km autour de chaque grappe d'enquête.

```{r}
# Calcul des indicateurs------------------------------------------------------- 
if(file.exists("data/derived/spatial_covars_staggered_5km.rds")) {cat("Le fichier spatial_covars_staggered_5km.rds existe déjà")
} else {
    cat("Fichier introuvable, début du traitement... \n")
  
  # Créer un plan pour paralléliser les calculs
  plan(sequential)
  plan(multisession, workers = 4)
  
  # Maximum temperatures
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_temperature_max_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 34502.12 sec elapsed
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_max_temp.rds", compress = "gz")
  
  
  # Minimum temperatures
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
         calc_temperature_min_wc( engine = "extract", stats = "mean")
      )
  })
  toc() # 24445.67 sec elapsed 
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_min_temp.rds", compress = "gz")
  
  
  # Precipitations
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_precipitation_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # # 21007.7 sec elapsed 
 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_precip.rds", compress = "gz") 
  
  
  # Forest cover rate in 2000
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_treecover_area(years = 2000, min_size = 1, min_cover = 10)
      )
  })
  toc()   # 2392.16 sec elapsed
 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_treecover.rds", compress = "gz")
  
  
  # slope 
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_slope(engine = "extract", stats = "mean")
      )
  })
  toc() # 5995.94 sec elapsed  
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_slope.rds", compress = "gz")
  
  
  # Elevation
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_elevation(engine = "extract", stats = "mean")
      )
  })
  toc() # 2163.28 sec elapsed 
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_elevation.rds", compress = "gz")
  
  
  # Population density
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_population_count(engine = "extract", stats = "mean")
      )
  })
  toc() # 2134.34 sec elapsed
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_pop_density.rds", compress = "gz")
  
  
  # Accessibility
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_traveltime_2000(engine = "extract", stats = "mean")
      )
  })
  toc() # 2162.22 sec elapsed  
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_accessibility.rds", compress = "gz")
  
  # Enregistrement final des données 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_staggered_5km.rds")
 }
```

#### Spei calculation 

```{r}
library(SPEI) # Calcul de l'indice SPEI
library(labelled) # Manipulation des labels
library(tibbletime) # Manipulation des données temporelles 
library(zoo) # Manipulation des données temporelles 
library(readr) # Lecture des données de texte rectangulaires
library(ggplot2) # visualisation

# Load data 
spatial_covars_5km <- read_rds("data/derived/spatial_covars_staggered_5km.rds")

# Function to compute SPEI
compute_spei_annual <- function(tmin_tbl, tmax_tbl, prec_tbl, lat_deg) {
  # tmin_tbl/tmax_tbl/prec_tbl: tibbles avec colonnes `datetime` (Date) et `value` (num)
  d_tmin <- tibble(date = tmin_tbl$datetime, tmin = tmin_tbl$value)
  d_tmax <- tibble(date = tmax_tbl$datetime, tmax = tmax_tbl$value)
  d_prec <- tibble(date = prec_tbl$datetime, prec = prec_tbl$value)

  d_merged <- reduce(list(d_tmin, d_tmax, d_prec), left_join, by = "date") %>%
    arrange(date)

  d_clean <- drop_na(d_merged)  # supprime lignes avec NA

  # Si séries trop courtes, renvoyer squelette 1981:2021 en NA
  if (nrow(d_clean) < 12) {
    return(tibble(year = 1981:2021, spei_mean = NA_real_))
  }

  # PET (Hargreaves), bilan hydrique et SPEI mensuel
  pet <- hargreaves(Tmin = d_clean$tmin,
                    Tmax = d_clean$tmax,
                    Pre  = d_clean$prec,
                    lat  = lat_deg)

  wb <- d_clean$prec - pet

  wb_ts <- ts(wb,
              start = c(year(min(d_clean$date)), month(min(d_clean$date))),
              frequency = 12)

  spei_obj <- spei(wb_ts,
                   scale = 12,
                   ref.start = c(1981, 1),
                   ref.end   = c(2021, 12))

  tibble(datetime = d_clean$date,
         spei      = as.numeric(spei_obj$fitted)) %>%
    filter(datetime >= as.Date("1981-01-01"),
           datetime <= as.Date("2021-12-31")) %>%
    mutate(year = year(datetime)) %>%
    group_by(year) %>%
    summarise(spei_mean = mean(spei, na.rm = TRUE), .groups = "drop") %>%
    complete(year = 1981:2021, fill = list(spei_mean = NA_real_))
}



# Latitude géodésique depuis la géométrie (centroïde)
spatial_covars_spei_5km <- spatial_covars_5km %>%
  mutate(lat = st_coordinates(st_centroid(geometry))[, 2])

row1 <- spatial_covars_spei_5km[1, ]

spei_tbl_one <- compute_spei_annual(
  tmin_tbl = row1$temperature_min_wc[[1]],
  tmax_tbl = row1$temperature_max_wc[[1]],
  prec_tbl = row1$precipitation_wc[[1]],
  lat_deg  = row1$lat
)

# Graphique 
spei_2017 <- spei_tbl_one %>% 
  filter(year == 2017)

ggplot(spei_tbl_one, aes(x = year, y = spei_mean)) +
  geom_col(aes(y = pmax(0, -spei_mean)), alpha = 0.25) +  # barres pour sécheresse (optionnel)
  geom_line(linewidth = 0.8) +
  geom_vline(xintercept = 2017, color = "red", linetype = "dotted", linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label(
    data = spei_2017, 
    aes(x = 2017, y = spei_mean, 
        label = paste0("Année: 2017\nSPEI: ", round(spei_mean, 2))),
    nudge_x = 1, 
    nudge_y = 0.3,
    fill = "white",
    color = "black",
    linewidth = 0.4, 
    label.padding = unit(0.2, "lines")
  ) +
  
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI (scale=12) – cluster de démonstration",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# SPEI for all clusters 
spatial_covars_spei_5km <- spatial_covars_spei_5km %>%
  mutate(
    spei_wc = pmap(
      list(temperature_min_wc, temperature_max_wc, precipitation_wc, lat),
      ~ compute_spei_annual(..1, ..2, ..3, ..4)
    )
  )

spei_df <- spatial_covars_spei_5km %>%
  select(DHSCLUST, spei_wc) %>%
  unnest(spei_wc)

ggplot(spei_df, aes(x = year, y = spei_mean, group = DHSCLUST)) +
  geom_line(alpha = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI by cluster with 5 km buffer (1981–2021)",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# Chaque élément spei_wc devient une table {datetime, variable, unit, value}
spatial_covars_spei_5km <- spatial_covars_spei_5km %>%
  mutate(
    spei_wc = map(spei_wc, ~ .x %>%
      mutate(
        datetime = as.Date(paste0(.data$year, "-01-01")),
        variable = "spei_scale12_mean",
        unit     = "annual",
        value    = .data$spei_mean
      ) %>%
      select(datetime, variable, unit, value))
  )

# Sauvegarde (cohérente avec le reste de tes scripts)
spatial_covars_spei_df_5km <- as.data.frame(spatial_covars_spei_5km)
write_rds(spatial_covars_spei_df_5km, "data/derived/spatial_covars_spei_staggered_5km.rds")
cat("SPEI (annuel, 1981–2021) enregistré dans data/derived/spatial_covars_spei_staggered_5km.rds\n")
```

#### Variable consolidation

```{r}

library(lubridate)

# Covariates spatio-temporelles + classification de traitement
spatial_covars_spei_5km <- readRDS("data/derived/spatial_covars_spei_staggered_5km.rds")
all_covars <- spatial_covars_spei_5km %>%
  select(DHSYEAR, DHSCLUST, URBAN_RURA, treecover_area, slope, elevation,
         population_count, traveltime_2000, spei_wc)

all_class_5km <- read.csv("data/derived/cluster_treatment_classification_staggered_5km.csv")

# Helper: fabrique la table finale pour une année donnée
vars_to_nest <- c("treecover_area", "slope", "elevation",
                  "population_count", "traveltime_2000", "spei_wc")

build_year <- function(hr_object,
                       year,
                       hh_rural_path,
                       spei_years = (year-2):year) {

  # Charger HR (identifiants + variables chef) et HH_rural (centiles/zscore déjà calculés)
  hr <- hr_object %>%
    dplyr::select(hv001, hv002, hv219, hv220)
  
  hh_rural <- read_rds(hh_rural_path) # contient hv001/hv002 + wealth_* déjà prêts
  
  # Joindre covariates spatiaux + classification de groupes
  base <- hh_rural %>%
    left_join(hr, by = c("hv001", "hv002")) %>%
    left_join(
      all_covars %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    left_join(
      all_class_5km %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    mutate(DHSYEAR = year) %>%
    relocate(DHSYEAR, .before = everything())
  
  # Désimbriquer les covars imbriquées et appliquer la fenêtre temporelle SPEI
  #    moyenne par (hv001, hv002) pour chaque indicateur_année
  df_long <- base %>%
    select(hv001, hv002, any_of(vars_to_nest)) %>%
    pivot_longer(cols = any_of(vars_to_nest),
                 names_to = "indicator", values_to = "data") %>%
    unnest(data) %>%
    filter(indicator != "spei_wc" | year(datetime) %in% spei_years) %>%
    mutate(year_indicator = paste0(indicator, "_", year(datetime))) %>%
    select(hv001, hv002, year_indicator, value)
  
  df_wide <- df_long %>%
    pivot_wider(names_from = year_indicator, values_from = value,
                names_glue = "{year_indicator}") %>%
    group_by(hv001, hv002) %>%
    summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
  
  # Table finale (une ligne par ménage hv001/hv002)
  out <- base %>%
    select(-any_of(vars_to_nest)) %>%
    distinct(hv001, hv002, .keep_all = TRUE) %>%
    left_join(df_wide, by = c("hv001", "hv002"))
  
  out
}

# Application

hr_1997_final_5km <- read_dta("data/raw/dhs/DHS_1997/MDHR31DT/MDHR31FL.DTA") %>%
  build_year(year = 1997,
             hh_rural_path = "data/derived/hh_1997_rural_simpler.rds",
             spei_years = 1995:1997)

hr_2008_final_5km <- read_dta("data/raw/dhs/DHS_2008/MDHR51DT/MDHR51FL.DTA") %>%
  build_year(year = 2008,
             hh_rural_path = "data/derived/hh_2008_rural_simpler.rds",
             spei_years = 2006:2008)

hr_2011_final_5km <- read_dta("data/raw/dhs/DHS_2011/MDHR61DT/MDHR61FL.DTA") %>%
  build_year(year = 2011,
             hh_rural_path = "data/derived/hh_2011_rural_simpler.rds",
             spei_years = 2009:2011)

hr_2013_final_5km <- read_dta("data/raw/dhs/DHS_2013/MDHR6ADT/MDHR6AFL.DTA") %>%
  build_year(year = 2013,
  hh_rural_path = "data/derived/hh_2013_rural_simpler.rds",
  spei_years = 2011:2013)

hr_2016_final_5km <- read_dta("data/raw/dhs/DHS_2016/MDHR71DT/MDHR71FL.DTA") %>%
  build_year(year = 2016,
  hh_rural_path = "data/derived/hh_2016_rural_simpler.rds",
  spei_years = 2014:2016)

hr_2021_final_5km <- read_dta("data/raw/dhs/DHS_2021/MDHR81DT/MDHR81FL.DTA") %>%
  build_year(year = 2021,
  hh_rural_path = "data/derived/hh_2021_rural_simpler.rds",
  spei_years = 2019:2021)

# Consolidation

hr_consolidated_5km <- bind_rows(
  hr_1997_final_5km,
  hr_2008_final_5km,
  hr_2011_final_5km,
  hr_2013_final_5km,
  hr_2016_final_5km,
  hr_2021_final_5km
)

hr_consolidated_5km %>% count(DHSYEAR)

# Sauvegardes millésime
write_rds(hr_1997_final_5km, "data/derived/hr_1997_final_5km.rds")
write_rds(hr_2008_final_5km, "data/derived/hr_2008_final_5km.rds")
write_rds(hr_2011_final_5km, "data/derived/hr_2011_final_5km.rds")
write_rds(hr_2013_final_5km, "data/derived/hr_2013_final_5km.rds")
write_rds(hr_2016_final_5km, "data/derived/hr_2016_final_5km.rds")
write_rds(hr_2021_final_5km, "data/derived/hr_2021_final_5km.rds")

# Sauvegarde consolidée
write_rds(hr_consolidated_5km, "data/derived/hr_consolidated_5km_1997_2008_2011_2013_2016_2021.rds")
cat("Données enregistrées\n")
```

#### Matching

```{r}
# Library 
library(rbounds) # Analyse de sensibilité
library(rgenoud) # Implementation de l'algorithme génétique
library(Matching) # Estimation des effets de traitement causaux
library(progressr) # Suivi de progression
library(rlang)
library(car)
library(tibble)
library(qqplotr) # pour créer la bande de confiance
library(halfmoon)
library(cobalt)
library(ggpubr)

matching_variables <- c(
  "treecover_area_2000","slope_2000","elevation_2000",
  "population_count_2000","traveltime_2000_2000"
)

prep_matching <- function(df_final) {
  out <- df_final %>%
    filter(GROUP %in% c("Treatment","Control")) %>%
    mutate(treatment = if_else(GROUP == "Treatment", 1L, 0L))
  
  missing_cols <- setdiff(matching_variables, names(out))
  if (length(missing_cols) > 0) {
    message(">> Colonnes manquantes: ", paste(missing_cols, collapse=", "))
  }
  
  out %>% drop_na(all_of(intersect(matching_variables, names(out))))
}

# supprimer toute ancienne version pour éviter le masquage
if (exists("run_matching_year")) rm(run_matching_year)

run_matching_year <- function(year, overwrite = list(gen=FALSE, match=FALSE)) {
  cat("\n=== Matching", year, "===\n")
  fin_path <- glue("data/derived/hr_{year}_final_5km.rds")
  if (!file.exists(fin_path)) stop("Fichier introuvable: ", fin_path)
  
  dat   <- readRDS(fin_path)
  dat_m <- prep_matching(dat)
  
  
  n_total <- nrow(dat)
  n_filt <- nrow(dat_m)
  n_treat <- sum(dat_m$treatment == 1, na.rm = TRUE)
  n_ctrl <- sum(dat_m$treatment == 0, na.rm = TRUE)
  
  
  cat(glue(">> N total={n_total}, après filtre/NA={n_filt}; ",
           "Traités={n_treat}, ",
           "Contrôles={n_ctrl}\n"))
  
  have_all_vars <- all(matching_variables %in% names(dat_m))
  cat(">> Toutes les covars présentes ? ", have_all_vars, "\n")
  if (n_filt < 5 || !have_all_vars) {
    warning(glue("Année {year}: données insuffisantes ou variables manquantes — on saute."))
    return(NULL)
  }
  
  X_match <- dat_m %>%
    sf::st_drop_geometry() %>%
    dplyr::select(all_of(matching_variables)) %>%
    as.data.frame()
  
  gen_path         <- glue("data/derived/gen_match_model_{year}_5km.rds")
  match_path       <- glue("data/derived/matching_result_{year}_5km.rds")
  matched_out_path <- glue("data/derived/data_matched_{year}_5km.rds")
  
  # --- GenMatch ---
  used_cache_gen <- FALSE
  t0 <- Sys.time()
  if (file.exists(gen_path) && !isTRUE(overwrite$gen)) {
    cat(">> GenMatch: cache trouvé -> lecture\n")
    gen_model <- readRDS(gen_path)
    used_cache_gen <- TRUE
  } else {
    cat(">> GenMatch: calcul en cours...\n")
    gen_model <- GenMatch(
      Tr = dat_m$treatment,
      X  = X_match,
      BalanceMatrix = X_match,
      estimand = "ATT",
      M = 1,
      weights = NULL,
      pop.size = 1000,
      max.generations = 100,
      wait.generations = 4,
      caliper = .25,
      print.level = 1,
      cluster = rep("localhost", 4)
    )
    saveRDS(gen_model, gen_path)
  }
  t_gen <- as.numeric(difftime(Sys.time(), t0, units="mins"))
  cat(glue(">> GenMatch temps = {round(t_gen,1)} min (cache={used_cache_gen})\n"))
  
  # --- matchit() ---
  used_cache_match <- FALSE
  t1 <- Sys.time()
  if (file.exists(match_path) && !isTRUE(overwrite$match)) {
    cat(">> matchit: cache trouvé → lecture\n")
    m_out <- readRDS(match_path)
    used_cache_match <- TRUE
  } else {
    cat(">> matchit: calcul en cours...\n")
    fml <- as.formula(paste("treatment ~", paste(matching_variables, collapse=" + ")))
   
    
     m_out <- matchit(
      formula   = fml,
      data      = dat_m,
      method    = "genetic",
      distance  = "mahalanobis",
      gen.match = gen_model
    )
     
    saveRDS(m_out, match_path)
  }
  
  matched <- match.data(m_out, data = sf::st_drop_geometry(dat_m)) %>%
    dplyr::filter(weights > 0)
  
  saveRDS(matched, matched_out_path)
  cat(glue(">> N appariés = {nrow(matched)} (écrit: {matched_out_path})\n"))
  
  
  tibble(
    Année = year,
    'Total des observations' = n_total,
    'Après filtre/NA' = n_filt,
    Traités = n_treat,
    Contrôles = n_ctrl,
    'N appariés' = nrow(matched)
  )
}

need_overwrite <- function(year) {
  gen_path   <- glue("data/derived/gen_match_model_{year}_5km.rds")
  match_path <- glue("data/derived/matching_result_{year}_5km.rds")
  list(gen = !file.exists(gen_path), match = !file.exists(match_path))
}

# --- Exécution avec progression ---
yrs <- c(1997, 2008, 2011, 2013, 2016, 2021)


res_list <- vector("list", length(yrs))
names(res_list) <- yrs

with_progress({
  p <- progressor(along = yrs)

for (i in seq_along(yrs)) {
  yr <- yrs[i]
  ow <- need_overwrite(yr) 
  cat(glue("\n>> overwrite {yr}: gen={ow$gen}, match={ow$match}\n"))
  cat(sprintf("Start %s", yr))
  t_all <- Sys.time()
  res_list[[i]] <- tryCatch(
    run_matching_year(yr, overwrite = ow),
    error = function(e) { warning(glue("Year {yr} ERROR: {e$message}")); NULL }
  )
  cat(sprintf("Done %s (%.1f min)",
            yr, as.numeric(difftime(Sys.time(), t_all, units="mins"))))
}
})

result_list <- purrr::compact(res_list) |> bind_rows()
saveRDS(result_list, "data/derived/matching_summary_all_years_5km.rds")

bal_tabs <- purrr::imap(res_list, ~ {if (!is.null(.x)) {
  tryCatch(cobalt::bal.tab(.x$m), error = function(e) NULL) } else {
    NULL
  }
})

saveRDS(bal_tabs, "data/derived/matching_balance_tabs_all_years_5km.rds")

print(result_list)
```

#### Estimation_staggered

### Test pour une distance de 15km

#### Assignation du traitement

```{r}
# Buffer de 15 km
buffer_dist <- 15000

# Créer des buffers de 15 km autour des AP
buffer_15km_before_2008 <- wdpa_before_2008 %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)


buffer_15km_from_2008 <- wdpa_from_2008  %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)

# Visualisation des cartes---------------------
tmap_mode("view")

tm_shape(contour_mada) + 
  tm_borders(col = "black", lwd = 1) +
  
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "blue", 
              col =  "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) +
  
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "darkgreen", 
              col = "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) + 
  
tm_shape(buffer_15km_from_2008) +
tm_borders(col = "darkgreen", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
  
tm_shape(buffer_15km_before_2008) +
tm_borders(col = "blue", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
tm_add_legend(
  type = "polygons", 
  fill = c("blue", "darkgreen"), 
  labels = c("avant 2008", "après 2008")) +
  tm_title("Aires protégées du WDPA par période de création</b><br/>Source: WDPA, 2024") +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE,
    legend.title.size = 1.2,
    legend.text.size = 0.8
  ) +
  tm_compass(type = "8star", position = c("right", "top")) +
  tm_scalebar(position = c("right", "bottom"))

# Classification des clusters---------------------------------------------------------
#| fig-cap: "Grappes d'enquêtes DHS par rapport aux aires protégées existantes"


classify_clusters_with_pa <- function(cluster_gps,
                                      buffer_before,   # union of <2008
                                      wdpa_after,      # polygons >=2008 (no union)
                                      buffer_dist = 15000,
                                      label_treat = "Treatment",
                                      label_excl  = "Excluded",
                                      label_ctrl  = "Control") {

  # per-PA buffers (keep attrs)
  wdpa_after_buf <- wdpa_after %>%
    st_transform(mdg_crs) %>%
    mutate(geometry = st_buffer(geometry, buffer_dist)) %>%
    st_transform(standard_crs)

  # flags
  in_after  <- st_within(cluster_gps, st_union(wdpa_after_buf),  sparse = FALSE)[,1]
  in_before <- st_within(cluster_gps, buffer_before,            sparse = FALSE)[,1]

  base <- cluster_gps %>%
    mutate(groupe = case_when(
      in_after & !in_before & URBAN_RURA == "R" ~ label_treat,
      in_before | URBAN_RURA == "U"            ~ label_excl,
      TRUE                                     ~ label_ctrl
    ))

  # enrich treated with oldest+nearest PA
  treated_pts <- base %>% filter(groupe == label_treat)

  if (nrow(treated_pts) == 0) return(base)

  cand <- st_join(treated_pts, wdpa_after_buf, join = st_within, left = FALSE) %>%
  mutate(
    .idx = match(WDPAID, wdpa_after$WDPAID),
    dist_km = as.numeric(
      st_distance(
        geometry,
        wdpa_after$geometry[.idx],
        by_element = TRUE
      )
    ) / 1000
  ) %>%
  dplyr::select(-.idx)

  best <- cand %>%
    group_by(DHSCLUST) %>%
    slice_min(STATUS_YR, with_ties = TRUE) %>%
    slice_min(dist_km,   with_ties = FALSE) %>%
    ungroup() %>%
    st_drop_geometry() %>%
    select(DHSYEAR, DHSCLUST, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

  base %>% left_join(best, by = c("DHSYEAR","DHSCLUST"))
}

gps_1997_class <- classify_clusters_with_pa(gps_1997, buffer_15km_before_2008, 
                                            wdpa_from_2008)
gps_2008_class <- classify_clusters_with_pa(gps_2008, buffer_15km_before_2008, 
                                            wdpa_from_2008)
gps_2011_class <- classify_clusters_with_pa(gps_2011, buffer_15km_before_2008, 
                                            wdpa_from_2008)
gps_2013_class <- classify_clusters_with_pa(gps_2013, buffer_15km_before_2008,
                                            wdpa_from_2008)
gps_2016_class <- classify_clusters_with_pa(gps_2016, buffer_15km_before_2008,
                                            wdpa_from_2008)
gps_2021_class <- classify_clusters_with_pa(gps_2021, buffer_15km_before_2008,
                                            wdpa_from_2008)


gps_all_class_15km <- bind_rows(
  gps_1997_class,
  gps_2008_class,
  gps_2011_class,
  gps_2013_class,
  gps_2016_class,
  gps_2021_class
)

# Créer un plot pour visualiser la carte des AP avec les clusters----------------------
tm_shape(buffer_15km_from_2008) +
  tm_borders("green", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +  
  tm_shape(buffer_15km_before_2008) +
  tm_borders("darkgreen", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "green", 
              fill_alpha = 0.5,
              col = "black", 
              fill.legend = tm_legend(title = "à partir de 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "darkgreen", 
              fill_alpha = 0.5, 
              col =  "black", 
              fill.legend = tm_legend(title = "avant 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(gps_all_class_15km) +
  tm_symbols(
    fill = "groupe", 
    fill.legend = tm_legend(title = "Groupes"),
    fill.scale = tm_scale(values = c("Treatment" = "red", "Control" = "blue", "Excluded" = "gray")),
     size = 0.5,
    shape = 21
  ) +
  tm_facets("DHSYEAR") +
  tm_add_legend(type = "polygons", 
                fill = c("green", "darkgreen"), 
                labels = c("à partir de 2008", "avant 2008")) +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE
  ) +
  tm_scalebar(position = c("left", "bottom"))

# Tableau récapitulatif du nombre de grappes d'enquête classées dans chaque groupe-----
treated_sub_clusters <- gps_all_class_15km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  mutate(subcat = case_when(
    !is.na(STATUS_YR) & DHSYEAR <  STATUS_YR ~ "Avant traitement",
    !is.na(STATUS_YR) & DHSYEAR >= STATUS_YR ~ "Déjà traités",
    TRUE ~ NA_character_
  )) %>%
  count(DHSYEAR, subcat, name = "n_clusters") %>%
  pivot_wider(names_from = subcat, values_from = n_clusters, values_fill = 0)

# Ligne "Ensemble" (tous les traités, quel que soit le statut)
treated_all_clusters <- gps_all_class_15km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  count(DHSYEAR, name = "Ensemble")

# Colonnes Contrôles / Exclus
ctrl_excl_clusters <- gps_all_class_15km %>%
  st_drop_geometry() %>%
  filter(groupe %in% c("Control", "Excluded")) %>%
  mutate(Groupe = recode(groupe, Control = "Contrôles", Excluded = "Exclus")) %>%
  count(DHSYEAR, Groupe, name = "n") %>%
  pivot_wider(names_from = Groupe, values_from = n, values_fill = 0)

# Assemblage large (années en lignes)
tab_wide_clusters <- list(treated_sub_clusters, treated_all_clusters, 
                          ctrl_excl_clusters) %>%
  Reduce(function(x, y) full_join(x, y, by = "DHSYEAR"), .) %>%
  arrange(DHSYEAR) %>%
  mutate(across(-DHSYEAR, ~replace_na(.x, 0L)))

# Tableau gt : spanner "Traitement" + colonnes Contrôles / Exclus
gt_table_clusters <- tab_wide_clusters %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de grappes par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des grappes *Traitement*."),
    locations = cells_title(groups = "title")
  )

gt_table_clusters

# Tableau récapitulatif du nombre de ménages d'enquête classées dans chaque groupe-----
load_dhs_data <- function(dhs_folder, year, identifier) {
  folder_pattern <- paste0(".*", year, ".*", identifier)
  
  matching_folder <- list.dirs(dhs_folder, full.names = TRUE, recursive = TRUE) %>%
    keep(~ str_detect(.x, folder_pattern))
  
  if (length(matching_folder) == 0) {
    stop("No folder found for the specified year and identifier.")
  }
  
  if (identifier == "GE") {
    file_pattern <- "\\.shp$"
    data_loader <- function(file) st_read(file, quiet = TRUE)
  } else {
    file_pattern <- "\\.[Dd][Tt][Aa]$"
    data_loader <- read_dta
  }
  
  target_file <- list.files(matching_folder, pattern = file_pattern, full.names = TRUE)
  
  if (length(target_file) == 0) {
    stop("No valid file found in the folder.")
  }
  
  data <- data_loader(target_file)
  
  return(data)
}

dhs_folder <- "data/raw/dhs"


# Années disponibles
years_all <- sort(unique(gps_all_class_15km$DHSYEAR))

# Compte ménages (toutes observations) 
households_counts_all <- map_dfr(years_all, function(y) {
  # HR de l'année
  hr <- load_dhs_data(dhs_folder, y, "HR") %>%
    mutate(DHSYEAR = y)  # pour la jointure avec la classification

  # Classification des grappes de l'année
  cl_y <- gps_all_class_15km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == y) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)

  # Jointure ménages <- classification (par cluster hv001)
  hr_cl <- hr %>%
    select(DHSYEAR, hv001) %>%
    left_join(cl_y, by = c("DHSYEAR" = "DHSYEAR", "hv001" = "DHSCLUST"))

  # Comptes par sous-catégories du traitement (DHSYEAR vs STATUS_YR)
  avant  <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR <  STATUS_YR) %>% nrow()
  deja   <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR >= STATUS_YR) %>% nrow()
  ens    <- hr_cl %>% filter(groupe == "Treatment") %>% nrow()
  ctrl   <- hr_cl %>% filter(groupe == "Control")   %>% nrow()
  excl   <- hr_cl %>% filter(groupe == "Excluded")  %>% nrow()

  tibble(
    DHSYEAR = y,
    `Avant traitement` = avant,
    `Déjà traités`     = deja,
    Ensemble           = ens,
    `Contrôles`        = ctrl,
    `Exclus`           = excl
  )
})

# Tableau gt (ménages, toutes observations)
gt_table_menages_all <- households_counts_all %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de ménages par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0, use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des ménages du groupe *Traitement*."), locations = cells_title(groups = "title"))

gt_table_menages_all   

# Sauvegarde des classifications des clusters 
all_class_15km <- gps_all_class_15km %>%
  select(DHSYEAR, DHSCLUST, GROUP = groupe, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

write_csv(all_class_15km, "data/derived/cluster_treatment_classification_staggered_15km.csv")

write_csv(wdpa_before_2008, "data/derived/wdpa_before_2008_15km.csv")
write_csv(wdpa_from_2008, "data/derived/wdpa_from_2008_15km.csv")

# Classification des clusters avec les données HR des ménages--------------------------- 
for(year in years_all) {
  hr_data <- load_dhs_data(dhs_folder, year, "HR") %>%
    mutate(DHSYEAR = year)
  
  cluster_class <- gps_all_class_15km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == year) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)
  
  hr_final_15km <- hr_data %>%
    rename(DHSCLUST = hv001) %>%
    left_join(cluster_class, by = c("DHSYEAR", "DHSCLUST")) %>%
    
    mutate(treatment = if_else(groupe == "Treatment", 1L, 0L),
           control = if_else(groupe == "Control", 1L, 0L))
  
  saveRDS(hr_final_15km, glue("data/derived/hr_{year}_final_15km.rds"))
    
}
```

#### Covariates Calculation

```{r}
# Load data
buffer_all_15km <- gps_all_class_15km %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = 15000) %>%
  st_transform(standard_crs)

# Chargement des données géophysiques des ménages--------------------------------
# Définir le chemin relatif pour ton répertoire local

outdir <- "data/raw/mapme"
dir.create(outdir, recursive = TRUE, showWarnings = FALSE)
mapme_options(outdir = outdir, verbose = TRUE)


# Couvert forestier
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km  %>% 
    get_resources(get_gfw_treecover())
})
toc() # 1.18 sec elapsed 

# Perte de couvert
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% 
  get_resources(get_gfw_lossyear()) 
})
toc() # 1.39 sec elapsed 

# NASA SRTM
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% 
  get_resources(get_nasa_srtm()) 
})
toc() # 5.41 sec elapsed 

# Worldpop 2000
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>%
    get_resources(get_worldpop(years = 2000))
})
toc() # 0.27 sec elapsed 
  
# Accesibility
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% 
  get_resources(get_accessibility_2000()) 
})
toc() # 0.25 sec elapsed 

# Maximum temperatures
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% get_resources(
    get_worldclim_max_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 86.71 sec elapsed 

# Minimum temperatures
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% get_resources(
    get_worldclim_min_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 93.67 sec elapsed 

# Precipitations
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% get_resources(
    get_worldclim_precipitation(years = 1980:2021, resolution = "2.5m")
  )
})
toc() #  25.87 sec elapsed
  
```

Après chargement et extraction des données sur les données géophysiques des ménages, nous allons calculer les indicateurs des variables environnementales dans un rayon de 15 km autour de chaque grappe d'enquête.

```{r}
# Calcul des indicateurs------------------------------------------------------- 
if(file.exists("data/derived/spatial_covars_staggered_15km.rds")) {cat("Le fichier spatial_covars_staggered_15km.rds existe déjà")
} else {
    cat("Fichier introuvable, début du traitement... \n")
  
  # Créer un plan pour paralléliser les calculs
  plan(sequential)
  plan(multisession, workers = 4)
  
  # Maximum temperatures
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_temperature_max_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 28053.12 sec elapsed
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_max_temp_15km.rds", compress = "gz")
   
  
  # Minimum temperatures
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
         calc_temperature_min_wc( engine = "extract", stats = "mean")
      )
  })
  toc() # 26406.66 sec elapsed 
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_min_temp_15km.rds", compress = "gz")
  
  
  # Precipitations
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_precipitation_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 18938.39 sec elapsed 
 
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_precip_15km.rds", compress = "gz") 
  
  
  # Forest cover rate in 2000
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_treecover_area(years = 2000, min_size = 1, min_cover = 10)
      )
  })
  toc()   # 8712.08 sec elapsed
 
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_treecover_15km.rds", compress = "gz")
  
  
  # slope 
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_slope(engine = "extract", stats = "mean")
      )
  })
  toc() # 7270.96 sec elapsed  
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_slope_15km.rds", compress = "gz")
  
  
  # Elevation
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_elevation(engine = "extract", stats = "mean")
      )
  })
  toc() # 8016.01 sec elapsed 
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_elevation_15km.rds", compress = "gz")
  
  
  # Population density
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_population_count(engine = "extract", stats = "mean")
      )
  })
  toc() # 544.9 sec elapsed
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_pop_density_15km.rds", compress = "gz")
  
  
  # Accessibility
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_traveltime_2000(engine = "extract", stats = "mean")
      )
  })
  toc() # 289.5 sec elapsed  
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_accessibility_15km.rds", compress = "gz")
  
  # Enregistrement final des données 
  write_rds(buffer_all_15km, "data/derived/spatial_covars_staggered_15km.rds")
 }
```

-   Matching
-   Test d'équilibre
-   DID
-   Test de robustesse

## Test pour l'hypothèse multiple

La méthode "False Directory Rate" de Benjamini-Hochberg sera appliqué aux hypothèses H2 et H3 pour corriger le problème des tests multiples.

## Analyse de sensibilité de Rosenbaum

Vérification de la robustesse des résultats issus du matching face à un éventuel biais non observé en testant différentes valeurs de Γ, afin d'évaluer dans quelle mesure la présence d'un biais caché pourraient influencer les conclusions de l'analyse

## Effets hétérogènes

Estimation des effets hétérogènes en introduisant des interactions entre le traitement et les différentes variables différenciatrices dans un modèle de double DID pour explorer les effets différenciés des aires protégées sur les ménages en fonction des caractéristiques socio-démographiques et environnementales

Caractéristiques socio-démographiques et environnementales:

-   Sexe et âge du chef de ménage

-   Conditions environnementales (Pluviométrie, sécheresse)

-   Type de gouvernance des aires protégées (strictes (statuts IUCN I-IV) vs multi-usages ( statuts IUCN V-VI))

-   Distance aux aires protégées (5km, 10 km, 15 km) -\> même analyse que test de robustess? si oui, enlver de cette partie

## Impact sur l'inégalité intra-communautaire

-   Inégalité intra-communautaire (Z-score standardisée du wealth index)

## Pseudo Panel

-   Construction de cohorte de ménage

-   Estimation d'un modèle à effet fixe pour corriger les biais liées aux variables non observés

-   Pondérer les observations en fonction de la taille des cohortes

# Appendix

## Statistical power

-   Estimation de la puissance statistique pour détecter un effet d'au moins 7.5 centiles dans l'indice de richesse entre les groupes

-   EStimation de la probabilité à un seuil de puissance fixée à 0.8 avec un seuil de signification fixée à 0.05

-   **Mobilisation des données MIS 2011, MIS 2013 et MIS 2016 si la puissance statistique est insuffisante**

Analyse de sensibilité ==\> à voir

Tests de robustesse

Test de sensibilité aux tailles de buffer

Test pour une distance de 5 km

Création d'un buffer de 5 km autour des aires protégées

Réassignation des traitements

Matching

Test d'équilibre

DID

Test de robustesse

Test pour une distance de 15km

Création d'un buffer de 15 km autour des aires protégées Matching DID Test de robustesse

Réassignation des traitements

Matching

Test d'équilibre

DID

Test de robustesse

Test pour l'hypothèse multiple

La méthode "False Directory Rate" de Benjamini-Hochberg sera appliqué aux hypothèses H2 et H3 pour corriger le problème des tests multiples.

Analyse de sensibilité de Rosenbaum

Vérification de la robustesse des résultats issus du matching face à un éventuel biais non observé en testant différentes valeurs de Γ, afin d'évaluer dans quelle mesure la présence d'un biais caché pourraient influencer les conclusions de l'analyse

Effets hétérogènes

Estimation des effets hétérogènes en introduisant des interactions entre le traitement et les différentes variables différenciatrices dans un modèle de double DID pour explorer les effets différenciés des aires protégées sur les ménages en fonction des caractéristiques socio-démographiques et environnementales

Caractéristiques socio-démographiques et environnementales:

Sexe et âge du chef de ménage

Conditions environnementales (Pluviométrie, sécheresse)

Type de gouvernance des aires protégées (strictes (statuts IUCN I-IV) vs multi-usages ( statuts IUCN V-VI))

Distance aux aires protégées (5km, 10 km, 15 km) -\> même analyse que test de robustess? si oui, enlver de cette partie

Impact sur l'inégalité intra-communautaire

Inégalité intra-communautaire (Z-score standardisée du wealth index)

Pseudo Panel

Construction de cohorte de ménage

Estimation d'un modèle à effet fixe pour corriger les biais liées aux variables non observés

Pondérer les observations en fonction de la taille des cohortes

Appendix

Statistical power

Estimation de la puissance statistique pour détecter un effet d'au moins 7.5 centiles dans l'indice de richesse entre les groupes

EStimation de la probabilité à un seuil de puissance fixée à 0.8 avec un seuil de signification fixée à 0.05

Mobilisation des données MIS 2011, MIS 2013 et MIS 2016 si la puissance statistique est insuffisante

Analyse de sensibilité ==\> à voir
