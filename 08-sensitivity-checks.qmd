---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Sensitivity tests

Ce document fournit les différents tests de robustesse utilisés dans l'analyse. Cette étape est un aspect crucial pour garantir la fiabilité et de la validation de notre méthodologie.

## Test de sensibilité aux tailles de buffer

### Test pour une distance de 5 km

#### Assignation des traitements

```{r}
# Library
library(tidyverse) 
library(haven) 
library(sf) 
library(tmap) 
library(gt)  
library(geodata) 
library(writexl)
library(units) 
library(leaflet) 
library(readxl) 
library(glue)

# Systèmes de coordonnées de référence 
standard_crs <- 4326
mdg_crs <- 29702 

# On charge les données gps 
gps_1997_initial <- st_read("data/raw/dhs/DHS_1997/MDGE32FL/MDGE32FL.shp")
gps_2008_initial <- st_read("data/raw/dhs/DHS_2008/MDGE53FL/MDGE53FL.shp") 
gps_2011_initial <- st_read("data/raw/dhs/DHS_2011/MDGE61FL/MDGE61FL.shp") 
gps_2013_initial <- st_read("data/raw/dhs/DHS_2013/MDGE6AFL/MDGE6AFL.shp") 
gps_2016_initial <- st_read("data/raw/dhs/DHS_2016/MDGE71FL/MDGE71FL.shp")
gps_2021_initial <- st_read("data/raw/dhs/DHS_2021/MDGE81FL/MDGE81FL.shp")

# Fonction qui vérifie que les coordonnées ne sont pas nulles
check_coordinates <- function(dhs_gps, country_polygon, negate = FALSE) {
  dhs_gps %>%
    filter(LONGNUM != 0 | LATNUM != 0)
}

gps_1997 <- check_coordinates(gps_1997_initial, contour_mada)
gps_2008 <- check_coordinates(gps_2008_initial, contour_mada)
gps_2011 <- check_coordinates(gps_2011_initial, contour_mada)
gps_2013 <- check_coordinates(gps_2013_initial, contour_mada)
gps_2016 <- check_coordinates(gps_2016_initial, contour_mada)
gps_2021 <- check_coordinates(gps_2021_initial, contour_mada)


# On charge les données des AP
wdpa_terrestre_mod <- st_read("data/derived/wdpa_terrestre_mod.shp")
wdpa_terrestre_mod <- wdpa_terrestre_mod %>%
  dplyr::rename(
    WDPA_PID = WDPA_PI,
    ORIG_NAME = ORIG_NA,
    DESIG_ENG = DESIG_E,
    DESIG_TYPE = DESIG_T,
    IUCN_CAT = IUCN_CA,   
    INT_CRIT = INT_CRI,
    REP_M_AREA = REP_M_A,
    REP_AREA = REP_ARE,
    NO_TK_AREA = NO_TK_A,
    STATUS_YR = STATUS_,
    GEOMETRY_TYPE = GEOMETR,
    AREA_KM2 = AREA_KM,
    area_km2 = are_km2
  )


# Spécification des AP avant-après 2008 avec un Buffer de 5 km------------------------
buffer_dist <- 5000 
wdpa_before_2008 <- wdpa_terrestre_mod %>%
  filter(STATUS_YR < 2008)
wdpa_from_2008 <- wdpa_terrestre_mod %>%
  filter(STATUS_YR >= 2008)

# Créer des buffers de 5 km autour des AP
buffer_5km_before_2008 <- wdpa_before_2008 %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)

buffer_5km_from_2008 <- wdpa_from_2008  %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>% 
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)

# Visualisation des cartes------------------------------------------------------------ 
tm_shape(wdpa_before_2008) +
tm_polygons(fill = "blue", 
            col =  "black", 
            fill_alpha = 0.5) +
tm_shape(buffer_5km_from_2008) +
tm_borders(col = "darkgreen", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
tm_shape(buffer_5km_before_2008) +
tm_borders(col = "blue", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
tm_shape(wdpa_from_2008) +
tm_polygons(fill = "darkgreen", 
            col = "black", 
            fill_alpha = 0.5) +
tm_add_legend(type = "polygons", fill = c("blue", "darkgreen"), labels = c("avant 2008", "après 2008")) +
  tm_title("Aires protégées du WDPA par période de création</b><br/>Source: WDPA, 2024") +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE,
    legend.title.size = 1.2,
    legend.text.size = 0.8
  ) +
  tm_compass(type = "8star", position = c("right", "top")) +
  tm_scalebar(position = c("right", "bottom"))

# Classification des clusters---------------------------------------------------------
#| fig-cap: "Grappes d'enquêtes DHS par rapport aux aires protégées existantes"


classify_clusters_with_pa <- function(cluster_gps,
                                      buffer_before,   # union of <2008
                                      wdpa_after,      # polygons >=2008 (no union)
                                      buffer_dist = 5000,
                                      label_treat = "Treatment",
                                      label_excl  = "Excluded",
                                      label_ctrl  = "Control") {

  # per-PA buffers (keep attrs)
  wdpa_after_buf <- wdpa_after %>%
    st_transform(mdg_crs) %>%
    mutate(geometry = st_buffer(geometry, buffer_dist)) %>%
    st_transform(standard_crs)

  # flags
  in_after  <- st_within(cluster_gps, st_union(wdpa_after_buf),  sparse = FALSE)[,1]
  in_before <- st_within(cluster_gps, buffer_before,            sparse = FALSE)[,1]

  base <- cluster_gps %>%
    mutate(groupe = case_when(
      in_after & !in_before & URBAN_RURA == "R" ~ label_treat,
      in_before | URBAN_RURA == "U"            ~ label_excl,
      TRUE                                     ~ label_ctrl
    ))

  # enrich treated with oldest+nearest PA
  treated_pts <- base %>% filter(groupe == label_treat)

  if (nrow(treated_pts) == 0) return(base)

  cand <- st_join(treated_pts, wdpa_after_buf, join = st_within, left = FALSE) %>%
  mutate(
    .idx = match(WDPAID, wdpa_after$WDPAID),
    dist_km = as.numeric(
      st_distance(
        geometry,
        wdpa_after$geometry[.idx],
        by_element = TRUE
      )
    ) / 1000
  ) %>%
  dplyr::select(-.idx)

  best <- cand %>%
    group_by(DHSCLUST) %>%
    slice_min(STATUS_YR, with_ties = TRUE) %>%
    slice_min(dist_km,   with_ties = FALSE) %>%
    ungroup() %>%
    st_drop_geometry() %>%
    select(DHSYEAR, DHSCLUST, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

  base %>% left_join(best, by = c("DHSYEAR","DHSCLUST"))
}

gps_1997_class <- classify_clusters_with_pa(gps_1997, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2008_class <- classify_clusters_with_pa(gps_2008, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2011_class <- classify_clusters_with_pa(gps_2011, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2013_class <- classify_clusters_with_pa(gps_2013, buffer_5km_before_2008,
                                            wdpa_from_2008)
gps_2016_class <- classify_clusters_with_pa(gps_2016, buffer_5km_before_2008,
                                            wdpa_from_2008)
gps_2021_class <- classify_clusters_with_pa(gps_2021, buffer_5km_before_2008,
                                            wdpa_from_2008)


gps_all_class_5km <- bind_rows(
  gps_1997_class,
  gps_2008_class,
  gps_2011_class,
  gps_2013_class,
  gps_2016_class,
  gps_2021_class
)

# Créer un plot pour visualiser la carte des AP avec les clusters----------------------
tm_shape(buffer_5km_from_2008) +
  tm_borders("green", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +  
  tm_shape(buffer_5km_before_2008) +
  tm_borders("darkgreen", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "green", 
              fill_alpha = 0.5,
              col = "black", 
              fill.legend = tm_legend(title = "à partir de 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "darkgreen", 
              fill_alpha = 0.5, 
              col =  "black", 
              fill.legend = tm_legend(title = "avant 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(gps_all_class_5km) +
  tm_symbols(
    fill = "groupe", 
    fill.legend = tm_legend(title = "Groupes"),
    fill.scale = tm_scale(values = c("Treatment" = "red", "Control" = "blue", "Excluded" = "gray")),
     size = 0.5,
    shape = 21
  ) +
  tm_facets("DHSYEAR") +
  tm_add_legend(type = "polygons", 
                fill = c("green", "darkgreen"), 
                labels = c("à partir de 2008", "avant 2008")) +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE
  ) +
  tm_scalebar(position = c("left", "bottom"))

# Tableau récapitulatif du nombre de grappes d'enquête classées dans chaque groupe-----
treated_sub_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  mutate(subcat = case_when(
    !is.na(STATUS_YR) & DHSYEAR <  STATUS_YR ~ "Avant traitement",
    !is.na(STATUS_YR) & DHSYEAR >= STATUS_YR ~ "Déjà traités",
    TRUE ~ NA_character_
  )) %>%
  count(DHSYEAR, subcat, name = "n_clusters") %>%
  pivot_wider(names_from = subcat, values_from = n_clusters, values_fill = 0)

# Ligne "Ensemble" (tous les traités, quel que soit le statut)
treated_all_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  count(DHSYEAR, name = "Ensemble")

# Colonnes Contrôles / Exclus
ctrl_excl_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe %in% c("Control", "Excluded")) %>%
  mutate(Groupe = recode(groupe, Control = "Contrôles", Excluded = "Exclus")) %>%
  count(DHSYEAR, Groupe, name = "n") %>%
  pivot_wider(names_from = Groupe, values_from = n, values_fill = 0)

# Assemblage large (années en lignes)
tab_wide_clusters <- list(treated_sub_clusters, treated_all_clusters, 
                          ctrl_excl_clusters) %>%
  Reduce(function(x, y) full_join(x, y, by = "DHSYEAR"), .) %>%
  arrange(DHSYEAR) %>%
  mutate(across(-DHSYEAR, ~replace_na(.x, 0L)))

# Tableau gt : spanner "Traitement" + colonnes Contrôles / Exclus
gt_table_clusters <- tab_wide_clusters %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de grappes par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des grappes *Traitement*."),
    locations = cells_title(groups = "title")
  )

gt_table_clusters

# Tableau récapitulatif du nombre de ménages d'enquête classées dans chaque groupe-----
load_dhs_data <- function(dhs_folder, year, identifier) {
  folder_pattern <- paste0(".*", year, ".*", identifier)
  
  matching_folder <- list.dirs(dhs_folder, full.names = TRUE, recursive = TRUE) %>%
    keep(~ str_detect(.x, folder_pattern))
  
  if (length(matching_folder) == 0) {
    stop("No folder found for the specified year and identifier.")
  }
  
  if (identifier == "GE") {
    file_pattern <- "\\.shp$"
    data_loader <- function(file) st_read(file, quiet = TRUE)
  } else {
    file_pattern <- "\\.[Dd][Tt][Aa]$"
    data_loader <- read_dta
  }
  
  target_file <- list.files(matching_folder, pattern = file_pattern, full.names = TRUE)
  
  if (length(target_file) == 0) {
    stop("No valid file found in the folder.")
  }
  
  data <- data_loader(target_file)
  
  return(data)
}

dhs_folder <- "data/raw/dhs"


# Années disponibles
years_all <- sort(unique(gps_all_class_5km$DHSYEAR))

# Compte ménages (toutes observations) 
households_counts_all <- map_dfr(years_all, function(y) {
  # HR de l'année
  hr <- load_dhs_data(dhs_folder, y, "HR") %>%
    mutate(DHSYEAR = y)  # pour la jointure avec la classification

  # Classification des grappes de l'année
  cl_y <- gps_all_class_5km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == y) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)

  # Jointure ménages <- classification (par cluster hv001)
  hr_cl <- hr %>%
    select(DHSYEAR, hv001) %>%
    left_join(cl_y, by = c("DHSYEAR" = "DHSYEAR", "hv001" = "DHSCLUST"))

  # Comptes par sous-catégories du traitement (DHSYEAR vs STATUS_YR)
  avant  <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR <  STATUS_YR) %>% nrow()
  deja   <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR >= STATUS_YR) %>% nrow()
  ens    <- hr_cl %>% filter(groupe == "Treatment") %>% nrow()
  ctrl   <- hr_cl %>% filter(groupe == "Control")   %>% nrow()
  excl   <- hr_cl %>% filter(groupe == "Excluded")  %>% nrow()

  tibble(
    DHSYEAR = y,
    `Avant traitement` = avant,
    `Déjà traités`     = deja,
    Ensemble           = ens,
    `Contrôles`        = ctrl,
    `Exclus`           = excl
  )
})

# Tableau gt (ménages, toutes observations)
gt_table_menages_all <- households_counts_all %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de ménages par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0, use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des ménages du groupe *Traitement*."), locations = cells_title(groups = "title"))

gt_table_menages_all   

# Sauvegarde des classifications des clusters 
all_class_5km <- gps_all_class_5km %>%
  select(DHSYEAR, DHSCLUST, GROUP = groupe, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

write_csv(all_class_5km, "data/derived/cluster_treatment_classification_staggered_5km.csv")

write_csv(wdpa_before_2008, "data/derived/wdpa_before_2008_5km.csv")
write_csv(wdpa_from_2008, "data/derived/wdpa_from_2008_5km.csv")

# Classification des clusters avec les données HR des ménages--------------------------- 
for(year in years_all) {
  hr_data <- load_dhs_data(dhs_folder, year, "HR") %>%
    mutate(DHSYEAR = year)
  
  cluster_class <- gps_all_class_5km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == year) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)
  
  hr_final_5km <- hr_data %>%
    rename(DHSCLUST = hv001) %>%
    left_join(cluster_class, by = c("DHSYEAR", "DHSCLUST")) %>%
    
    mutate(treatment = if_else(groupe == "Treatment", 1L, 0L),
           control = if_else(groupe == "Control", 1L, 0L))
  
  saveRDS(hr_final_5km, glue("data/derived/hr_{year}_final_5km.rds"))
    
}
```

#### Covariates Calculation

```{r}
library(labelled) # Manipulation des labels
library(mapme.biodiversity)
library(progressr) # Pour avoir des barres de progression
library(tictoc) # Pour minuter le temps d'exécution
library(future) # Pour permettre du calcul parallèle

# Load data
buffer_all_5km <- gps_all_class_5km %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = 5000) %>%
  st_transform(standard_crs)

# Chargement des données géophysiques des ménages--------------------------------
# Définir le chemin relatif pour ton répertoire local

outdir <- "data/raw/mapme"
dir.create(outdir, recursive = TRUE, showWarnings = FALSE)
mapme_options(outdir = outdir, verbose = TRUE)


# Couvert forestier
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km  %>% 
    get_resources(get_gfw_treecover())
})
toc()

# Perte de couvert
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_gfw_lossyear()) 
})
toc()

# NASA SRTM
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_nasa_srtm()) 
})
toc()

# Worldpop 2000
#tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>%
    get_resources(get_worldpop(years = 2000))
})
#toc()
  
# Accesibility
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_accessibility_2000()) 
})
toc()

# Maximum temperatures
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_max_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc()

# Minimum temperatures
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_min_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc()

# Precipitations
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_precipitation(years = 1980:2021, resolution = "2.5m")
  )
})
toc()
  
# Calcul des indicateurs------------------------------------------------------- 
if (file.exists("data/derived/spatial_covars_staggered_5km.rds")) {
  cat("Le fichier spatial_covars_staggered_5km.rds existe déjà")
} else {
  cat("Fichier introuvable, début du traitement...\n")
  
  # Créer un plan pour paralléliser les calculs
  plan(sequential)
  plan(multisession, workers = 4)
  
  # Maximum temperatures
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_temperature_max_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 11984.55 sec elapsed
  
  # Minimum temperatures
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
         calc_temperature_min_wc( engine = "extract", stats = "mean")
      )
  })
  toc() # 12588.37 sec | 9660.17 sec elapsed 
  
  
  # Precipitations
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_precipitation_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 17857.13 sec | 8883.61 sec elapsed 
  
  
  # Forest cover rate in 2000
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_treecover_area(years = 2000, min_size = 1, min_cover = 10)
      )
  })
  toc()   # 548.69 sec | 2519.61 sec elapsed
  
  # slope 
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_slope(engine = "extract", stats = "mean")
      )
  })
  toc() # 365.87 sec | 2557.28 sec elapsed    
  
  # Elevation
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_elevation(engine = "extract", stats = "mean")
      )
  })
  toc() # 283.51 sec | 2672.57 sec elapsed  
  
  # Population density
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_population_count(engine = "extract", stats = "mean")
      )
  })
  toc() # 83.55 sec | 1877.78 sec elapsed
  
  # Accessibility
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_traveltime_2000(engine = "extract", stats = "mean")
      )
  })
  toc() # 87.63 sec | 2594.06 sec elapsed   
  
  # Enregistrement des données 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_staggered_5km.rds")
  cat("Données enregistrées dans spatial_covars_staggered_5km.rds")
}

```

#### Matching

### Test pour une distance de 15km

-   Création d'un buffer de 15 km autour des aires protégées Matching DID Test de robustesse
-   Réassignation des traitements
-   Matching
-   Test d'équilibre
-   DID
-   Test de robustesse

## Test pour l'hypothèse multiple

La méthode "False Directory Rate" de Benjamini-Hochberg sera appliqué aux hypothèses H2 et H3 pour corriger le problème des tests multiples.

## Analyse de sensibilité de Rosenbaum

Vérification de la robustesse des résultats issus du matching face à un éventuel biais non observé en testant différentes valeurs de Γ, afin d'évaluer dans quelle mesure la présence d'un biais caché pourraient influencer les conclusions de l'analyse

## Effets hétérogènes

Estimation des effets hétérogènes en introduisant des interactions entre le traitement et les différentes variables différenciatrices dans un modèle de double DID pour explorer les effets différenciés des aires protégées sur les ménages en fonction des caractéristiques socio-démographiques et environnementales

Caractéristiques socio-démographiques et environnementales:

-   Sexe et âge du chef de ménage

-   Conditions environnementales (Pluviométrie, sécheresse)

-   Type de gouvernance des aires protégées (strictes (statuts IUCN I-IV) vs multi-usages ( statuts IUCN V-VI))

-   Distance aux aires protégées (5km, 10 km, 15 km) -\> même analyse que test de robustess? si oui, enlver de cette partie

## Impact sur l'inégalité intra-communautaire

-   Inégalité intra-communautaire (Z-score standardisée du wealth index)

## Pseudo Panel

-   Construction de cohorte de ménage

-   Estimation d'un modèle à effet fixe pour corriger les biais liées aux variables non observés

-   Pondérer les observations en fonction de la taille des cohortes

# Appendix

## Statistical power

-   Estimation de la puissance statistique pour détecter un effet d'au moins 7.5 centiles dans l'indice de richesse entre les groupes

-   EStimation de la probabilité à un seuil de puissance fixée à 0.8 avec un seuil de signification fixée à 0.05

-   **Mobilisation des données MIS 2011, MIS 2013 et MIS 2016 si la puissance statistique est insuffisante**

Analyse de sensibilité ==\> à voir

Tests de robustesse

Test de sensibilité aux tailles de buffer

Test pour une distance de 5 km

Création d'un buffer de 5 km autour des aires protégées

Réassignation des traitements

Matching

Test d'équilibre

DID

Test de robustesse

Test pour une distance de 15km

Création d'un buffer de 15 km autour des aires protégées Matching DID Test de robustesse

Réassignation des traitements

Matching

Test d'équilibre

DID

Test de robustesse

Test pour l'hypothèse multiple

La méthode "False Directory Rate" de Benjamini-Hochberg sera appliqué aux hypothèses H2 et H3 pour corriger le problème des tests multiples.

Analyse de sensibilité de Rosenbaum

Vérification de la robustesse des résultats issus du matching face à un éventuel biais non observé en testant différentes valeurs de Γ, afin d'évaluer dans quelle mesure la présence d'un biais caché pourraient influencer les conclusions de l'analyse

Effets hétérogènes

Estimation des effets hétérogènes en introduisant des interactions entre le traitement et les différentes variables différenciatrices dans un modèle de double DID pour explorer les effets différenciés des aires protégées sur les ménages en fonction des caractéristiques socio-démographiques et environnementales

Caractéristiques socio-démographiques et environnementales:

Sexe et âge du chef de ménage

Conditions environnementales (Pluviométrie, sécheresse)

Type de gouvernance des aires protégées (strictes (statuts IUCN I-IV) vs multi-usages ( statuts IUCN V-VI))

Distance aux aires protégées (5km, 10 km, 15 km) -\> même analyse que test de robustess? si oui, enlver de cette partie

Impact sur l'inégalité intra-communautaire

Inégalité intra-communautaire (Z-score standardisée du wealth index)

Pseudo Panel

Construction de cohorte de ménage

Estimation d'un modèle à effet fixe pour corriger les biais liées aux variables non observés

Pondérer les observations en fonction de la taille des cohortes

Appendix

Statistical power

Estimation de la puissance statistique pour détecter un effet d'au moins 7.5 centiles dans l'indice de richesse entre les groupes

EStimation de la probabilité à un seuil de puissance fixée à 0.8 avec un seuil de signification fixée à 0.05

Mobilisation des données MIS 2011, MIS 2013 et MIS 2016 si la puissance statistique est insuffisante

Analyse de sensibilité ==\> à voir
