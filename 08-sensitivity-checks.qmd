---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Sensitivity tests

Ce document fournit les différents tests de robustesse utilisés dans l'analyse. Cette étape est un aspect crucial pour garantir la fiabilité et de la validation de notre méthodologie.

## Test de sensibilité aux tailles de buffer

Cette partie vérifie la robustesse des conclusions des estimations effectuées auparavant en retenant des distances de 5 km et de 15 km.

### Test pour une distance de 5 km

#### Assignation des traitements

```{r}
# Library
library(tidyverse) 
library(haven) 
library(sf) 
library(tmap) 
library(gt)  
library(geodata) 
library(writexl)
library(units) 
library(leaflet) 
library(readxl) 
library(glue)


# Systèmes de coordonnées de référence 
standard_crs <- 4326
mdg_crs <- 29702 

# On charge les données gps 
gps_1997_initial <- st_read("data/raw/dhs/DHS_1997/MDGE32FL/MDGE32FL.shp")
gps_2008_initial <- st_read("data/raw/dhs/DHS_2008/MDGE53FL/MDGE53FL.shp") 
gps_2011_initial <- st_read("data/raw/dhs/DHS_2011/MDGE61FL/MDGE61FL.shp") 
gps_2013_initial <- st_read("data/raw/dhs/DHS_2013/MDGE6AFL/MDGE6AFL.shp") 
gps_2016_initial <- st_read("data/raw/dhs/DHS_2016/MDGE71FL/MDGE71FL.shp")
gps_2021_initial <- st_read("data/raw/dhs/DHS_2021/MDGE81FL/MDGE81FL.shp")

# Fonction qui vérifie que les coordonnées ne sont pas nulles
check_coordinates <- function(dhs_gps, country_polygon, negate = FALSE) {
  dhs_gps %>%
    filter(LONGNUM != 0 | LATNUM != 0)
}

gps_1997 <- check_coordinates(gps_1997_initial, contour_mada)
gps_2008 <- check_coordinates(gps_2008_initial, contour_mada)
gps_2011 <- check_coordinates(gps_2011_initial, contour_mada)
gps_2013 <- check_coordinates(gps_2013_initial, contour_mada)
gps_2016 <- check_coordinates(gps_2016_initial, contour_mada)
gps_2021 <- check_coordinates(gps_2021_initial, contour_mada)

# Load boundary 
contour_mada <- gadm(country = "Madagascar", level = 0, path = "data") %>%
  st_as_sf() %>%
  st_set_crs(standard_crs)

# On charge les données des AP
wdpa_terrestre_mod <- st_read("data/derived/wdpa_terrestre_mod.shp") %>%
  rename(
    WDPA_PID = WDPA_PI,
    ORIG_NAME = ORIG_NA,
    DESIG_ENG = DESIG_E,
    DESIG_TYPE = DESIG_T,
    IUCN_CAT = IUCN_CA,   
    INT_CRIT = INT_CRI,
    REP_M_AREA = REP_M_A,
    REP_AREA = REP_ARE,
    NO_TK_AREA = NO_TK_A,
    STATUS_YR = STATUS_,
    GEOMETRY_TYPE = GEOMETR,
    AREA_KM2 = AREA_KM,
    area_km2 = are_km2
  ) %>% 
  st_make_valid() %>%
  st_transform(standard_crs)

# Intersection des AP de WDPA avec la limite de Madagascar
wdpa_terrestre <- wdpa_terrestre_mod %>%
  st_make_valid() %>%
  filter(rowSums(st_intersects(., contour_mada, sparse = FALSE)) > 0) %>%
  st_transform(mdg_crs) %>%
  mutate(
    area_m2  = as.numeric(st_area(.)),
    area_ha  = area_m2 / 1e4,
    area_km2 = area_m2 / 1e6
  ) %>%
  st_transform(standard_crs)

# Buffer de 5 km
buffer_dist <- 5000

# Spécification des AP avant-après 2008--------
wdpa_before_2008 <- wdpa_terrestre_mod %>%
  filter(STATUS_YR < 2008)
wdpa_from_2008 <- wdpa_terrestre_mod %>%
  filter(STATUS_YR >= 2008)

# Créer des buffers de 5 km autour des AP
buffer_5km_before_2008 <- 
  wdpa_before_2008 %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)


buffer_5km_from_2008 <- wdpa_from_2008  %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)

# Visualisation des cartes---------------------
tmap_mode("view")

tm_shape(contour_mada) + 
  tm_borders(col = "black", lwd = 1) +
  
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "blue", 
              col =  "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) +
  
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "darkgreen", 
              col = "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) + 
  
tm_shape(buffer_5km_from_2008) +
tm_borders(col = "darkgreen", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
  
tm_shape(buffer_5km_before_2008) +
tm_borders(col = "blue", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
tm_add_legend(
  type = "polygons", 
  fill = c("blue", "darkgreen"), 
  labels = c("avant 2008", "après 2008")) +
  tm_title("Aires protégées du WDPA par période de création</b><br/>Source: WDPA, 2024") +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE,
    legend.title.size = 1.2,
    legend.text.size = 0.8
  ) +
  tm_compass(type = "8star", position = c("right", "top")) +
  tm_scalebar(position = c("right", "bottom"))

# Classification des clusters---------------------------------------------------------
#| fig-cap: "Grappes d'enquêtes DHS par rapport aux aires protégées existantes"


classify_clusters_with_pa <- function(cluster_gps,
                                      buffer_before,   # union of <2008
                                      wdpa_after,      # polygons >=2008 (no union)
                                      buffer_dist = 5000,
                                      label_treat = "Treatment",
                                      label_excl  = "Excluded",
                                      label_ctrl  = "Control") {

  # per-PA buffers (keep attrs)
  wdpa_after_buf <- wdpa_after %>%
    st_transform(mdg_crs) %>%
    mutate(geometry = st_buffer(geometry, buffer_dist)) %>%
    st_transform(standard_crs)

  # flags
  in_after  <- st_within(cluster_gps, st_union(wdpa_after_buf),  sparse = FALSE)[,1]
  in_before <- st_within(cluster_gps, buffer_before,            sparse = FALSE)[,1]

  base <- cluster_gps %>%
    mutate(groupe = case_when(
      in_after & !in_before & URBAN_RURA == "R" ~ label_treat,
      in_before | URBAN_RURA == "U"            ~ label_excl,
      TRUE                                     ~ label_ctrl
    ))

  # enrich treated with oldest+nearest PA
  treated_pts <- base %>% filter(groupe == label_treat)

  if (nrow(treated_pts) == 0) return(base)

  cand <- st_join(treated_pts, wdpa_after_buf, join = st_within, left = FALSE) %>%
  mutate(
    .idx = match(WDPAID, wdpa_after$WDPAID),
    dist_km = as.numeric(
      st_distance(
        geometry,
        wdpa_after$geometry[.idx],
        by_element = TRUE
      )
    ) / 1000
  ) %>%
  dplyr::select(-.idx)

  best <- cand %>%
    group_by(DHSCLUST) %>%
    slice_min(STATUS_YR, with_ties = TRUE) %>%
    slice_min(dist_km,   with_ties = FALSE) %>%
    ungroup() %>%
    st_drop_geometry() %>%
    select(DHSYEAR, DHSCLUST, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

  base %>% left_join(best, by = c("DHSYEAR","DHSCLUST"))
}

gps_1997_class <- classify_clusters_with_pa(gps_1997, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2008_class <- classify_clusters_with_pa(gps_2008, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2011_class <- classify_clusters_with_pa(gps_2011, buffer_5km_before_2008, 
                                            wdpa_from_2008)
gps_2013_class <- classify_clusters_with_pa(gps_2013, buffer_5km_before_2008,
                                            wdpa_from_2008)
gps_2016_class <- classify_clusters_with_pa(gps_2016, buffer_5km_before_2008,
                                            wdpa_from_2008)
gps_2021_class <- classify_clusters_with_pa(gps_2021, buffer_5km_before_2008,
                                            wdpa_from_2008)


gps_all_class_5km <- bind_rows(
  gps_1997_class,
  gps_2008_class,
  gps_2011_class,
  gps_2013_class,
  gps_2016_class,
  gps_2021_class
)

# Créer un plot pour visualiser la carte des AP avec les clusters----------------------
tm_shape(buffer_5km_from_2008) +
  tm_borders("green", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +  
  tm_shape(buffer_5km_before_2008) +
  tm_borders("darkgreen", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "green", 
              fill_alpha = 0.5,
              col = "black", 
              fill.legend = tm_legend(title = "à partir de 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "darkgreen", 
              fill_alpha = 0.5, 
              col =  "black", 
              fill.legend = tm_legend(title = "avant 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(gps_all_class_5km) +
  tm_symbols(
    fill = "groupe", 
    fill.legend = tm_legend(title = "Groupes"),
    fill.scale = tm_scale(values = c("Treatment" = "red", "Control" = "blue", "Excluded" = "gray")),
     size = 0.5,
    shape = 21
  ) +
  tm_facets("DHSYEAR") +
  tm_add_legend(type = "polygons", 
                fill = c("green", "darkgreen"), 
                labels = c("à partir de 2008", "avant 2008")) +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE
  ) +
  tm_scalebar(position = c("left", "bottom"))

# Tableau récapitulatif du nombre de grappes d'enquête classées dans chaque groupe-----
treated_sub_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  mutate(subcat = case_when(
    !is.na(STATUS_YR) & DHSYEAR <  STATUS_YR ~ "Avant traitement",
    !is.na(STATUS_YR) & DHSYEAR >= STATUS_YR ~ "Déjà traités",
    TRUE ~ NA_character_
  )) %>%
  count(DHSYEAR, subcat, name = "n_clusters") %>%
  pivot_wider(names_from = subcat, values_from = n_clusters, values_fill = 0)

# Ligne "Ensemble" (tous les traités, quel que soit le statut)
treated_all_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  count(DHSYEAR, name = "Ensemble")

# Colonnes Contrôles / Exclus
ctrl_excl_clusters <- gps_all_class_5km %>%
  st_drop_geometry() %>%
  filter(groupe %in% c("Control", "Excluded")) %>%
  mutate(Groupe = recode(groupe, Control = "Contrôles", Excluded = "Exclus")) %>%
  count(DHSYEAR, Groupe, name = "n") %>%
  pivot_wider(names_from = Groupe, values_from = n, values_fill = 0)

# Assemblage large (années en lignes)
tab_wide_clusters <- list(treated_sub_clusters, treated_all_clusters, 
                          ctrl_excl_clusters) %>%
  Reduce(function(x, y) full_join(x, y, by = "DHSYEAR"), .) %>%
  arrange(DHSYEAR) %>%
  mutate(across(-DHSYEAR, ~replace_na(.x, 0L)))

# Tableau gt : spanner "Traitement" + colonnes Contrôles / Exclus
gt_table_clusters <- tab_wide_clusters %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de grappes par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des grappes *Traitement*."),
    locations = cells_title(groups = "title")
  )

gt_table_clusters

# Tableau récapitulatif du nombre de ménages d'enquête classées dans chaque groupe-----
load_dhs_data <- function(dhs_folder, year, identifier) {
  folder_pattern <- paste0(".*", year, ".*", identifier)
  
  matching_folder <- list.dirs(dhs_folder, full.names = TRUE, recursive = TRUE) %>%
    keep(~ str_detect(.x, folder_pattern))
  
  if (length(matching_folder) == 0) {
    stop("No folder found for the specified year and identifier.")
  }
  
  if (identifier == "GE") {
    file_pattern <- "\\.shp$"
    data_loader <- function(file) st_read(file, quiet = TRUE)
  } else {
    file_pattern <- "\\.[Dd][Tt][Aa]$"
    data_loader <- read_dta
  }
  
  target_file <- list.files(matching_folder, pattern = file_pattern, full.names = TRUE)
  
  if (length(target_file) == 0) {
    stop("No valid file found in the folder.")
  }
  
  data <- data_loader(target_file)
  
  return(data)
}

dhs_folder <- "data/raw/dhs"


# Années disponibles
years_all <- sort(unique(gps_all_class_5km$DHSYEAR))

# Compte ménages (toutes observations) 
households_counts_all <- map_dfr(years_all, function(y) {
  # HR de l'année
  hr <- load_dhs_data(dhs_folder, y, "HR") %>%
    mutate(DHSYEAR = y)  # pour la jointure avec la classification

  # Classification des grappes de l'année
  cl_y <- gps_all_class_5km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == y) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)

  # Jointure ménages <- classification (par cluster hv001)
  hr_cl <- hr %>%
    select(DHSYEAR, hv001) %>%
    left_join(cl_y, by = c("DHSYEAR" = "DHSYEAR", "hv001" = "DHSCLUST"))

  # Comptes par sous-catégories du traitement (DHSYEAR vs STATUS_YR)
  avant  <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR <  STATUS_YR) %>% nrow()
  deja   <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR >= STATUS_YR) %>% nrow()
  ens    <- hr_cl %>% filter(groupe == "Treatment") %>% nrow()
  ctrl   <- hr_cl %>% filter(groupe == "Control")   %>% nrow()
  excl   <- hr_cl %>% filter(groupe == "Excluded")  %>% nrow()

  tibble(
    DHSYEAR = y,
    `Avant traitement` = avant,
    `Déjà traités`     = deja,
    Ensemble           = ens,
    `Contrôles`        = ctrl,
    `Exclus`           = excl
  )
})

# Tableau gt (ménages, toutes observations)
gt_table_menages_all <- households_counts_all %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de ménages par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0, use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des ménages du groupe *Traitement*."), locations = cells_title(groups = "title"))

gt_table_menages_all   

# Sauvegarde des classifications des clusters 
all_class_5km <- gps_all_class_5km %>%
  select(DHSYEAR, DHSCLUST, GROUP = groupe, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

write_csv(all_class_5km, "data/derived/cluster_treatment_classification_staggered_5km.csv")

write_csv(wdpa_before_2008, "data/derived/wdpa_before_2008_5km.csv")
write_csv(wdpa_from_2008, "data/derived/wdpa_from_2008_5km.csv")

# Classification des clusters avec les données HR des ménages--------------------------- 
for(year in years_all) {
  hr_data <- load_dhs_data(dhs_folder, year, "HR") %>%
    mutate(DHSYEAR = year)
  
  cluster_class <- gps_all_class_5km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == year) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)
  
  hr_final_5km <- hr_data %>%
    rename(DHSCLUST = hv001) %>%
    left_join(cluster_class, by = c("DHSYEAR", "DHSCLUST")) %>%
    
    mutate(treatment = if_else(groupe == "Treatment", 1L, 0L),
           control = if_else(groupe == "Control", 1L, 0L))
  
  saveRDS(hr_final_5km, glue("data/derived/hr_{year}_final_5km.rds"))
    
}
```

#### Covariates Calculation

Nous chargeons les covariables à partir du package mapme.biodiversity.

```{r}
library(labelled) # Manipulation des labels
library(mapme.biodiversity)
library(progressr) # Pour avoir des barres de progression
library(tictoc) # Pour minuter le temps d'exécution
library(future) # Pour permettre du calcul parallèle

# Load data
buffer_all_5km <- gps_all_class_5km %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = 5000) %>%
  st_transform(standard_crs)

# Chargement des données géophysiques des ménages--------------------------------
# Définir le chemin relatif pour ton répertoire local

outdir <- "data/raw/mapme"
dir.create(outdir, recursive = TRUE, showWarnings = FALSE)
mapme_options(outdir = outdir, verbose = TRUE)


# Couvert forestier
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km  %>% 
    get_resources(get_gfw_treecover())
})
toc() # 1.25 sec elapsed 

# Perte de couvert
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_gfw_lossyear()) 
})
toc() # 1.15 sec elapsed 

# NASA SRTM
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_nasa_srtm()) 
})
toc() # 5.22 sec elapsed 

# Worldpop 2000
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>%
    get_resources(get_worldpop(years = 2000))
})
toc() # 0.22 sec elapsed 
  
# Accesibility
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% 
  get_resources(get_accessibility_2000()) 
})
toc() # 0.28 sec elapsed 

# Maximum temperatures
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_max_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 28.74 sec elapsed 

# Minimum temperatures
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_min_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 28.23 sec elapsed 

# Precipitations
tic()
with_progress({
  buffer_all_5km <- buffer_all_5km %>% get_resources(
    get_worldclim_precipitation(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 275.08 sec elapsed
  
```

Après chargement et extraction des données sur les données géophysiques des ménages, nous allons calculer les indicateurs des variables environnementales dans un rayon de 5 km autour de chaque grappe d'enquête.

```{r}
# Calcul des indicateurs------------------------------------------------------- 
if(file.exists("data/derived/spatial_covars_staggered_5km.rds")) {cat("Le fichier spatial_covars_staggered_5km.rds existe déjà")
} else {
    cat("Fichier introuvable, début du traitement... \n")
  
  # Créer un plan pour paralléliser les calculs
  plan(sequential)
  plan(multisession, workers = 4)
  
  # Maximum temperatures
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_temperature_max_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 34502.12 sec elapsed
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_max_temp.rds", compress = "gz")
  
  
  # Minimum temperatures
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
         calc_temperature_min_wc( engine = "extract", stats = "mean")
      )
  })
  toc() # 24445.67 sec elapsed 
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_min_temp.rds", compress = "gz")
  
  
  # Precipitations
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_precipitation_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # # 21007.7 sec elapsed 
 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_precip.rds", compress = "gz") 
  
  
  # Forest cover rate in 2000
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_treecover_area(years = 2000, min_size = 1, min_cover = 10)
      )
  })
  toc()   # 2392.16 sec elapsed
 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_treecover.rds", compress = "gz")
  
  
  # slope 
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_slope(engine = "extract", stats = "mean")
      )
  })
  toc() # 5995.94 sec elapsed  
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_slope.rds", compress = "gz")
  
  
  # Elevation
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_elevation(engine = "extract", stats = "mean")
      )
  })
  toc() # 2163.28 sec elapsed 
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_elevation.rds", compress = "gz")
  
  
  # Population density
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_population_count(engine = "extract", stats = "mean")
      )
  })
  toc() # 2134.34 sec elapsed
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_pop_density.rds", compress = "gz")
  
  
  # Accessibility
  tic()
  with_progress({
    buffer_all_5km <- buffer_all_5km %>%
      calc_indicators(
        calc_traveltime_2000(engine = "extract", stats = "mean")
      )
  })
  toc() # 2162.22 sec elapsed  
  
  write_rds(buffer_all_5km, "data/derived/spatial_covars_partial_accessibility.rds", compress = "gz")
  
  # Enregistrement final des données 
  write_rds(buffer_all_5km, "data/derived/spatial_covars_staggered_5km.rds")
 }
```

#### Spei calculation

Nous calculons ici l'évolution annuelle du SPEI, à l'échelle de 12 mois, pour un cluster pour la période de 1980 - 2021.

```{r}
library(SPEI) # Calcul de l'indice SPEI
library(labelled) # Manipulation des labels
library(tibbletime) # Manipulation des données temporelles 
library(zoo) # Manipulation des données temporelles 
library(readr) # Lecture des données de texte rectangulaires
library(ggplot2) # visualisation

# Load data 
spatial_covars_5km <- read_rds("data/derived/spatial_covars_staggered_5km.rds")

# Function to compute SPEI
compute_spei_annual <- function(tmin_tbl, tmax_tbl, prec_tbl, lat_deg) {
  # tmin_tbl/tmax_tbl/prec_tbl: tibbles avec colonnes `datetime` (Date) et `value` (num)
  d_tmin <- tibble(date = tmin_tbl$datetime, tmin = tmin_tbl$value)
  d_tmax <- tibble(date = tmax_tbl$datetime, tmax = tmax_tbl$value)
  d_prec <- tibble(date = prec_tbl$datetime, prec = prec_tbl$value)

  d_merged <- reduce(list(d_tmin, d_tmax, d_prec), left_join, by = "date") %>%
    arrange(date)

  d_clean <- drop_na(d_merged)  # supprime lignes avec NA

  # Si séries trop courtes, renvoyer squelette 1981:2021 en NA
  if (nrow(d_clean) < 12) {
    return(tibble(year = 1981:2021, spei_mean = NA_real_))
  }

  # PET (Hargreaves), bilan hydrique et SPEI mensuel
  pet <- hargreaves(Tmin = d_clean$tmin,
                    Tmax = d_clean$tmax,
                    Pre  = d_clean$prec,
                    lat  = lat_deg)

  wb <- d_clean$prec - pet

  wb_ts <- ts(wb,
              start = c(year(min(d_clean$date)), month(min(d_clean$date))),
              frequency = 12)

  spei_obj <- spei(wb_ts,
                   scale = 12,
                   ref.start = c(1981, 1),
                   ref.end   = c(2021, 12))

  tibble(datetime = d_clean$date,
         spei      = as.numeric(spei_obj$fitted)) %>%
    filter(datetime >= as.Date("1981-01-01"),
           datetime <= as.Date("2021-12-31")) %>%
    mutate(year = year(datetime)) %>%
    group_by(year) %>%
    summarise(spei_mean = mean(spei, na.rm = TRUE), .groups = "drop") %>%
    complete(year = 1981:2021, fill = list(spei_mean = NA_real_))
}

# Latitude géodésique depuis la géométrie (centroïde)
spatial_covars_spei_5km <- spatial_covars_5km %>%
  mutate(lat = st_coordinates(st_centroid(geometry))[, 2])

row1 <- spatial_covars_spei_5km[1, ]

spei_tbl_one <- compute_spei_annual(
  tmin_tbl = row1$temperature_min_wc[[1]],
  tmax_tbl = row1$temperature_max_wc[[1]],
  prec_tbl = row1$precipitation_wc[[1]],
  lat_deg  = row1$lat
)

# Graphique 
spei_2017 <- spei_tbl_one %>% 
  filter(year == 2017)

ggplot(spei_tbl_one, aes(x = year, y = spei_mean)) +
  geom_col(aes(y = pmax(0, -spei_mean)), alpha = 0.25) +  # barres pour sécheresse (optionnel)
  geom_line(linewidth = 0.8) +
  geom_vline(xintercept = 2017, color = "red", linetype = "dotted", linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label(
    data = spei_2017, 
    aes(x = 2017, y = spei_mean, 
        label = paste0("Année: 2017\nSPEI: ", round(spei_mean, 2))),
    nudge_x = 1, 
    nudge_y = 0.3,
    fill = "white",
    color = "black",
    linewidth = 0.4, 
    label.padding = unit(0.2, "lines")
  ) +
  
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI (scale=12) – cluster de démonstration",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# SPEI for all clusters 
spatial_covars_spei_5km <- spatial_covars_spei_5km %>%
  mutate(
    spei_wc = pmap(
      list(temperature_min_wc, temperature_max_wc, precipitation_wc, lat),
      ~ compute_spei_annual(..1, ..2, ..3, ..4)
    )
  )

spei_df <- spatial_covars_spei_5km %>%
  select(DHSCLUST, spei_wc) %>%
  unnest(spei_wc)

ggplot(spei_df, aes(x = year, y = spei_mean, group = DHSCLUST)) +
  geom_line(alpha = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI by cluster with 5 km buffer (1981–2021)",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# Chaque élément spei_wc devient une table {datetime, variable, unit, value}
spatial_covars_spei_5km <- spatial_covars_spei_5km %>%
  mutate(
    spei_wc = map(spei_wc, ~ .x %>%
      mutate(
        datetime = as.Date(paste0(.data$year, "-01-01")),
        variable = "spei_scale12_mean",
        unit     = "annual",
        value    = .data$spei_mean
      ) %>%
      select(datetime, variable, unit, value))
  )

# Sauvegarde (cohérente avec le reste de tes scripts)
spatial_covars_spei_df_5km <- as.data.frame(spatial_covars_spei_5km)
write_rds(spatial_covars_spei_df_5km, "data/derived/spatial_covars_spei_staggered_5km.rds")
cat("SPEI (annuel, 1981–2021) enregistré dans data/derived/spatial_covars_spei_staggered_5km.rds\n")
```

Dans l'ensemble, la série oscille autour de zéro, alternant des périodes humides et sèches. On observe toutefois plusieurs épisodes de sécheresse importante à la fin des années 1980. En 2017, le SPEI a une valeur particulièrement basse (SPEI = -2.25), qui d'après la classification de Vicente-Serrano et al. @2010 caractérise une sécheresse très sévère.

#### Variable consolidation

Nous combinons les clusters de 1997, 2008, 2011, 2013, 2016 et 2021 avec leurs caractéristiques géophysiques et leur variable de résultat respectif dans un seul dataframe.

```{r}

library(lubridate)

# Covariates spatio-temporelles + classification de traitement
spatial_covars_spei_5km <- readRDS("data/derived/spatial_covars_spei_staggered_5km.rds")
all_covars <- spatial_covars_spei_5km %>%
  select(DHSYEAR, DHSCLUST, URBAN_RURA, treecover_area, slope, elevation,
         population_count, traveltime_2000, spei_wc)

all_class_5km <- read.csv("data/derived/cluster_treatment_classification_staggered_5km.csv")

# Helper: fabrique la table finale pour une année donnée
vars_to_nest <- c("treecover_area", "slope", "elevation",
                  "population_count", "traveltime_2000", "spei_wc")

build_year <- function(hr_object,
                       year,
                       hh_rural_path,
                       spei_years = (year-2):year) {

  # Charger HR (identifiants + variables chef) et HH_rural (centiles/zscore déjà calculés)
  hr <- hr_object %>%
    dplyr::select(hv001, hv002, hv219, hv220)
  
  hh_rural <- read_rds(hh_rural_path) # contient hv001/hv002 + wealth_* déjà prêts
  
  # Joindre covariates spatiaux + classification de groupes
  base <- hh_rural %>%
    left_join(hr, by = c("hv001", "hv002")) %>%
    left_join(
      all_covars %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    left_join(
      all_class_5km %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    mutate(DHSYEAR = year) %>%
    relocate(DHSYEAR, .before = everything())
  
  # Désimbriquer les covars imbriquées et appliquer la fenêtre temporelle SPEI
  #    moyenne par (hv001, hv002) pour chaque indicateur_année
  df_long <- base %>%
    select(hv001, hv002, any_of(vars_to_nest)) %>%
    pivot_longer(cols = any_of(vars_to_nest),
                 names_to = "indicator", values_to = "data") %>%
    unnest(data) %>%
    filter(indicator != "spei_wc" | year(datetime) %in% spei_years) %>%
    mutate(year_indicator = paste0(indicator, "_", year(datetime))) %>%
    select(hv001, hv002, year_indicator, value)
  
  df_wide <- df_long %>%
    pivot_wider(names_from = year_indicator, values_from = value,
                names_glue = "{year_indicator}") %>%
    group_by(hv001, hv002) %>%
    summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
  
  # Table finale (une ligne par ménage hv001/hv002)
  out <- base %>%
    select(-any_of(vars_to_nest)) %>%
    distinct(hv001, hv002, .keep_all = TRUE) %>%
    left_join(df_wide, by = c("hv001", "hv002"))
  
  out
}

# Application

hr_1997_final_5km <- read_dta("data/raw/dhs/DHS_1997/MDHR31DT/MDHR31FL.DTA") %>%
  build_year(year = 1997,
             hh_rural_path = "data/derived/hh_1997_rural_simpler.rds",
             spei_years = 1995:1997)

hr_2008_final_5km <- read_dta("data/raw/dhs/DHS_2008/MDHR51DT/MDHR51FL.DTA") %>%
  build_year(year = 2008,
             hh_rural_path = "data/derived/hh_2008_rural_simpler.rds",
             spei_years = 2006:2008)

hr_2011_final_5km <- read_dta("data/raw/dhs/DHS_2011/MDHR61DT/MDHR61FL.DTA") %>%
  build_year(year = 2011,
             hh_rural_path = "data/derived/hh_2011_rural_simpler.rds",
             spei_years = 2009:2011)

hr_2013_final_5km <- read_dta("data/raw/dhs/DHS_2013/MDHR6ADT/MDHR6AFL.DTA") %>%
  build_year(year = 2013,
  hh_rural_path = "data/derived/hh_2013_rural_simpler.rds",
  spei_years = 2011:2013)

hr_2016_final_5km <- read_dta("data/raw/dhs/DHS_2016/MDHR71DT/MDHR71FL.DTA") %>%
  build_year(year = 2016,
  hh_rural_path = "data/derived/hh_2016_rural_simpler.rds",
  spei_years = 2014:2016)

hr_2021_final_5km <- read_dta("data/raw/dhs/DHS_2021/MDHR81DT/MDHR81FL.DTA") %>%
  build_year(year = 2021,
  hh_rural_path = "data/derived/hh_2021_rural_simpler.rds",
  spei_years = 2019:2021)

# Consolidation

hr_consolidated_5km <- bind_rows(
  hr_1997_final_5km,
  hr_2008_final_5km,
  hr_2011_final_5km,
  hr_2013_final_5km,
  hr_2016_final_5km,
  hr_2021_final_5km
)

hr_consolidated_5km %>% count(DHSYEAR)

# Sauvegardes millésime
write_rds(hr_1997_final_5km, "data/derived/hr_1997_final_5km.rds")
write_rds(hr_2008_final_5km, "data/derived/hr_2008_final_5km.rds")
write_rds(hr_2011_final_5km, "data/derived/hr_2011_final_5km.rds")
write_rds(hr_2013_final_5km, "data/derived/hr_2013_final_5km.rds")
write_rds(hr_2016_final_5km, "data/derived/hr_2016_final_5km.rds")
write_rds(hr_2021_final_5km, "data/derived/hr_2021_final_5km.rds")

# Sauvegarde consolidée
write_rds(hr_consolidated_5km, "data/derived/hr_consolidated_5km_1997_2008_2011_2013_2016_2021.rds")
cat("Données enregistrées\n")
```

#### Matching

La méthode de matching est appliquée pour rendre comparable les groupes traités et contrôles, en les appariant selon cinq caractéristiques environnementales dans un rayon de 5 km.

```{r}
# Library 
library(rbounds) # Analyse de sensibilité
library(MatchIt)
library(rgenoud) # Implementation de l'algorithme génétique
library(Matching) # Estimation des effets de traitement causaux
library(progressr) # Suivi de progression
library(rlang)
library(car)
library(tibble)
library(qqplotr) # pour créer la bande de confiance
library(halfmoon)
library(cobalt)
library(ggpubr)

matching_variables <- c(
  "treecover_area_2000","slope_2000","elevation_2000",
  "population_count_2000","traveltime_2000_2000"
)

prep_matching <- function(df_final) {
  out <- df_final %>%
    filter(GROUP %in% c("Treatment","Control")) %>%
    mutate(treatment = if_else(GROUP == "Treatment", 1L, 0L))
  
  missing_cols <- setdiff(matching_variables, names(out))
  if (length(missing_cols) > 0) {
    message(">> Colonnes manquantes: ", paste(missing_cols, collapse=", "))
  }
  
  out %>% drop_na(all_of(intersect(matching_variables, names(out))))
}

# supprimer toute ancienne version pour éviter le masquage
if (exists("run_matching_year")) rm(run_matching_year)

run_matching_year <- function(year, overwrite = list(gen=FALSE, match=FALSE)) {
  cat("\n=== Matching", year, "===\n")
  fin_path <- glue("data/derived/hr_{year}_final_5km.rds")
  if (!file.exists(fin_path)) stop("Fichier introuvable: ", fin_path)
  
  dat   <- readRDS(fin_path)
  dat_m <- prep_matching(dat)
  
  
  n_total <- nrow(dat)
  n_filt <- nrow(dat_m)
  n_treat <- sum(dat_m$treatment == 1, na.rm = TRUE)
  n_ctrl <- sum(dat_m$treatment == 0, na.rm = TRUE)
  
  
  cat(glue(">> N total={n_total}, après filtre/NA={n_filt}; ",
           "Traités={n_treat}, ",
           "Contrôles={n_ctrl}\n"))
  
  have_all_vars <- all(matching_variables %in% names(dat_m))
  cat(">> Toutes les covars présentes ? ", have_all_vars, "\n")
  if (n_filt < 5 || !have_all_vars) {
    warning(glue("Année {year}: données insuffisantes ou variables manquantes — on saute."))
    return(NULL)
  }
  
  X_match <- dat_m %>%
    sf::st_drop_geometry() %>%
    dplyr::select(all_of(matching_variables)) %>%
    as.data.frame()
  
  gen_path         <- glue("data/derived/gen_match_model_{year}_5km.rds")
  match_path       <- glue("data/derived/matching_result_{year}_5km.rds")
  matched_out_path <- glue("data/derived/data_matched_{year}_5km.rds")
  
  # --- GenMatch ---
  used_cache_gen <- FALSE
  t0 <- Sys.time()
  if (file.exists(gen_path) && !isTRUE(overwrite$gen)) {
    cat(">> GenMatch: cache trouvé -> lecture\n")
    gen_model <- readRDS(gen_path)
    used_cache_gen <- TRUE
  } else {
    cat(">> GenMatch: calcul en cours...\n")
    gen_model <- GenMatch(
      Tr = dat_m$treatment,
      X  = X_match,
      BalanceMatrix = X_match,
      estimand = "ATT",
      M = 1,
      weights = NULL,
      pop.size = 1000,
      max.generations = 100,
      wait.generations = 4,
      caliper = .25,
      print.level = 1,
      cluster = rep("localhost", 4)
    )
    saveRDS(gen_model, gen_path)
  }
  t_gen <- as.numeric(difftime(Sys.time(), t0, units="mins"))
  cat(glue(">> GenMatch temps = {round(t_gen,1)} min (cache={used_cache_gen})\n"))
  
  # --- matchit() ---
  used_cache_match <- FALSE
  t1 <- Sys.time()
  if (file.exists(match_path) && !isTRUE(overwrite$match)) {
    cat(">> matchit: cache trouvé → lecture\n")
    m_out <- readRDS(match_path)
    used_cache_match <- TRUE
  } else {
    cat(">> matchit: calcul en cours...\n")
    fml <- as.formula(paste("treatment ~", paste(matching_variables, collapse=" + ")))
   
    
     m_out <- matchit(
      formula   = fml,
      data      = dat_m,
      method    = "genetic",
      distance  = "mahalanobis",
      gen.match = gen_model
    )
     
    saveRDS(m_out, match_path)
  }
  
  matched <- match.data(m_out, data = sf::st_drop_geometry(dat_m)) %>%
    dplyr::filter(weights > 0)
  
  saveRDS(matched, matched_out_path)
  cat(glue(">> N appariés = {nrow(matched)} (écrit: {matched_out_path})\n"))
  
  
  tibble(
    Année = year,
    'Total des observations' = n_total,
    'Après filtre/NA' = n_filt,
    Traités = n_treat,
    Contrôles = n_ctrl,
    'N appariés' = nrow(matched)
  )
}

need_overwrite <- function(year) {
  gen_path   <- glue("data/derived/gen_match_model_{year}_5km.rds")
  match_path <- glue("data/derived/matching_result_{year}_5km.rds")
  list(gen = !file.exists(gen_path), match = !file.exists(match_path))
}

# --- Exécution avec progression ---
yrs <- c(1997, 2008, 2011, 2013, 2016, 2021)


res_list <- vector("list", length(yrs))
names(res_list) <- yrs

with_progress({
  p <- progressor(along = yrs)

for (i in seq_along(yrs)) {
  yr <- yrs[i]
  ow <- need_overwrite(yr) 
  cat(glue("\n>> overwrite {yr}: gen={ow$gen}, match={ow$match}\n"))
  cat(sprintf("Start %s", yr))
  t_all <- Sys.time()
  res_list[[i]] <- tryCatch(
    run_matching_year(yr, overwrite = ow),
    error = function(e) { warning(glue("Year {yr} ERROR: {e$message}")); NULL }
  )
  cat(sprintf("Done %s (%.1f min)",
            yr, as.numeric(difftime(Sys.time(), t_all, units="mins"))))
}
})

result_list <- purrr::compact(res_list) |> bind_rows()
saveRDS(result_list, "data/derived/matching_summary_all_years_5km.rds")

bal_tabs <- purrr::imap(res_list, ~ {if (!is.null(.x)) {
  tryCatch(cobalt::bal.tab(.x$m), error = function(e) NULL) } else {
    NULL
  }
})

saveRDS(bal_tabs, "data/derived/matching_balance_tabs_all_years_5km.rds")

print(result_list)
```

Après le matching, nous obtenons:

-   1997: 5124 groupes appariées dont 624 traités et 4141 contrôles

-   2008: 13364 groupes appariées dont 1266 traités et 11221 contrôles

-   2011: 6025 groupes appariées dont 528 traités et 5076 contrôles

-   2013: 6375 groupes appariées dont 874 traités et 5092 contrôles

-   2016: 9295 groupes appariées dont 863 traités et 7933 contrôles

-   2021: 15364 groupes appariées dont 1806 traités et 12487 contrôles

##### Checking covariate balance: test before matching

Nous allons vérifier l'équilibre relatif des variables mesurées dans des unités différentes avant le matching pour mesurer l'écart entre les moyennes des covariables dans les groupes de traitement et de contrôle pour un buffer de 5 km.

```{r}
# Load 
hr_list <- setNames(
  lapply(yrs, function(y) read_rds(paste0("data/derived/hr_", y, "_final_5km.rds"))),
  yrs
)

# Equilibre des covariables
check_balance_before <- function(df, year, matching_variables) {
  
  data <- df %>%
    filter(GROUP %in% c("Treatment", "Control")) %>%
    mutate(treatment = if_else(GROUP == "Treatment", 1, 0))

  formula <- reformulate(matching_variables, response = "treatment")
  
  # Balance avant appariement
  bal_before <- bal.tab(
    formula,
    data = data,
    estimand = "ATT",
    un = TRUE,
    abs = TRUE
  )
  
  # Extraction du Standardized Mean Difference (SMD)
 balance_df <- bal_before$Balance %>%
    as.data.frame() %>%
    tibble::rownames_to_column("Variable")

  smd_col <- grep("Diff|Std", names(balance_df), value = TRUE)[1]

  smd_table <- balance_df %>%
    dplyr::select(Variable, SMD = all_of(smd_col)) %>%
    mutate(
      Year = year,
      Equilibre = if_else(abs(SMD) <= 0.1, "Équilibré", "Déséquilibré")
    ) %>%
    relocate(Year)

  return(smd_table)
}

balance_results <- lapply(names(hr_list), function(y) {
  check_balance_before(hr_list[[y]], as.numeric(y), matching_variables)
})

balance_results <- bind_rows(balance_results)

balance_results

# Distribution des covariables
data_list <- list(
  "1997" = hr_1997_final_5km,
  "2008" = hr_2008_final_5km,
  "2011" = hr_2011_final_5km,
  "2013" = hr_2013_final_5km,
  "2016" = hr_2016_final_5km,
  "2021" = hr_2021_final_5km 
)


  density_plot <- function(data, year, matching_variables){
    data %>%
      filter(GROUP %in% c("Treatment", "Control")) %>%
      mutate(GROUP =factor(GROUP, levels = c("Control", "Treatment"))) %>%
    pivot_longer(cols = all_of(matching_variables), names_to = "variable", values_to = "value") %>%
    ggplot(aes(x = value, fill = GROUP)) +
    geom_density(alpha = 0.5, color = "black", linewidth = 0.7, adjust = 0.7) +
    facet_wrap(~variable, scales = "free") + 
    scale_fill_manual(values = c("Control" = "green", "Treatment" = "blue")) +
    labs(
      title = paste("Covariate distribution before matching(", year, ")", sep = ""),
      x = "Valeur de la covariable",
      y = "Densité",
      fill = "Group"
    ) + 
    theme_minimal()
  }
    
print(density_plot(hr_1997_final_5km, 1997, matching_variables))
print(density_plot(hr_2008_final_5km, 2008, matching_variables))
print(density_plot(hr_2011_final_5km, 2011, matching_variables))
print(density_plot(hr_2013_final_5km, 2013, matching_variables))
print(density_plot(hr_2016_final_5km, 2016, matching_variables))
print(density_plot(hr_2021_final_5km, 2021, matching_variables))
```

L'analyse de l'équilibre avant appariement montre que, pour la plupart des années, les différences moyennes standardisées entre les groupes traités et contrôles restent inférieures au seuil de 0.1, indiquant un bon équilibre. En 1997, toutes les covariables présentent un bon équilibre, seule la variable population_count_2000 demeure déséquilibrer (Diff.Un = 0.2107). L'année 2008 affiche l'équilibre les plus satisfaisant, avec des différences quasi nulles pour toutes les covariables. En 2011 et 2013, l'équilibre demeure globalement correct, toutefois la variable population_count_2000 reste légèrement déséquilibrée avec une différence standardisée de 0.1352 pour 2011 et 0.0903 pour 2013. L'année 2016 constitue le cas le plus problématiques pour plusieurs covariables, la variable treecover_ara_2000 (Diff.Un = 0.1113) et population_count_2000 (Diff.Un = 0.1457) dépassant le seuil de 0.1. En revanche, pour 2021, la différence standardisée pour toutes les covariables est inférieure à 0.1.

Ci-suit le test de l'équilibre après l'appariement pour chaque covariable d'appariement.

##### Checking covariate balance: test after matching

```{r}
# Balance test after matching: Quantile- quantile QQ Plot analysis
check_balance_after <- function(data_matched, year, matching_variables, plot_dir = "plots") {
  
  # Balance après appariement
  bal_after <- cobalt::bal.tab(
    x = data_matched[, matching_variables],
    treat = data_matched$GROUP,
    un = TRUE,
    abs = TRUE,
    estimand = "ATT"
  )
  
  print(bal_after)
  
  # QQ Plot
  year_dir <- file.path(plot_dir, glue("QQplots_{year}"))
  dir.create(year_dir, recursive = TRUE, showWarnings = FALSE)
  
  matching_variables %>% walk(function(var){
  if(!is.numeric(data_matched[[var]])){
    return(NULL)
  }
    
    p <- ggqqplot(
      data_matched, x = var, color = "GROUP",
      palette = c("#1f77b4", "#ff7f0e"),
      title = glue("QQ Polt - {var} ({year})")
    ) + 
      geom_abline(slope = 1, intercept = 0, linetype = "dashed") + 
      theme_minimal() +
      labs(x = "Quantiles théoriques", y = "Quantiles observés", color = "Groupe") + 
      theme(plot.title = element_text(hjust = 0.5))
    
    
    ggsave(
      filename = file.path(year_dir, glue("QQplot_{var}_{year}.png")), plot = p, width = 7, height = 5
    )
  })
  
  return(list(balance = bal_after))
}

results_list <- map(yrs, function(y){
  data_y <- readRDS(glue("data/derived/data_matched_{y}_5km.rds"))
  check_balance_after(data_y, y,matching_variables)
})

names(results_list) <- yrs


# Balance test after matching: Histogram
plot_mirror_hist_5km <- function(year, variable){
  
 df <- readRDS(glue("data/derived/data_matched_{year}.rds")) %>%
   filter(GROUP %in% c("Treatment", "Control")) %>%
   mutate(
     treatment = ifelse(GROUP == "Treatment", "Traité", "Contrôle"), 
     value = .data[[variable]]
   )
 
 ggplot() +
   geom_histogram(
     data = df %>% filter(treatment == "Traité"), 
     aes(x = value), 
     bins = 30, 
     fill = "blue", 
     alpha = 0.6
     ) + 
 geom_histogram(
   data = df %>% filter(treatment == "Contrôle"), 
   aes(x = value, y = -after_stat(count)),
   bins = 30, 
   fill = "green", 
   alpha = 0.6
   ) + 
   geom_hline(yintercept = 0, color = "black") + 
   labs(
     title = glue("Covariate after matching - {variable} - 5km ({year})"),
     x = variable, 
     y = "Effectifs (+ Traités / - Contrôles)"
     ) + 
   annotate("text", x = Inf, y = -Inf, label = "Traités", hjust = 1.1, vjust = 2, color = "blue") +
   annotate("text", x = Inf, y = -Inf, label = "Contrôles", hjust = 1.1, vjust = -1.5, color = "green") +
   theme_minimal()
 
}

walk(yrs, function(y){
  walk(matching_variables, function(v){
    message(glue("→ Histogramme-5km {v} ({y})"))
    print(plot_mirror_hist_5km(y, v))
  })
})
```

Après le matching, pour l'ensemble des variables de chaque année, la différence moyenne standardisée s'est améliorée. Toutefois, la variable population_count_2000 reste difficile à équilibrer. Cela s'explique par le fait que les aires protégées ne sont pas implantées de manière aléatoire dans le paysage: celles gérées pour la conservation de la biodiversité se situent généralement dans des zones plus isolées et moins peuplées, tandis que les aires gérées pour des usages mixtes sont entourées de populations plus denses. Comme le souligne @chung2018 "la densité démographique autour des zones protégées gérées à des fins mixtes est également plus élevée que celle des zones protégées gérées principalement pour la conservation de la biodiversité." Cette hétérogénéité entre les contextes humains entourant les différents types d'aires protégées crée un manque d'overlap dans la distribution de la densité de population entre les groupes traités et contrôles, rendant cette variable difficile à équilibrer. même après matching.

#### Estimation

##### Overall effect on livelihoods

Cette partie évalue dans quelle mesure les aires protégées influencent les conditions de vie des ménages.

```{r}
# 2X2 DiD----------------------------------------------
library(fixest)
library(didimputation)
library(broom)

# Chargement des données
d97_5km <- read_rds("data/derived/data_matched_1997_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_1995,
         spei_wc_n_1 = spei_wc_1996,
         spei_wc_n   = spei_wc_1997) %>%
  mutate(hv219 = zap_labels(hv219), # hhh sex (1/2)
         hv220 = zap_labels(hv220)) # hhh age (num)

d08_5km <- read_rds("data/derived/data_matched_2008_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2006,
         spei_wc_n_1 = spei_wc_2007,
         spei_wc_n   = spei_wc_2008) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d11_5km <- read_rds("data/derived/data_matched_2011_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2009,
         spei_wc_n_1 = spei_wc_2010,
         spei_wc_n   = spei_wc_2011) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d13_5km <- read_rds("data/derived/data_matched_2013_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2011,
         spei_wc_n_1 = spei_wc_2012,
         spei_wc_n   = spei_wc_2013) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d16_5km <- read_rds("data/derived/data_matched_2016_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2014,
         spei_wc_n_1 = spei_wc_2015,
         spei_wc_n   = spei_wc_2016) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d21_5km <- read_rds("data/derived/data_matched_2021_5km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2019,
         spei_wc_n_1 = spei_wc_2020,
         spei_wc_n   = spei_wc_2021) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

# Préparation des données
dat_5km <- bind_rows(d97_5km, d08_5km, d11_5km, d13_5km, d16_5km, d21_5km) %>%
  filter(GROUP %in% c("Treatment","Control")) %>%
  mutate(
    hv219   = factor(hv219, levels = c(1,2), labels = c("Homme","Femme")), # sexe (cat.)
    hv220   = as.numeric(hv220),                                           # âge
    treat   = as.integer(GROUP == "Treatment"),
    w_svy   = hv005 / 1e6,
    w_all   = w_svy * weights, # poids d'enquête × poids de matching (si 'weights' existe)
    id      = row_number(),
    # Map des années de statut -> première année d'observation post (treatment_phase)
    treatment_phase = case_when(
      STATUS_YR == 2010 ~ 2011,
      STATUS_YR == 2012 ~ 2013,
      STATUS_YR == 2015 ~ 2016,
      STATUS_YR == 2017 ~ 2021,
      is.na(STATUS_YR)  ~ 0,
      TRUE               ~ STATUS_YR
    )
  )

# Outcome h
yvar <- "wealth_centile_rural_weighted"

# fixest DID 2×2: placebo 1997–2008, traitement 2008–2021 ------------------

# Placebo 1997–2008
pre_5km <- dat_5km %>%
  filter(DHSYEAR %in% c(1997, 2008)) %>%
  mutate(post = as.integer(DHSYEAR == 2008),
         treat_post = treat * post)

f_pre <- as.formula(paste(
  yvar, "~ treat + post + treat_post +",
  "spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220"
))

m_pre <- feols(f_pre, data = pre_5km, weights = ~ w_all, cluster = ~ hv001)

# Traitement 2008–2021
main <- dat_5km %>%
  filter(DHSYEAR %in% c(2008, 2021)) %>%
  mutate(post = as.integer(DHSYEAR == 2021),
         treat_post = treat * post)

f_main <- f_pre  # même formule

m_main <- feols(f_main, data = main, weights = ~ w_all, cluster = ~ hv001)

etable(m_pre, m_main, headers = c("Placebo 97–08", "Traitement 08–21"))

# Extraction compacte des deux effets DID
did_row <- function(model, year_post, vc = ~ hv001, term = "treat_post"){
  summary(model, vcov = vc) %>% broom::tidy() %>%
    filter(term == !!term) %>%
    transmute(year = year_post, estimate, se = std.error)
}
did_df <- bind_rows(
  did_row(m_pre, 2008),
  did_row(m_main, 2021)
) %>%
  mutate(period = factor(ifelse(year == 2008, "1997–2008", "2008–2021"),
                         levels = c("1997–2008", "2008–2021")),
         lo = estimate - 1.96*se,
         hi = estimate + 1.96*se)

ggplot(did_df, aes(x = period, y = estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_errorbar(aes(ymin = lo, ymax = hi), width = .2) +
  geom_point(size = 3) +
  labs(x = NULL, y = "Effet DID sur le centile de richesse (pondéré)",
       title = "DID 2×2 avec IC clusterisés (hv001) - buffer 5 km")


# Staggered diff-in-diff----------------------------------------
# did2s (Gardner) : statique + event-study--------------------------------
library(did2s)

dat3 <- dat_5km %>%
  mutate(
    treat_on = as.integer(treatment_phase > 0 & DHSYEAR >= treatment_phase),
    rel_year = if_else(treatment_phase > 0, DHSYEAR - treatment_phase, Inf),
    # Binning prudent pour stabilité (-5..5)
    rel_year_binned = pmax(pmin(rel_year, 5), -5)
  )

# -- Statique (traitement "on/off")
did2s_static_5km <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(treat_on, ref = FALSE),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static_5km, headers = "did2s statique")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es_5km <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(rel_year_binned, ref = c(-1, Inf)),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es_5km, headers = "did2s event-study (-5..5)")

# Plot ES did2s
plot_did2s_5km <- broom::tidy(did2s_es_5km, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(k = as.numeric(sub("^rel_year_binned::", "", term))) %>%
  arrange(k)

ggplot(plot_did2s_5km, aes(k, estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s) - buffer 5 km")

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present_5km <- plot_did2s_5km$k[plot_did2s_5km$k < 0]
if(length(leads_present_5km) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present_5km, collapse="|"), ")$")
  print(fixest::wald(did2s_es_5km, keep = keep_regex))
}
```

Les résultats de l'estimation DID 2x2 indiquent qu'avant la mise en place des aires protégées, il n'y avait aucune différence d'évolution significative entre les groupes traités et contrôles. Le coefficient placebo treat_post est non significatif (7.743). De même, sur la période de traitement (2008-2021), le coefficient est légèrement négatif mais non significatif, indiquant l'absence d'effet détectable des aires protégées sur le centile de richesse des ménages ruraux. Les graphiques confirment également cela: pour le pré-traitement, l'effet est proche de zéro, tandis que pour le post-traitement, l'effet est plutôt négatif mais non significatif.

Dans l'analyse par event study (staggered adoption), un test de pre-trend a été réalisé à partir du test de Wald. Ce test examine l'hypothèse nulle H0 selon laquelle les coefficients associés aux périodes de pré-traitement rel_year_binned:: -5 et rel_year_binned::-3 sont conjointement égaux à zéro. Autrement dit, avant le traitement, pour les années -5 et -3 relatives à l'intervention, il ne doit pas y avoir d'effet. Le résultat du test indique que le p_value est égale à 0.4079145, largement supérieur au seuil de 0.05, donc l'hypothèse nulle est rejeté. Cela suggère que les trajectoires des groupes traités et contrôles étaient similaires avant le traitement pour les deux périodes, soutenant ainsi l'hypothèse des tendances parallèles. L'estimation par event study a aussi montré qu'un effet positif apparaît trois ans après la mise en place de l'aire protégée (rel_year = 3: 19.03\*), suggérant une amélioration du niveau de vie. Toutefois, l'absence de significativité pour les autres années montre qu'il ne s'agit pas d'un effet régulier ou durable.

##### Effect on inequalities

###### Staggered DID

Cette partie estime les effets sur les inégalités pour vérifier l'hypothèse 2: Les aires protégées exacerbent les inégalités économiques, car ce sont les personnes les plus aisées ou les mieux connectées qui profitent le plus des avantages.

```{r}
# Staggered DiD-----------------------------------------
yvar <- "zscore_wealth"

# did2s (Gardner) : statique + event-study--------------------------------
# -- Statique (traitement "on/off")
did2s_static_5km_zscore <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(treat_on, ref = FALSE),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static_5km_zscore, headers = "did2s statique")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es_5km_zscore <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(rel_year_binned, ref = c(-1, Inf)),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es_5km_zscore, headers = "did2s event-study (-5..5) - zscore - buffer 5 km")

# Plot ES did2s
plot_did2s_5km_zscore <- broom::tidy(did2s_es_5km_zscore, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(k = as.numeric(sub("^rel_year_binned::", "", term))) %>%
  arrange(k)

ggplot(plot_did2s_5km_zscore, aes(k, estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s) - zscore - buffer 5 km")

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present_5km_zscore <- plot_did2s_5km_zscore$k[plot_did2s_5km_zscore$k < 0]
if(length(leads_present_5km_zscore) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present_5km_zscore, collapse="|"), ")$")
  print(fixest::wald(did2s_es_5km_zscore, keep = keep_regex))
}

```

L'estimation DID 2x2 montre que l'effet moyen d'être dans un cluster traité (situé à proximité des aires protégées créées après 2008) n'est pas statistiquement significatif sur le Z-score de l'indice de richesse (𝜷 = 0.0029; SE = 0.0082). De plus R² et R² ajusté sont proches de zéro et identiques, indiquant que le modèle n'explique pratiquement aucune part de la variation du niveau de richesse.

Le modèle event study ne met en évidence aucune tendance significative avant la mise en place des aires protégées. L'hypothèse des tendances parallèles est vérifié car l'hypothèse nulle est rejeté (p-value = 0.06151144 \> 0.05). Après la mise en place de l'aire protégée, un effet positif émerge deux ans après l'intervention (rel_year = 2: 0.0228\*), puis devient particulièrement marqué au bout de trois ans (rel_year = 3: 0.0565\*\*\*). Toutefois, cet effet disparaît au bout de cinq ans, indiquant que l'effet n'est pas durable. Le R² et R² ajusté montrent que la part de variance expliquée par le traitement est minimale.

###### Quantile treatment effect

Cette partie mesure l'effet du traitement à différents points de la distribution du zscore de l'indice de richesse: au niveau des ménages les plus pauvres (quantiles bas), la classe moyenne et au niveau des ménages les plus aisés (quantiles élevés).

```{r}
# Quantile treatment effects
# Testing Quantile treatment effect------------------------------
library(qte)

# Avec CiC -------------------

## Traitement 2008 -> 2021
set.seed(123)
dat_2per <- dat_5km %>%
  filter(DHSYEAR %in% c(2008, 2021)) %>%
  mutate(treat = as.integer(GROUP == "Treatment"))

cic_res <- suppressWarnings(CiC(
  formla = wealth_centile_rural_weighted ~ treat,
  t = 2021, tmin1 = 2008, tname = "DHSYEAR",
  data = dat_2per,
  panel = FALSE, # repeated cross-sections
  se = TRUE, iters = 200, # bootstrap
  probs = seq(0.05, 0.95, 0.05),
  xformla = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220
))

summary(cic_res)
ggqte(cic_res) + labs(x="Quantiles", y="QTET", title="CiC QTET: 2008-2021")

## placebo------------------------------------------------------

## Placebo: 1997 -> 2008
dat_placebo <- dat_5km %>%
  filter(DHSYEAR %in% c(1997, 2008)) %>%
  mutate(treat = as.integer(GROUP == "Treatment"))

# (Optional) sanity check:
# with(dat_placebo, table(DHSYEAR, treat))

cic_pre <-  suppressWarnings(CiC(
  formla = wealth_centile_rural_simple ~ treat,
  t = 2008, tmin1 = 1997, tname = "DHSYEAR",
  data = dat_placebo,
  panel = FALSE, # repeated cross-sections
  se = TRUE, iters = 100, # bootstrap
  probs = seq(0.05, 0.95, 0.05),
  xformla = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220
))

summary(cic_pre)

ggqte(cic_pre) +
  labs(x = "Quantiles", y = "QTET",
       title = "Placebo CiC QTET: 1997-2008")
```

Pour l'estimation principale (2008-2021), les résultats de QTE indiquent un effet négatif sur l'ensemble de la distribution de la richesse des ménages. Toutefois, l'impact du traitement n'est pas homogène pour toutes les classes. Il est plus marqué pour les classes moyennes (quantile variant de 0.30 à 0.60 avec des effets entre -20 et -23), tandis qu'il est plus faible ches les ménages les plus pauvres et les plus riches. L'effet moyen du traitement (ATE = -16.36) confirme une baisse significative du niveau de richesse associée à la proximité des aires protégées créées après 2008. Ces résultats suggèrent que la mise en place des aires protégées renforcent les inégalités.

Pour le placebo (1997-2008), Les ménages les plus pauvres semblent peu affectés, voire légèrement bénéficiaires de la mise en place des aires protégées, avec des QTE positifs (quantiles variant de 5.53 à .

##### Heterogeneity

Cette partie vérifie l'hypothèse 3 portant sur l'hétérogénéité des effets selon le type de gouvernance des aires protégées.

```{r}
# Création du groupe IUCN 
dat3 <- dat3 %>%
  filter(!is.na(IUCN_CAT), !is.na(treat_on)) %>%
  mutate(
    IUCN_group = case_when(
    IUCN_CAT %in% c("Ia", "Ib", "II", "III", "IV") ~ "strict",
    IUCN_CAT %in% c("V", "VI") ~ "usage_multiple", 
    TRUE ~ NA_character_
  ),
  IUCN_group = factor(IUCN_group, levels = c("strict", "usage_multiple")),
  rel_year_binned = factor(rel_year_binned, levels = -5:5)
  ) %>%
  filter(!is.na(IUCN_group))

run_did2s_es <- function(data, yvar) {
  
  # DID Statique
  did2s_static_5km <- did2s(
    data        = data,
    yname       = yvar,
    first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
    second_stage = ~ treat_on * IUCN_group,
    treatment   = "treat_on",
    cluster_var = "hv001",
    weights     = "w_all"
  )
  print(etable(did2s_static_5km, headers = paste("did2s statique -", yvar)))
  
# DID event study
  
  did2s_es_5km <- did2s(
    data = data,
    yname = yvar, 
    first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
    second_stage = ~ i(rel_year_binned, IUCN_group, ref = -1),
    treatment   = "treat_on",
    cluster_var = "hv001",
    weights     = "w_all"
  )
  
  print(etable(did2s_es_5km, 
               headers = paste("did2s event-study (-5..5) par statut IUCN - buffer de 5km", yvar)))
  
    # Extraction des coefficients
  tidy_es <- broom::tidy(did2s_es_5km, conf.int = TRUE) %>%
    filter(grepl("^rel_year_binned::", term)) %>%
    mutate(
      year = as.numeric(stringr::str_extract(term, "(?<=::)-?[0-9]+")),
      
      # identifier strict vs usage_multiple
      group = case_when(
        grepl("usage_multiple", term, ignore.case = TRUE) ~ "usage_multiple",
        grepl("strict", term, ignore.case = TRUE) ~ "strict",
        TRUE ~ NA_character_
      ),
      outcome = yvar
    ) %>%
    filter(!is.na(group))

  #Plot
  plot_title <- paste0("Event-study (did2s) -", yvar, "\nHétérogénéité par statut IUCN - buffer 5km")
  
  g <- ggplot(tidy_es, aes(x = year, y = estimate, color = group)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
    labs(
      x = "Années relatives au 1er traitement (binnées -5..5)",
      y = "Effet estimé",
      title = plot_title,
      color = "Catégorie IUCN"
    ) +
    theme_minimal(base_size = 14)
  
  print(g)
  
  # Test de pré-tendances
  leads <- tidy_es %>% filter(year < 0)
  
  if(nrow(leads) > 0){
    keep_regex <- paste0("^rel_year_binned::(", paste(unique(leads$year), collapse="|"), "):")
    print(wald(did2s_es_5km, keep = keep_regex))
  }
  
  return(list(
    static = did2s_static_5km,
    es     = did2s_es_5km,
    coef   = tidy_es,
    plot   = g
  ))
}


res_wealth <- run_did2s_es(dat3, "wealth_centile_rural_weighted")
res_zscore <- run_did2s_es(dat3, "zscore_wealth")

```

[**Outcome**]{.underline}: Wealth_centile_rural

L'estimation du DID statique montre qu'être situé dans un rayon de 5 km autour d'une aire protégée (que ce soit pour les aires strictes ou pour les aires à usage multiple) n'a pas d'effet significatif sur le centile de richesse.

L'analyse en event study confirme également l'absence d'effet significatif avant le traitement. L'hypothèse de tendances parallèles est donc respectée. Au moment du traitement (rel_year_binned = 0), le résultat montre un effet positif et très significatif. Les ménages proches d'une aire protégée strict voient leur centile de richesse augmenter fortement (coefficient = 29.59\*). Les ménages proches d'une aire protégée à usage multiple connaissent également une augmentation de leur centile de richesse (coefficient = 10.48\*), mais plutôt modéré. Ces résultats apparaissent clairement sur le graphique, qui illustre l'évolution de l'effet estimé du traitement (à 5 km d'une aire protégée) avant et après le premier traitement, distinguant les aires protégées strictes et les aires en usage multiple.

A savoir que le résultat ne comprennent que les bins allant -5 à +2, car les bins +3, +4 et +5 n'ont pas assez d'observations pour certaines combinaisons et ne peuvent d'être estimer.

[**Outcome:**]{.underline} zscore_wealth

L'estimation DID statique indique que le fait de vivre dans un rayon de 5 km des aires protégées n'a pas d'effet significatif sur le zscore de richesse. Les effets diffèrent un peu entre les aires strictes et les aires à usages multiples.

De même pour l'analyse par event study, l'effet du traitement n'est pas non plus significatif. Les effets oscillent autour de 0, indiquant que les ménages proches des aires protégées ne deviennent ni plus riche ni plus pauvres, en termes de richesse standardisée après traitement.

### Test pour une distance de 15km

#### Assignation du traitement

```{r}
# Buffer de 15 km
buffer_dist <- 15000

# Créer des buffers de 15 km autour des AP
buffer_15km_before_2008 <- wdpa_before_2008 %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)


buffer_15km_from_2008 <- wdpa_from_2008  %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = buffer_dist) %>%
  st_make_valid() %>%
  st_union() %>%
  st_as_sf() %>%
  st_make_valid() %>%
  st_transform(standard_crs)

# Visualisation des cartes-----------------------------------------------
tmap_mode("view")

tm_shape(contour_mada) + 
  tm_borders(col = "black", lwd = 1) +
  
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "blue", 
              col =  "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) +
  
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "darkgreen", 
              col = "black", 
              fill_alpha = 0.5,
              id = "ORIG_NAME", 
              popup.vars = c("Année de création" = "STATUS_YR")) + 
  
tm_shape(buffer_15km_from_2008) +
tm_borders(col = "darkgreen", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
  
tm_shape(buffer_15km_before_2008) +
tm_borders(col = "blue", lwd = 2, lty = "dashed", fill.legend = tm_legend_hide()) +
tm_add_legend(
  type = "polygons", 
  fill = c("blue", "darkgreen"), 
  labels = c("avant 2008", "après 2008")) +
  tm_title("Aires protégées du WDPA par période de création - 15km </b><br/>Source: WDPA, 2024") +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE,
    legend.title.size = 1.2,
    legend.text.size = 0.8
  ) +
  tm_compass(type = "8star", position = c("right", "top")) +
  tm_scalebar(position = c("right", "bottom"))

# Classification des clusters---------------------------------------------------------
#| fig-cap: "Grappes d'enquêtes DHS par rapport aux aires protégées existantes"


classify_clusters_with_pa <- function(cluster_gps,
                                      buffer_before,   # union of <2008
                                      wdpa_after,      # polygons >=2008 (no union)
                                      buffer_dist = 15000,
                                      label_treat = "Treatment",
                                      label_excl  = "Excluded",
                                      label_ctrl  = "Control") {

  # per-PA buffers (keep attrs)
  wdpa_after_buf <- wdpa_after %>%
    st_transform(mdg_crs) %>%
    mutate(geometry = st_buffer(geometry, buffer_dist)) %>%
    st_transform(standard_crs)

  # flags
  in_after  <- st_within(cluster_gps, st_union(wdpa_after_buf),  sparse = FALSE)[,1]
  in_before <- st_within(cluster_gps, buffer_before,            sparse = FALSE)[,1]

  base <- cluster_gps %>%
    mutate(groupe = case_when(
      in_after & !in_before & URBAN_RURA == "R" ~ label_treat,
      in_before | URBAN_RURA == "U"            ~ label_excl,
      TRUE                                     ~ label_ctrl
    ))

  # enrich treated with oldest+nearest PA
  treated_pts <- base %>% filter(groupe == label_treat)

  if (nrow(treated_pts) == 0) return(base)

  cand <- st_join(treated_pts, wdpa_after_buf, join = st_within, left = FALSE) %>%
  mutate(
    .idx = match(WDPAID, wdpa_after$WDPAID),
    dist_km = as.numeric(
      st_distance(
        geometry,
        wdpa_after$geometry[.idx],
        by_element = TRUE
      )
    ) / 1000
  ) %>%
  dplyr::select(-.idx)

  best <- cand %>%
    group_by(DHSCLUST) %>%
    slice_min(STATUS_YR, with_ties = TRUE) %>%
    slice_min(dist_km,   with_ties = FALSE) %>%
    ungroup() %>%
    st_drop_geometry() %>%
    select(DHSYEAR, DHSCLUST, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

  base %>% left_join(best, by = c("DHSYEAR","DHSCLUST"))
}

gps_1997_class <- classify_clusters_with_pa(gps_1997, buffer_15km_before_2008, 
                                            wdpa_from_2008)
gps_2008_class <- classify_clusters_with_pa(gps_2008, buffer_15km_before_2008, 
                                            wdpa_from_2008)
gps_2011_class <- classify_clusters_with_pa(gps_2011, buffer_15km_before_2008, 
                                            wdpa_from_2008)
gps_2013_class <- classify_clusters_with_pa(gps_2013, buffer_15km_before_2008,
                                            wdpa_from_2008)
gps_2016_class <- classify_clusters_with_pa(gps_2016, buffer_15km_before_2008,
                                            wdpa_from_2008)
gps_2021_class <- classify_clusters_with_pa(gps_2021, buffer_15km_before_2008,
                                            wdpa_from_2008)


gps_all_class_15km <- bind_rows(
  gps_1997_class,
  gps_2008_class,
  gps_2011_class,
  gps_2013_class,
  gps_2016_class,
  gps_2021_class
)

# Créer un plot pour visualiser la carte des AP avec les clusters----------------------
tm_shape(buffer_15km_from_2008) +
  tm_borders("green", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +  
  tm_shape(buffer_15km_before_2008) +
  tm_borders("darkgreen", 
             lwd = 2, 
             lty = "dashed", 
             fill.legend = tm_legend_hide()) +
  tm_shape(wdpa_from_2008) +
  tm_polygons(fill = "green", 
              fill_alpha = 0.5,
              col = "black", 
              fill.legend = tm_legend(title = "à partir de 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(wdpa_before_2008) +
  tm_polygons(fill = "darkgreen", 
              fill_alpha = 0.5, 
              col =  "black", 
              fill.legend = tm_legend(title = "avant 2008", position = tm_pos_in("right", "top"))) +
  tm_shape(gps_all_class_15km) +
  tm_symbols(
    fill = "groupe", 
    fill.legend = tm_legend(title = "Groupes"),
    fill.scale = tm_scale(values = c("Treatment" = "red", "Control" = "blue", "Excluded" = "gray")),
     size = 0.5,
    shape = 21
  ) +
  tm_facets("DHSYEAR") +
  tm_add_legend(type = "polygons", 
                fill = c("green", "darkgreen"), 
                labels = c("à partir de 2008", "avant 2008")) +
  tm_layout(
    legend.outside = TRUE, 
    legend.position = c("left", "top"),
    frame = FALSE
  ) +
  tm_scalebar(position = c("left", "bottom"))

# Tableau récapitulatif du nombre de grappes d'enquête classées dans chaque groupe-----
treated_sub_clusters <- gps_all_class_15km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  mutate(subcat = case_when(
    !is.na(STATUS_YR) & DHSYEAR <  STATUS_YR ~ "Avant traitement",
    !is.na(STATUS_YR) & DHSYEAR >= STATUS_YR ~ "Déjà traités",
    TRUE ~ NA_character_
  )) %>%
  count(DHSYEAR, subcat, name = "n_clusters") %>%
  pivot_wider(names_from = subcat, values_from = n_clusters, values_fill = 0)

# Ligne "Ensemble" (tous les traités, quel que soit le statut)
treated_all_clusters <- gps_all_class_15km %>%
  st_drop_geometry() %>%
  filter(groupe == "Treatment") %>%
  count(DHSYEAR, name = "Ensemble")

# Colonnes Contrôles / Exclus
ctrl_excl_clusters <- gps_all_class_15km %>%
  st_drop_geometry() %>%
  filter(groupe %in% c("Control", "Excluded")) %>%
  mutate(Groupe = recode(groupe, Control = "Contrôles", Excluded = "Exclus")) %>%
  count(DHSYEAR, Groupe, name = "n") %>%
  pivot_wider(names_from = Groupe, values_from = n, values_fill = 0)

# Assemblage large (années en lignes)
tab_wide_clusters <- list(treated_sub_clusters, treated_all_clusters, 
                          ctrl_excl_clusters) %>%
  Reduce(function(x, y) full_join(x, y, by = "DHSYEAR"), .) %>%
  arrange(DHSYEAR) %>%
  mutate(across(-DHSYEAR, ~replace_na(.x, 0L)))

# Tableau gt : spanner "Traitement" + colonnes Contrôles / Exclus
gt_table_clusters <- tab_wide_clusters %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de grappes par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des grappes *Traitement*."),
    locations = cells_title(groups = "title")
  )

gt_table_clusters

# Tableau récapitulatif du nombre de ménages d'enquête classées dans chaque groupe-----
load_dhs_data <- function(dhs_folder, year, identifier) {
  folder_pattern <- paste0(".*", year, ".*", identifier)
  
  matching_folder <- list.dirs(dhs_folder, full.names = TRUE, recursive = TRUE) %>%
    keep(~ str_detect(.x, folder_pattern))
  
  if (length(matching_folder) == 0) {
    stop("No folder found for the specified year and identifier.")
  }
  
  if (identifier == "GE") {
    file_pattern <- "\\.shp$"
    data_loader <- function(file) st_read(file, quiet = TRUE)
  } else {
    file_pattern <- "\\.[Dd][Tt][Aa]$"
    data_loader <- read_dta
  }
  
  target_file <- list.files(matching_folder, pattern = file_pattern, full.names = TRUE)
  
  if (length(target_file) == 0) {
    stop("No valid file found in the folder.")
  }
  
  data <- data_loader(target_file)
  
  return(data)
}

dhs_folder <- "data/raw/dhs"


# Années disponibles
years_all <- sort(unique(gps_all_class_15km$DHSYEAR))

# Compte ménages (toutes observations) 
households_counts_all <- map_dfr(years_all, function(y) {
  # HR de l'année
  hr <- load_dhs_data(dhs_folder, y, "HR") %>%
    mutate(DHSYEAR = y)  # pour la jointure avec la classification

  # Classification des grappes de l'année
  cl_y <- gps_all_class_15km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == y) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)

  # Jointure ménages <- classification (par cluster hv001)
  hr_cl <- hr %>%
    select(DHSYEAR, hv001) %>%
    left_join(cl_y, by = c("DHSYEAR" = "DHSYEAR", "hv001" = "DHSCLUST"))

  # Comptes par sous-catégories du traitement (DHSYEAR vs STATUS_YR)
  avant  <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR <  STATUS_YR) %>% nrow()
  deja   <- hr_cl %>% filter(groupe == "Treatment", !is.na(STATUS_YR), DHSYEAR >= STATUS_YR) %>% nrow()
  ens    <- hr_cl %>% filter(groupe == "Treatment") %>% nrow()
  ctrl   <- hr_cl %>% filter(groupe == "Control")   %>% nrow()
  excl   <- hr_cl %>% filter(groupe == "Excluded")  %>% nrow()

  tibble(
    DHSYEAR = y,
    `Avant traitement` = avant,
    `Déjà traités`     = deja,
    Ensemble           = ens,
    `Contrôles`        = ctrl,
    `Exclus`           = excl
  )
})

# Tableau gt (ménages, toutes observations)
gt_table_menages_all <- households_counts_all %>%
  rename(Année = DHSYEAR) %>%
  gt() %>%
  tab_header(title = "Nombre de ménages par année d'enquête et par groupe") %>%
  cols_label(
    `Avant traitement` = "Avant traitement",
    `Déjà traités`     = "Déjà traités",
    Ensemble           = "Ensemble",
    `Contrôles`        = "Contrôles",
    `Exclus`           = "Exclus"
  ) %>%
  tab_spanner(
    label = "Traitement",
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble)
  ) %>%
  fmt_number(
    columns = c(`Avant traitement`, `Déjà traités`, Ensemble, `Contrôles`, `Exclus`),
    decimals = 0, use_seps = TRUE
  ) %>%
  cols_align(align = "center", columns = everything()) %>%
  tab_footnote(
    footnote = md("**Avant traitement** : DHSYEAR < STATUS_YR (AP pas encore créée). **Déjà traités** : DHSYEAR ≥ STATUS_YR. **Ensemble** : total des ménages du groupe *Traitement*."), locations = cells_title(groups = "title"))

gt_table_menages_all   

# Sauvegarde des classifications des clusters 
all_class_15km <- gps_all_class_15km %>%
  select(DHSYEAR, DHSCLUST, GROUP = groupe, WDPAID, STATUS_YR, IUCN_CAT, dist_km)

write_csv(all_class_15km, "data/derived/cluster_treatment_classification_staggered_15km.csv")

write_csv(wdpa_before_2008, "data/derived/wdpa_before_2008_15km.csv")
write_csv(wdpa_from_2008, "data/derived/wdpa_from_2008_15km.csv")

# Classification des clusters avec les données HR des ménages--------------------------- 
for(year in years_all) {
  hr_data <- load_dhs_data(dhs_folder, year, "HR") %>%
    mutate(DHSYEAR = year)
  
  cluster_class <- gps_all_class_15km %>%
    st_drop_geometry() %>%
    filter(DHSYEAR == year) %>%
    select(DHSYEAR, DHSCLUST, groupe, STATUS_YR)
  
  hr_final_15km <- hr_data %>%
    rename(DHSCLUST = hv001) %>%
    left_join(cluster_class, by = c("DHSYEAR", "DHSCLUST")) %>%
    
    mutate(treatment = if_else(groupe == "Treatment", 1L, 0L),
           control = if_else(groupe == "Control", 1L, 0L))
  
  saveRDS(hr_final_15km, glue("data/derived/hr_{year}_final_15km.rds"))
    
}
```

#### Covariates Calculation

```{r}
# Load data
buffer_all_15km <- gps_all_class_15km %>%
  st_transform(mdg_crs) %>%
  st_buffer(dist = 15000) %>%
  st_transform(standard_crs)

# Chargement des données géophysiques des ménages--------------------------------
# Définir le chemin relatif pour ton répertoire local

outdir <- "data/raw/mapme"
dir.create(outdir, recursive = TRUE, showWarnings = FALSE)
mapme_options(outdir = outdir, verbose = TRUE)


# Couvert forestier
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km  %>% 
    get_resources(get_gfw_treecover())
})
toc() # 1.18 sec elapsed 

# Perte de couvert
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% 
  get_resources(get_gfw_lossyear()) 
})
toc() # 1.39 sec elapsed 

# NASA SRTM
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% 
  get_resources(get_nasa_srtm()) 
})
toc() # 5.41 sec elapsed 

# Worldpop 2000
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>%
    get_resources(get_worldpop(years = 2000))
})
toc() # 0.27 sec elapsed 
  
# Accesibility
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% 
  get_resources(get_accessibility_2000()) 
})
toc() # 0.25 sec elapsed 

# Maximum temperatures
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% get_resources(
    get_worldclim_max_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 86.71 sec elapsed 

# Minimum temperatures
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% get_resources(
    get_worldclim_min_temperature(years = 1980:2021, resolution = "2.5m")
  )
})
toc() # 93.67 sec elapsed 

# Precipitations
tic()
with_progress({
  buffer_all_15km <- buffer_all_15km %>% get_resources(
    get_worldclim_precipitation(years = 1980:2021, resolution = "2.5m")
  )
})
toc() #  25.87 sec elapsed
  
```

Après chargement et extraction des données sur les données géophysiques des ménages, les indicateurs des variables environnementales dans un rayon de 15 km autour de chaque grappe d'enquête sont à calculer.

```{r}
# Calcul des indicateurs------------------------------------------------------- 
if(file.exists("data/derived/spatial_covars_staggered_15km.rds")) {cat("Le fichier spatial_covars_staggered_15km.rds existe déjà")
} else {
    cat("Fichier introuvable, début du traitement... \n")
  
  # Créer un plan pour paralléliser les calculs
  plan(sequential)
  plan(multisession, workers = 4)
  
  # Maximum temperatures
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_temperature_max_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 28053.12 sec elapsed
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_max_temp_15km.rds", compress = "gz")
   
  
  # Minimum temperatures
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
         calc_temperature_min_wc( engine = "extract", stats = "mean")
      )
  })
  toc() # 26406.66 sec elapsed 
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_min_temp_15km.rds", compress = "gz")
  
  
  # Precipitations
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_precipitation_wc(engine = "extract", stats = "mean")
      )
  })
  toc() # 18938.39 sec elapsed 
 
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_precip_15km.rds", compress = "gz") 
  
  
  # Forest cover rate in 2000
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_treecover_area(years = 2000, min_size = 1, min_cover = 10)
      )
  })
  toc()   # 8712.08 sec elapsed
 
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_treecover_15km.rds", compress = "gz")
  
  
  # slope 
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_slope(engine = "extract", stats = "mean")
      )
  })
  toc() # 7270.96 sec elapsed  
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_slope_15km.rds", compress = "gz")
  
  
  # Elevation
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_elevation(engine = "extract", stats = "mean")
      )
  })
  toc() # 8016.01 sec elapsed 
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_elevation_15km.rds", compress = "gz")
  
  
  # Population density
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_population_count(engine = "extract", stats = "mean")
      )
  })
  toc() # 544.9 sec elapsed
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_pop_density_15km.rds", compress = "gz")
  
  
  # Accessibility
  tic()
  with_progress({
    buffer_all_15km <- buffer_all_15km %>%
      calc_indicators(
        calc_traveltime_2000(engine = "extract", stats = "mean")
      )
  })
  toc() # 289.5 sec elapsed  
  
  write_rds(buffer_all_15km, "data/derived/spatial_covars_partial_accessibility_15km.rds", compress = "gz")
  
  # Enregistrement final des données 
  write_rds(buffer_all_15km, "data/derived/spatial_covars_staggered_15km.rds")
 }
```

#### Spei calculation

Cette partie calcule l'évolution annuelle du SPEI, à l'échelle de 12 mois, pour un cluster pour la période de 1980 - 2021, avec un buffer de 15 km.

```{r}

# Load data 
spatial_covars_15km <- read_rds("data/derived/spatial_covars_staggered_15km.rds")

# Function to compute SPEI
compute_spei_annual <- function(tmin_tbl, tmax_tbl, prec_tbl, lat_deg) {
  # tmin_tbl/tmax_tbl/prec_tbl: tibbles avec colonnes `datetime` (Date) et `value` (num)
  d_tmin <- tibble(date = tmin_tbl$datetime, tmin = tmin_tbl$value)
  d_tmax <- tibble(date = tmax_tbl$datetime, tmax = tmax_tbl$value)
  d_prec <- tibble(date = prec_tbl$datetime, prec = prec_tbl$value)

  d_merged <- reduce(list(d_tmin, d_tmax, d_prec), left_join, by = "date") %>%
    arrange(date)

  d_clean <- drop_na(d_merged)  # supprime lignes avec NA

  # Si séries trop courtes, renvoyer squelette 1981:2021 en NA
  if (nrow(d_clean) < 12) {
    return(tibble(year = 1981:2021, spei_mean = NA_real_))
  }

  # PET (Hargreaves), bilan hydrique et SPEI mensuel
  pet <- hargreaves(Tmin = d_clean$tmin,
                    Tmax = d_clean$tmax,
                    Pre  = d_clean$prec,
                    lat  = lat_deg)

  wb <- d_clean$prec - pet

  wb_ts <- ts(wb,
              start = c(year(min(d_clean$date)), month(min(d_clean$date))),
              frequency = 12)

  spei_obj <- spei(wb_ts,
                   scale = 12,
                   ref.start = c(1981, 1),
                   ref.end   = c(2021, 12))

  tibble(datetime = d_clean$date,
         spei      = as.numeric(spei_obj$fitted)) %>%
    filter(datetime >= as.Date("1981-01-01"),
           datetime <= as.Date("2021-12-31")) %>%
    mutate(year = year(datetime)) %>%
    group_by(year) %>%
    summarise(spei_mean = mean(spei, na.rm = TRUE), .groups = "drop") %>%
    complete(year = 1981:2021, fill = list(spei_mean = NA_real_))
}

# Latitude géodésique depuis la géométrie (centroïde)
spatial_covars_spei_15km <- spatial_covars_15km %>%
  mutate(lat = st_coordinates(st_centroid(geometry))[, 2])

row1 <- spatial_covars_spei_15km[1, ]

spei_tbl_one <- compute_spei_annual(
  tmin_tbl = row1$temperature_min_wc[[1]],
  tmax_tbl = row1$temperature_max_wc[[1]],
  prec_tbl = row1$precipitation_wc[[1]],
  lat_deg  = row1$lat
)

# Graphique 
spei_2017 <- spei_tbl_one %>% 
  filter(year == 2017)

ggplot(spei_tbl_one, aes(x = year, y = spei_mean)) +
  geom_col(aes(y = pmax(0, -spei_mean)), alpha = 0.25) +  # barres pour sécheresse (optionnel)
  geom_line(linewidth = 0.8) +
  geom_vline(xintercept = 2017, color = "red", linetype = "dotted", linewidth = 1) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_label(
    data = spei_2017, 
    aes(x = 2017, y = spei_mean, 
        label = paste0("Année: 2017\nSPEI: ", round(spei_mean, 2))),
    nudge_x = 1, 
    nudge_y = 0.3,
    fill = "white",
    color = "black",
    linewidth = 0.4, 
    label.padding = unit(0.2, "lines")
  ) +
  
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI (scale=12) – cluster de démonstration",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# SPEI for all clusters 
spatial_covars_spei_15km <- spatial_covars_spei_15km %>%
  mutate(
    spei_wc = pmap(
      list(temperature_min_wc, temperature_max_wc, precipitation_wc, lat),
      ~ compute_spei_annual(..1, ..2, ..3, ..4)
    )
  )

spei_df <- spatial_covars_spei_15km %>%
  select(DHSCLUST, spei_wc) %>%
  unnest(spei_wc)

ggplot(spei_df, aes(x = year, y = spei_mean, group = DHSCLUST)) +
  geom_line(alpha = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Annual SPEI by cluster with 15 km buffer (1981–2021)",
       x = "Année", y = "SPEI (moyenne annuelle)") +
  theme_minimal()

# Chaque élément spei_wc devient une table {datetime, variable, unit, value}
spatial_covars_spei_15km <- spatial_covars_spei_15km %>%
  mutate(
    spei_wc = map(spei_wc, ~ .x %>%
      mutate(
        datetime = as.Date(paste0(.data$year, "-01-01")),
        variable = "spei_scale12_mean",
        unit     = "annual",
        value    = .data$spei_mean
      ) %>%
      select(datetime, variable, unit, value))
  )

# Sauvegarde (cohérente avec le reste de tes scripts)
spatial_covars_spei_df_15km <- as.data.frame(spatial_covars_spei_15km)
write_rds(spatial_covars_spei_df_15km, "data/derived/spatial_covars_spei_staggered_15km.rds")
cat("SPEI (annuel, 1981–2021) enregistré dans data/derived/spatial_covars_spei_staggered_15km.rds\n")
```

Dans l'ensemble, la série oscille autour de zéro, alternant des périodes humides et sèches. On observe toutefois plusieurs épisodes de sécheresse importante à la fin des années 1980. En 2017, le SPEI a une valeur particulièrement basse (SPEI = -2.21), qui d'après la classification de Vicente-Serrano et al. @2010 caractérise une sécheresse très sévère.

#### Variable consolidation

```{r}
# Covariates spatio-temporelles + classification de traitement
spatial_covars_spei_15km <- readRDS("data/derived/spatial_covars_spei_staggered_15km.rds")
all_covars <- spatial_covars_spei_15km %>%
  select(DHSYEAR, DHSCLUST, URBAN_RURA, treecover_area, slope, elevation,
         population_count, traveltime_2000, spei_wc)

all_class_15km <- read.csv("data/derived/cluster_treatment_classification_staggered_15km.csv")

# Helper: fabrique la table finale pour une année donnée
vars_to_nest <- c("treecover_area", "slope", "elevation",
                  "population_count", "traveltime_2000", "spei_wc")

build_year <- function(hr_object,
                       year,
                       hh_rural_path,
                       spei_years = (year-2):year) {

  # Charger HR (identifiants + variables chef) et HH_rural (centiles/zscore déjà calculés)
  hr <- hr_object %>%
    dplyr::select(hv001, hv002, hv219, hv220)
  
  hh_rural <- read_rds(hh_rural_path) # contient hv001/hv002 + wealth_* déjà prêts
  
  # Joindre covariates spatiaux + classification de groupes
  base <- hh_rural %>%
    left_join(hr, by = c("hv001", "hv002")) %>%
    left_join(
      all_covars %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    left_join(
      all_class_15km %>% filter(DHSYEAR == year) %>% select(-DHSYEAR),
      by = c("hv001" = "DHSCLUST")
    ) %>%
    mutate(DHSYEAR = year) %>%
    relocate(DHSYEAR, .before = everything())
  
  # Désimbriquer les covars imbriquées et appliquer la fenêtre temporelle SPEI
  #    moyenne par (hv001, hv002) pour chaque indicateur_année
  df_long <- base %>%
    select(hv001, hv002, any_of(vars_to_nest)) %>%
    pivot_longer(cols = any_of(vars_to_nest),
                 names_to = "indicator", values_to = "data") %>%
    unnest(data) %>%
    filter(indicator != "spei_wc" | year(datetime) %in% spei_years) %>%
    mutate(year_indicator = paste0(indicator, "_", year(datetime))) %>%
    select(hv001, hv002, year_indicator, value)
  
  df_wide <- df_long %>%
    pivot_wider(names_from = year_indicator, values_from = value,
                names_glue = "{year_indicator}") %>%
    group_by(hv001, hv002) %>%
    summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
  
  # Table finale (une ligne par ménage hv001/hv002)
  out <- base %>%
    select(-any_of(vars_to_nest)) %>%
    distinct(hv001, hv002, .keep_all = TRUE) %>%
    left_join(df_wide, by = c("hv001", "hv002"))
  
  out
}

# Application

hr_1997_final_15km <- read_dta("data/raw/dhs/DHS_1997/MDHR31DT/MDHR31FL.DTA") %>%
  build_year(year = 1997,
             hh_rural_path = "data/derived/hh_1997_rural_simpler.rds",
             spei_years = 1995:1997)

hr_2008_final_15km <- read_dta("data/raw/dhs/DHS_2008/MDHR51DT/MDHR51FL.DTA") %>%
  build_year(year = 2008,
             hh_rural_path = "data/derived/hh_2008_rural_simpler.rds",
             spei_years = 2006:2008)

hr_2011_final_15km <- read_dta("data/raw/dhs/DHS_2011/MDHR61DT/MDHR61FL.DTA") %>%
  build_year(year = 2011,
             hh_rural_path = "data/derived/hh_2011_rural_simpler.rds",
             spei_years = 2009:2011)

hr_2013_final_15km <- read_dta("data/raw/dhs/DHS_2013/MDHR6ADT/MDHR6AFL.DTA") %>%
  build_year(year = 2013,
  hh_rural_path = "data/derived/hh_2013_rural_simpler.rds",
  spei_years = 2011:2013)

hr_2016_final_15km <- read_dta("data/raw/dhs/DHS_2016/MDHR71DT/MDHR71FL.DTA") %>%
  build_year(year = 2016,
  hh_rural_path = "data/derived/hh_2016_rural_simpler.rds",
  spei_years = 2014:2016)

hr_2021_final_15km <- read_dta("data/raw/dhs/DHS_2021/MDHR81DT/MDHR81FL.DTA") %>%
  build_year(year = 2021,
  hh_rural_path = "data/derived/hh_2021_rural_simpler.rds",
  spei_years = 2019:2021)

# Consolidation

hr_consolidated_15km <- bind_rows(
  hr_1997_final_15km,
  hr_2008_final_15km,
  hr_2011_final_15km,
  hr_2013_final_15km,
  hr_2016_final_15km,
  hr_2021_final_15km
)

hr_consolidated_15km %>% count(DHSYEAR)

# Sauvegardes millésime
write_rds(hr_1997_final_15km, "data/derived/hr_1997_final_15km.rds")
write_rds(hr_2008_final_15km, "data/derived/hr_2008_final_15km.rds")
write_rds(hr_2011_final_15km, "data/derived/hr_2011_final_15km.rds")
write_rds(hr_2013_final_15km, "data/derived/hr_2013_final_15km.rds")
write_rds(hr_2016_final_15km, "data/derived/hr_2016_final_15km.rds")
write_rds(hr_2021_final_15km, "data/derived/hr_2021_final_15km.rds")

# Sauvegarde consolidée
write_rds(hr_consolidated_15km, "data/derived/hr_consolidated_15km_1997_2008_2011_2013_2016_2021.rds")
cat("Données enregistrées\n")
```

#### Matching

La méthode de matching est appliquée pour rendre comparable les groupes traités et contrôles, en les appariant selon cinq caractéristiques environnementales dans un rayon de 15 km.

```{r}

prep_matching <- function(df_final) {
  out <- df_final %>%
    filter(GROUP %in% c("Treatment","Control")) %>%
    mutate(treatment = if_else(GROUP == "Treatment", 1L, 0L))
  
  missing_cols <- setdiff(matching_variables, names(out))
  if (length(missing_cols) > 0) {
    message(">> Colonnes manquantes: ", paste(missing_cols, collapse=", "))
  }
  
  out %>% drop_na(all_of(intersect(matching_variables, names(out))))
}

# supprimer toute ancienne version pour éviter le masquage
if (exists("run_matching_year")) rm(run_matching_year)

run_matching_year <- function(year, overwrite = list(gen=FALSE, match=FALSE)) {
  cat("\n=== Matching", year, "===\n")
  fin_path <- glue("data/derived/hr_{year}_final_15km.rds")
  if (!file.exists(fin_path)) stop("Fichier introuvable: ", fin_path)
  
  dat   <- readRDS(fin_path)
  dat_m <- prep_matching(dat)
  
  
  n_total <- nrow(dat)
  n_filt <- nrow(dat_m)
  n_treat <- sum(dat_m$treatment == 1, na.rm = TRUE)
  n_ctrl <- sum(dat_m$treatment == 0, na.rm = TRUE)
  
  
  cat(glue(">> N total={n_total}, après filtre/NA={n_filt}; ",
           "Traités={n_treat}, ",
           "Contrôles={n_ctrl}\n"))
  
  have_all_vars <- all(matching_variables %in% names(dat_m))
  cat(">> Toutes les covars présentes ? ", have_all_vars, "\n")
  if (n_filt < 5 || !have_all_vars) {
    warning(glue("Année {year}: données insuffisantes ou variables manquantes — on saute."))
    return(NULL)
  }
  
  X_match <- dat_m %>%
    sf::st_drop_geometry() %>%
    dplyr::select(all_of(matching_variables)) %>%
    as.data.frame()
  
  gen_path         <- glue("data/derived/gen_match_model_{year}_15km.rds")
  match_path       <- glue("data/derived/matching_result_{year}_15km.rds")
  matched_out_path <- glue("data/derived/data_matched_{year}_15km.rds")
  
  # --- GenMatch ---
  used_cache_gen <- FALSE
  t0 <- Sys.time()
  if (file.exists(gen_path) && !isTRUE(overwrite$gen)) {
    cat(">> GenMatch: cache trouvé -> lecture\n")
    gen_model <- readRDS(gen_path)
    used_cache_gen <- TRUE
  } else {
    cat(">> GenMatch: calcul en cours...\n")
    gen_model <- GenMatch(
      Tr = dat_m$treatment,
      X  = X_match,
      BalanceMatrix = X_match,
      estimand = "ATT",
      M = 1,
      weights = NULL,
      pop.size = 1000,
      max.generations = 100,
      wait.generations = 4,
      caliper = .25,
      print.level = 1,
      cluster = rep("localhost", 4)
    )
    saveRDS(gen_model, gen_path)
  }
  t_gen <- as.numeric(difftime(Sys.time(), t0, units="mins"))
  cat(glue(">> GenMatch temps = {round(t_gen,1)} min (cache={used_cache_gen})\n"))
  
  # --- matchit() ---
  used_cache_match <- FALSE
  t1 <- Sys.time()
  if (file.exists(match_path) && !isTRUE(overwrite$match)) {
    cat(">> matchit: cache trouvé → lecture\n")
    m_out <- readRDS(match_path)
    used_cache_match <- TRUE
  } else {
    cat(">> matchit: calcul en cours...\n")
    fml <- as.formula(paste("treatment ~", paste(matching_variables, collapse=" + ")))
   
    
     m_out <- matchit(
      formula   = fml,
      data      = dat_m,
      method    = "genetic",
      distance  = "mahalanobis",
      gen.match = gen_model
    )
     
    saveRDS(m_out, match_path)
  }
  
  matched <- match.data(m_out, data = sf::st_drop_geometry(dat_m)) %>%
    dplyr::filter(weights > 0)
  
  saveRDS(matched, matched_out_path)
  cat(glue(">> N appariés = {nrow(matched)} (écrit: {matched_out_path})\n"))
  
  
  tibble(
    Année = year,
    'Total des observations' = n_total,
    'Après filtre/NA' = n_filt,
    Traités = n_treat,
    Contrôles = n_ctrl,
    'N appariés' = nrow(matched)
  )
}

need_overwrite <- function(year) {
  gen_path   <- glue("data/derived/gen_match_model_{year}_15km.rds")
  match_path <- glue("data/derived/matching_result_{year}_15km.rds")
  list(gen = !file.exists(gen_path), match = !file.exists(match_path))
}

# --- Exécution avec progression ---
yrs <- c(1997, 2008, 2011, 2013, 2016, 2021)


res_list <- vector("list", length(yrs))
names(res_list) <- yrs

with_progress({
  p <- progressor(along = yrs)

for (i in seq_along(yrs)) {
  yr <- yrs[i]
  ow <- need_overwrite(yr) 
  cat(glue("\n>> overwrite {yr}: gen={ow$gen}, match={ow$match}\n"))
  cat(sprintf("Start %s", yr))
  t_all <- Sys.time()
  res_list[[i]] <- tryCatch(
    run_matching_year(yr, overwrite = ow),
    error = function(e) { warning(glue("Year {yr} ERROR: {e$message}")); NULL }
  )
  cat(sprintf("Done %s (%.1f min)",
            yr, as.numeric(difftime(Sys.time(), t_all, units="mins"))))
}
})

result_list <- purrr::compact(res_list) |> bind_rows()
saveRDS(result_list, "data/derived/matching_summary_all_years_15km.rds")

bal_tabs <- purrr::imap(res_list, ~ {if (!is.null(.x)) {
  tryCatch(cobalt::bal.tab(.x$m), error = function(e) NULL) } else {
    NULL
  }
})

saveRDS(bal_tabs, "data/derived/matching_balance_tabs_all_years_15km.rds")

print(result_list)
```

Après le matching, nous obtenons:

-   1997: 5124 groupes appariées dont 1431 traités et 2851 contrôles

-   2008: 13364 groupes appariées dont 3489 traités et 7726 contrôles

-   2011: 6025 groupes appariées dont 1300 traités et 3583 contrôles

-   2013: 6375 groupes appariées dont 1952 traités et 3175 contrôles

-   2016: 9295 groupes appariées dont 2166 traités et 5762 contrôles

-   2021: 15364 groupes appariées dont 4355 traités et 8520 contrôles

##### Checking covariate balance: test before matching

Cette étape vérifie l'équilibre relatif des variables mesurées dans des unités différentes avant le matching pour mesurer l'écart entre les moyennes des covariables dans les groupes de traitement et de contrôle pour un buffer de 15 km.

```{r}
# Load 
hr_list <- setNames(
  lapply(yrs, function(y) read_rds(paste0("data/derived/hr_", y, "_final_15km.rds"))),
  yrs
)

# Equilibre des covariables
check_balance_before <- function(df, year, matching_variables) {
  
  data <- df %>%
    filter(GROUP %in% c("Treatment", "Control")) %>%
    mutate(treatment = if_else(GROUP == "Treatment", 1, 0))

  formula <- reformulate(matching_variables, response = "treatment")
  
  # Balance avant appariement
  bal_before <- bal.tab(
    formula,
    data = data,
    estimand = "ATT",
    un = TRUE,
    abs = TRUE
  )
  
  # Extraction du Standardized Mean Difference (SMD)
 balance_df <- bal_before$Balance %>%
    as.data.frame() %>%
    tibble::rownames_to_column("Variable")

  smd_col <- grep("Diff|Std", names(balance_df), value = TRUE)[1]

  smd_table <- balance_df %>%
    dplyr::select(Variable, SMD = all_of(smd_col)) %>%
    mutate(
      Year = year,
      Equilibre = if_else(abs(SMD) <= 0.1, "Équilibré", "Déséquilibré")
    ) %>%
    relocate(Year)

  return(smd_table)
}

balance_results <- lapply(names(hr_list), function(y) {
  check_balance_before(hr_list[[y]], as.numeric(y), matching_variables)
})

balance_results <- bind_rows(balance_results)

balance_results

# Distribution des covariables
data_list <- list(
  "1997" = hr_1997_final_15km,
  "2008" = hr_2008_final_15km,
  "2011" = hr_2011_final_15km,
  "2013" = hr_2013_final_15km,
  "2016" = hr_2016_final_15km,
  "2021" = hr_2021_final_15km 
)


  density_plot <- function(data, year, matching_variables){
    data %>%
      filter(GROUP %in% c("Treatment", "Control")) %>%
      mutate(GROUP =factor(GROUP, levels = c("Control", "Treatment"))) %>%
    pivot_longer(cols = all_of(matching_variables), names_to = "variable", values_to = "value") %>%
    ggplot(aes(x = value, fill = GROUP)) +
    geom_density(alpha = 0.5, color = "black", linewidth = 0.7, adjust = 0.7) +
    facet_wrap(~variable, scales = "free") + 
    scale_fill_manual(values = c("Control" = "green", "Treatment" = "blue")) +
    labs(
      title = paste("Covariate distribution before matching(", year, ")", sep = ""),
      x = "Valeur de la covariable",
      y = "Densité",
      fill = "Group"
    ) + 
    theme_minimal()
  }
    
print(density_plot(hr_1997_final_15km, 1997, matching_variables))
print(density_plot(hr_2008_final_15km, 2008, matching_variables))
print(density_plot(hr_2011_final_15km, 2011, matching_variables))
print(density_plot(hr_2013_final_15km, 2013, matching_variables))
print(density_plot(hr_2016_final_15km, 2016, matching_variables))
print(density_plot(hr_2021_final_15km, 2021, matching_variables))
```

L'analyse de l'équilibre avant appariement montre que, pour la plupart des années, les différences moyennes standardisées entre les groupes traités et contrôles sont supérieurs au seuil de 0.1, indiquant un déséquilibre. Seules les variables population_count_2000 (0.036553348) et travel_time_2000 (0.008339615) est équilibrée en 2008. En 2013, la variable slope aussi est équilibrée (0.044327937), ainsi que la variable traveltime pour l'année 2016 (0.068312075).

##### Checking covariate balance: test after matching

```{r}
# Balance test after matching: Quantile- quantile QQ Plot analysis
check_balance_after <- function(data_matched, year, matching_variables, plot_dir = "plots") {
  
  # Balance après appariement
  bal_after <- cobalt::bal.tab(
    x = data_matched[, matching_variables],
    treat = data_matched$GROUP,
    un = TRUE,
    abs = TRUE,
    estimand = "ATT"
  )
  
  print(bal_after)
  
  # QQ Plot
  year_dir <- file.path(plot_dir, glue("QQplots_{year}"))
  dir.create(year_dir, recursive = TRUE, showWarnings = FALSE)
  
  matching_variables %>% walk(function(var){
  if(!is.numeric(data_matched[[var]])){
    return(NULL)
  }
    
    p <- ggqqplot(
      data_matched, x = var, color = "GROUP",
      palette = c("#1f77b4", "#ff7f0e"),
      title = glue("QQ Polt - {var} ({year})")
    ) + 
      geom_abline(slope = 1, intercept = 0, linetype = "dashed") + 
      theme_minimal() +
      labs(x = "Quantiles théoriques", y = "Quantiles observés", color = "Groupe") + 
      theme(plot.title = element_text(hjust = 0.5))
    
    
    ggsave(
      filename = file.path(year_dir, glue("QQplot_{var}_{year}.png")), plot = p, width = 7, height = 5
    )
  })
  
  return(list(balance = bal_after))
}

results_list <- map(yrs, function(y){
  data_y <- readRDS(glue("data/derived/data_matched_{y}_15km.rds"))
  check_balance_after(data_y, y,matching_variables)
})

names(results_list) <- yrs


# Balance test after matching: Histogram
plot_mirror_hist_15km <- function(year, variable){
  
 df <- readRDS(glue("data/derived/data_matched_{year}.rds")) %>%
   filter(GROUP %in% c("Treatment", "Control")) %>%
   mutate(
     treatment = ifelse(GROUP == "Treatment", "Traité", "Contrôle"), 
     value = .data[[variable]]
   )
 
 ggplot() +
   geom_histogram(
     data = df %>% filter(treatment == "Traité"), 
     aes(x = value), 
     bins = 30, 
     fill = "blue", 
     alpha = 0.6
     ) + 
 geom_histogram(
   data = df %>% filter(treatment == "Contrôle"), 
   aes(x = value, y = -after_stat(count)),
   bins = 30, 
   fill = "green", 
   alpha = 0.6
   ) + 
   geom_hline(yintercept = 0, color = "black") + 
   labs(
     title = glue("Covariate after matching - {variable} - 15km ({year})"),
     x = variable, 
     y = "Effectifs (+ Traités / - Contrôles)"
     ) + 
   annotate("text", x = Inf, y = -Inf, label = "Traités", hjust = 1.1, vjust = 2, color = "blue") +
   annotate("text", x = Inf, y = -Inf, label = "Contrôles", hjust = 1.1, vjust = -1.5, color = "green") +
   theme_minimal()
 
}

walk(yrs, function(y){
  walk(matching_variables, function(v){
    message(glue("→ Histogramme-15km {v} ({y})"))
    print(plot_mirror_hist_15km(y, v))
  })
})
```

Après le matching,

-   En 1997, l'équilibre entre les groupes traités et contrôles est plutôt modéré, même si certains déséquilibres sont notables pour le treecover et la densité de population.

-   En 2008, l'équilibre entre les groupes est excellent avec des SMD \< 0.1.

-   En 2011, l'équilibre entre les groupes reste correct même si le SMD de traveltime monte à 0.0944, qui reste tout de même acceptable.

-   En 2013, l'équilibre entre les groupes est plutôt faible car deux covariables ont un SMD \> 0.1: treecover avec un SMD = 0.2204 et elevation avec un SMD = 0.2081

-   En 2016, l'équilibre entre les groupes est excellent avec des SMD \< 0.1 pour l'ensemmble des variables.

-   En 2021, les groupes appariés restent assez différents en termes de treecover. La SMD des deux covariables slope et population_density montrent également un léger déséquilibre entre les groupes.

#### Estimation

##### Overall effect on livelihoods

```{r}
# 2X2 DiD----------------------------------------------
library(fixest)
library(didimputation)
library(broom)

# Chargement des données
d97_15km <- read_rds("data/derived/data_matched_1997_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_1995,
         spei_wc_n_1 = spei_wc_1996,
         spei_wc_n   = spei_wc_1997) %>%
  mutate(hv219 = zap_labels(hv219), # hhh sex (1/2)
         hv220 = zap_labels(hv220)) # hhh age (num)

d08_15km <- read_rds("data/derived/data_matched_2008_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2006,
         spei_wc_n_1 = spei_wc_2007,
         spei_wc_n   = spei_wc_2008) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d11_15km <- read_rds("data/derived/data_matched_2011_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2009,
         spei_wc_n_1 = spei_wc_2010,
         spei_wc_n   = spei_wc_2011) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d13_15km <- read_rds("data/derived/data_matched_2013_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2011,
         spei_wc_n_1 = spei_wc_2012,
         spei_wc_n   = spei_wc_2013) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d16_15km <- read_rds("data/derived/data_matched_2016_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2014,
         spei_wc_n_1 = spei_wc_2015,
         spei_wc_n   = spei_wc_2016) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

d21_15km <- read_rds("data/derived/data_matched_2021_15km.rds") %>%
  rename(spei_wc_n_2 = spei_wc_2019,
         spei_wc_n_1 = spei_wc_2020,
         spei_wc_n   = spei_wc_2021) %>%
  mutate(hv219 = zap_labels(hv219),
         hv220 = zap_labels(hv220))

# Préparation des données
dat_15km <- bind_rows(d97_15km, d08_15km, d11_15km, d13_15km, d16_15km, d21_15km) %>%
  filter(GROUP %in% c("Treatment","Control")) %>%
  mutate(
    hv219   = factor(hv219, levels = c(1,2), labels = c("Homme","Femme")), # sexe (cat.)
    hv220   = as.numeric(hv220),                                           # âge
    treat   = as.integer(GROUP == "Treatment"),
    w_svy   = hv005 / 1e6,
    w_all   = w_svy * weights, # poids d'enquête × poids de matching (si 'weights' existe)
    id      = row_number(),
    # Map des années de statut -> première année d'observation post (treatment_phase)
    treatment_phase = case_when(
      STATUS_YR == 2010 ~ 2011,
      STATUS_YR == 2012 ~ 2013,
      STATUS_YR == 2015 ~ 2016,
      STATUS_YR == 2017 ~ 2021,
      is.na(STATUS_YR)  ~ 0,
      TRUE               ~ STATUS_YR
    )
  )

# Outcome h
yvar <- "wealth_centile_rural_weighted"

# fixest DID 2×2: placebo 1997–2008, traitement 2008–2021 ------------------

# Placebo 1997–2008
pre_15km <- dat_15km %>%
  filter(DHSYEAR %in% c(1997, 2008)) %>%
  mutate(post = as.integer(DHSYEAR == 2008),
         treat_post = treat * post)

f_pre <- as.formula(paste(
  yvar, "~ treat + post + treat_post +",
  "spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220"
))

m_pre <- feols(f_pre, data = pre_15km, weights = ~ w_all, cluster = ~ hv001)

# Traitement 2008–2021
main <- dat_15km %>%
  filter(DHSYEAR %in% c(2008, 2021)) %>%
  mutate(post = as.integer(DHSYEAR == 2021),
         treat_post = treat * post)

f_main <- f_pre  # même formule

m_main <- feols(f_main, data = main, weights = ~ w_all, cluster = ~ hv001)

etable(m_pre, m_main, headers = c("Placebo 97–08", "Traitement 08–21"))

# Extraction compacte des deux effets DID
did_row <- function(model, year_post, vc = ~ hv001, term = "treat_post"){
  summary(model, vcov = vc) %>% broom::tidy() %>%
    filter(term == !!term) %>%
    transmute(year = year_post, estimate, se = std.error)
}
did_df <- bind_rows(
  did_row(m_pre, 2008),
  did_row(m_main, 2021)
) %>%
  mutate(period = factor(ifelse(year == 2008, "1997–2008", "2008–2021"),
                         levels = c("1997–2008", "2008–2021")),
         lo = estimate - 1.96*se,
         hi = estimate + 1.96*se)

ggplot(did_df, aes(x = period, y = estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_errorbar(aes(ymin = lo, ymax = hi), width = .2) +
  geom_point(size = 3) +
  labs(x = NULL, y = "Effet DID sur le centile de richesse (pondéré)",
       title = "DID 2×2 avec IC clusterisés (hv001) - buffer 15 km")


# Staggered diff-in-diff----------------------------------------
# did2s (Gardner) : statique + event-study--------------------------------
library(did2s)

dat3 <- dat_15km %>%
  mutate(
    treat_on = as.integer(treatment_phase > 0 & DHSYEAR >= treatment_phase),
    rel_year = if_else(treatment_phase > 0, DHSYEAR - treatment_phase, Inf),
    # Binning prudent pour stabilité (-5..5)
    rel_year_binned = pmax(pmin(rel_year, 5), -5)
  )

# -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(treat_on, ref = FALSE),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static, headers = "did2s statique")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(rel_year_binned, ref = c(-1, Inf)),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es, headers = "did2s event-study (-5..5) - buffer 15 km")

# Plot ES did2s
plot_did2s <- broom::tidy(did2s_es, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(k = as.numeric(sub("^rel_year_binned::", "", term))) %>%
  arrange(k)

ggplot(plot_did2s, aes(k, estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s)")

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present <- plot_did2s$k[plot_did2s$k < 0]
if(length(leads_present) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present, collapse="|"), ")$")
  print(fixest::wald(did2s_es, keep = keep_regex))
}
```

Dans l'ensemble, les analyses DID 2x2 et staggered DID montrent que la création d'aires protégées n'a pas entraîné de changements significatifs sur le centile de richesse des ménages à 15 km des aires protégées.

Les tests placebo (1997-2008) montre l'absence de d'effet avant la création des aires protégées, renforçant la crédibilité causale. Toutefois, on observe un léger effet positif moyen des aires protégées sur le centile de richesse dans les années 1 à 3 années suivant sa mise en place. Ces effets sont sont ni robustes ni durable.

##### Effect on inequalities

###### Staggered DID

```{r}
# Staggered DiD-----------------------------------------
yvar <- "zscore_wealth"

# did2s (Gardner) : statique + event-study--------------------------------
# -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(treat_on, ref = FALSE),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static, headers = "did2s statique")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(rel_year_binned, ref = c(-1, Inf)),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es, headers = "did2s event-study (-5..5)")

# Plot ES did2s
plot_did2s <- broom::tidy(did2s_es, conf.int = TRUE) %>%
  filter(grepl("^rel_year_binned::", term)) %>%
  mutate(k = as.numeric(sub("^rel_year_binned::", "", term))) %>%
  arrange(k)

ggplot(plot_did2s, aes(k, estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .2) +
  labs(x = "Années relatives au 1er traitement (binnées -5..5)",
       y = "Effet estimé",
       title = "Event-study (did2s) - 15 km")

# Test joint de pré-tendances (tous les leads k < 0)
# On construit un motif regex pour k = -5..-1 présents dans le modèle
leads_present <- plot_did2s$k[plot_did2s$k < 0]
if(length(leads_present) > 0){
  keep_regex <- paste0("^rel_year_binned::(", paste(leads_present, collapse="|"), ")$")
  print(fixest::wald(did2s_es, keep = keep_regex))
}

```

L'estimation DID 2x2 montre que l'effet moyen d'être dans un cluster traité (situé à proximité des aires protégées créées après 2008) n'est pas statistiquement significatif sur le Z-score de l'indice de richesse (𝜷 = -7.35$e^-5$; SE = 0.0053). De plus R² et R² ajusté sont proches de zéro et identiques, indiquant que le modèle n'explique pratiquement aucune part de la variation du niveau de richesse.

Le modèle event study ne met en évidence aucune tendance significative avant la mise en place des aires protégées. L'hypothèse des tendances parallèles est vérifié car l'hypothèse nulle est rejeté (p-value = 0.6222184 \> 0.05). Après la mise en place de l'aire protégée, un effet positif émerge deux ans après l'intervention (rel_year = 2: 0.0190\*\*\*). Toutefois, cet effet disparaît au bout de trois ans, indiquant que l'effet n'est pas durable. Le R² et R² ajusté montrent que la part de variance expliquée par le traitement est minimale.

###### Quantile treatment effect

```{r}
# Quantile treatment effects
# Testing Quantile treatment effect------------------------------
library(qte)

# Avec CiC -------------------

## Traitement 2008 -> 2021
set.seed(123)
dat_2per <- dat_15km %>%
  filter(DHSYEAR %in% c(2008, 2021)) %>%
  mutate(treat = as.integer(GROUP == "Treatment"))

cic_res <- suppressWarnings(CiC(
  formla = wealth_centile_rural_weighted ~ treat,
  t = 2021, tmin1 = 2008, tname = "DHSYEAR",
  data = dat_2per,
  panel = FALSE, # repeated cross-sections
  se = TRUE, iters = 200, # bootstrap
  probs = seq(0.05, 0.95, 0.05),
  xformla = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220
))

summary(cic_res)
ggqte(cic_res) + labs(x="Quantiles", y="QTET", title="CiC QTET: 2008-2021")

## placebo------------------------------------------------------

## Placebo: 1997 -> 2008
dat_placebo <- dat_15km %>%
  filter(DHSYEAR %in% c(1997, 2008)) %>%
  mutate(treat = as.integer(GROUP == "Treatment"))

# (Optional) sanity check:
# with(dat_placebo, table(DHSYEAR, treat))

cic_pre <-  suppressWarnings(CiC(
  formla = wealth_centile_rural_simple ~ treat,
  t = 2008, tmin1 = 1997, tname = "DHSYEAR",
  data = dat_placebo,
  panel = FALSE, # repeated cross-sections
  se = TRUE, iters = 100, # bootstrap
  probs = seq(0.05, 0.95, 0.05),
  xformla = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220
))

summary(cic_pre)

ggqte(cic_pre) +
  labs(x = "Quantiles", y = "QTET",
       title = "Placebo CiC QTET: 1997-2008")

```

Pour l'estimation principale (2008-2021), les résultats de QTE indiquent un effet négatif sur l'ensemble de la distribution de la richesse des ménages. Toutefois, l'impact du traitement n'est pas homogène pour toutes les classes. Il est plus marqué pour les classes moyennes (quantile variant de 0.30 à 0.60 avec des effets entre -20 et -23), tandis qu'il est plus faible ches les ménages les plus pauvres et les plus riches. L'effet moyen du traitement (ATE = -16.36) confirme une baisse significative du niveau de richesse associée à la proximité des aires protégées créées après 2008. Ces résultats suggèrent que la mise en place des aires protégées renforcent les inégalités.

Pour le placebo (1997-2008), Les ménages les plus pauvres semblent peu affectés, voire légèrement bénéficiaires de la mise en place des aires protégées, avec des QTE positifs (quantiles variant de 5.53 à .

##### Heterogeneity

```{r}
# Création du groupe IUCN 
dat3 <- dat3 %>%
  filter(!is.na(IUCN_CAT), !is.na(treat_on)) %>%
  mutate(
    IUCN_group = case_when(
    IUCN_CAT %in% c("Ia", "Ib", "II", "III", "IV") ~ "strict",
    IUCN_CAT %in% c("V", "VI") ~ "usage_multiple", 
    TRUE ~ NA_character_
  ),
  IUCN_group = factor(IUCN_group, levels = c("strict", "usage_multiple")),
  rel_year_binned = factor(rel_year_binned, levels = -5:5)
  ) %>%
  filter(!is.na(IUCN_group))

run_did2s_es <- function(data, yvar) {
  
  # DID Statique
  did2s_static_15km <- did2s(
    data        = data,
    yname       = yvar,
    first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
    second_stage = ~ treat_on * IUCN_group,
    treatment   = "treat_on",
    cluster_var = "hv001",
    weights     = "w_all"
  )
  print(etable(did2s_static_15km, headers = paste("did2s statique -", yvar)))
  
# DID event study
  
  did2s_es_15km <- did2s(
    data = data,
    yname = yvar, 
    first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
    second_stage = ~ i(rel_year_binned, IUCN_group, ref = -1),
    treatment   = "treat_on",
    cluster_var = "hv001",
    weights     = "w_all"
  )
  
  print(etable(did2s_es, 
               headers = paste("did2s event-study (-5..5) par statut IUCN - buffer 15km", yvar)))
  
    # Extraction des coefficients
  tidy_es <- broom::tidy(did2s_es_15km, conf.int = TRUE) %>%
    filter(grepl("^rel_year_binned::", term)) %>%
    mutate(
      year = as.numeric(stringr::str_extract(term, "(?<=::)-?[0-9]+")),
      
      # identifier strict vs usage_multiple
      group = case_when(
        grepl("usage_multiple", term, ignore.case = TRUE) ~ "usage_multiple",
        grepl("strict", term, ignore.case = TRUE) ~ "strict",
        TRUE ~ NA_character_
      ),
      outcome = yvar
    ) %>%
    filter(!is.na(group))

  #Plot
  plot_title <- paste0("Event-study (did2s) -", yvar, "\nHétérogénéité par statut IUCN - buffer 15km")
  
  g <- ggplot(tidy_es, aes(x = year, y = estimate, color = group)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
    labs(
      x = "Années relatives au 1er traitement (binnées -5..5) - buffer 15 km",
      y = "Effet estimé",
      title = plot_title,
      color = "Catégorie IUCN"
    ) +
    theme_minimal(base_size = 14)
  
  print(g)
  
  # Test de pré-tendances
  leads <- tidy_es %>% filter(year < 0)
  
  if(nrow(leads) > 0){
    keep_regex <- paste0("^rel_year_binned::(", paste(unique(leads$year), collapse="|"), "):")
    print(wald(did2s_es_15km, keep = keep_regex))
  }
  
  return(list(
    static = did2s_static_15km,
    es     = did2s_es_15km,
    coef   = tidy_es,
    plot   = g
  ))
}


res_wealth <- run_did2s_es(dat3, "wealth_centile_rural_weighted")
res_zscore <- run_did2s_es(dat3, "zscore_wealth")

```

## Test pour l'hypothèse multiple

Cette partie présente le tes tests multiples sur les variables de résultat et les hypothèses. Lorsqu'on teste beaucoup d'hypothèses, on augmente automatiquement le risque d'inférer à tort des effets significatifs, des problèmes de multiplicité des tests. Afin de mitiger ce risque, @benjamini1995 propose de contrôler la proportion moyenne des faux positifs parmi les résultats déclarés significatifs. La méthode de False Discovery Rate (FDR) est donc appliqué aux hypothèses secondaires H2 sur les inégalités entre ménages (évaluées via un z-score de l'indice de richesse) et H3 sur l'importance du mode de gouvernance des aires protégées. Pour se faire, les p-values des tests de H2 et H3 sont récupérées et triées dans l'ordre croissant avant d'appliquer la règle BH. Si pBH \< 0.05, le test est considéré comme significatif.

### Test multiple pour l'hypothèse H2 

H2-effect on inequalities: PA exacerbate economic inequalities, as better-off or better-connected individuals capture most of the benefits (tourism jobs, development projects).

```{r}
library(fuzzySim)

# Test appliqué à H2-------------------------
# did2s (Gardner) : statique + event-study
# -- Statique (traitement "on/off")
did2s_static <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(treat_on, ref = FALSE),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_static, headers = "did2s statique")

# -- Event-study (avec binning -5..5, ref = -1 et never-treated)
did2s_es <- did2s(
  data        = dat3,
  yname       = yvar,
  first_stage = ~ spei_wc_n_2 + spei_wc_n_1 + spei_wc_n + hv219 + hv220 | DHSYEAR,
  second_stage= ~ i(rel_year_binned, ref = c(-1, Inf)),
  treatment   = "treat_on",
  cluster_var = "hv001",
  weights     = "w_all"
)
etable(did2s_es, headers = "did2s event-study (-5..5)")

# Extraction du p-value du coefficient estimé par DID static
tidy_H2 <- broom::tidy(did2s_static)

p_H2_did <- tidy_H2 %>%
  filter(term == "treat_on::1") %>% 
  pull(p.value)

# Extraction du p-value du coefficient estimé par event study
ev <- broom::tidy(did2s_es) %>%
  mutate(
    p_fdr <- p.adjust(p.value, method = "BH")
  )

# Extraction du p-value du coefficient estimé par QTE 
library(dplyr)

qte_df <- tibble(
  quantile  = cic_res$probs,
  QTE       = cic_res$qte,
  Std_Error = cic_res$qte.se
) %>% 
  mutate(
    t_stat  = QTE / Std_Error,
    p_value = 2 * (1 - pnorm(abs(t_stat))),
    p_fdr   = p.adjust(p_value, method = "BH")
  )

qte_df

# Correction FDR BH 
results_H2 <- list(
  DID_p_value = p_H2_did,
  EventStudy_Table = ev %>% select(term, estimate, std.error),
  QTE_table = qte_df 
)
results_H2 
```

L'estimation DID statique indique qu'en moyenne, la création des aires protégées n'a pas modifié significativement le score de richesse standardisé des ménages exposés (treat_on = 1:: 0.0015). Toutefois, l'analyse dynamique via l'event study) nuance cette conclusion. L' effet reste nul autour de l'année de la création des aires protégées, mais deviennent positifs et significatifs après deux à trois ans. L'effet n'est pas durable mais diminue environ cinq plus tard.

L'analyse distributionnelle (QTE) met en évidence la présence d'hétérogénéité des effets. Les ménages les plus pauvres à intermédiaires sont significativement appauvris, tandis que les ménages les plus aisés subissent des effets plus faibles. L'absence d'impact moyen masque en réalité une forte inégalité d'impact entre les groupes, notamment au détriment des ménages les plus pauvres.

## Analyse de sensibilité de Rosenbaum

Vérification de la robustesse des résultats issus du matching face à un éventuel biais non observé en testant différentes valeurs de Γ, afin d'évaluer dans quelle mesure la présence d'un biais caché pourraient influencer les conclusions de l'analyse

```{r}

```

## Effets hétérogènes

Estimation des effets hétérogènes en introduisant des interactions entre le traitement et les différentes variables différenciatrices dans un modèle de double DID pour explorer les effets différenciés des aires protégées sur les ménages en fonction des caractéristiques socio-démographiques et environnementales

Caractéristiques socio-démographiques et environnementales:

-   Sexe et âge du chef de ménage

-   Conditions environnementales (Pluviométrie, sécheresse)

-   Type de gouvernance des aires protégées (strictes (statuts IUCN I-IV) vs multi-usages ( statuts IUCN V-VI))

-   Distance aux aires protégées (5km, 10 km, 15 km) -\> même analyse que test de robustess? si oui, enlver de cette partie

## Impact sur l'inégalité intra-communautaire

-   Inégalité intra-communautaire (Z-score standardisée du wealth index)

```{r}

```

## Pseudo Panel

-   Construction de cohorte de ménage

-   Estimation d'un modèle à effet fixe pour corriger les biais liées aux variables non observés

-   Pondérer les observations en fonction de la taille des cohortes

```{r}

```

# Appendix

## Statistical power

-   Estimation de la puissance statistique pour détecter un effet d'au moins 7.5 centiles dans l'indice de richesse entre les groupes

-   EStimation de la probabilité à un seuil de puissance fixée à 0.8 avec un seuil de signification fixée à 0.05

**Mobilisation des données MIS 2011, MIS 2013 et MIS 2016 si la puissance statistique est insuffisante**
